===== START Sun 12/28/2025  6:28:57.53 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 06:29:30] [setup] RAM Tracking...
[codecarbon INFO @ 06:29:30] [setup] CPU Tracking...
[codecarbon WARNING @ 06:29:30] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:29:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:29:32] [setup] GPU Tracking...
[codecarbon INFO @ 06:29:32] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:29:32] >>> Tracker's metadata:
[codecarbon INFO @ 06:29:32]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:29:32]   Python version: 3.12.7
[codecarbon INFO @ 06:29:32]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:29:32]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:29:32]   CPU count: 56
[codecarbon INFO @ 06:29:32]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:29:32]   GPU count: 2
[codecarbon INFO @ 06:29:32]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:29:35] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:29:37] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:29:37] Energy consumed for all CPUs : 0.000041 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:29:37] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 17.643285223402156 W
[codecarbon INFO @ 06:29:37] 0.000067 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 06:57:17] [setup] RAM Tracking...
[codecarbon INFO @ 06:57:17] [setup] CPU Tracking...
[codecarbon WARNING @ 06:57:17] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:57:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:57:19] [setup] GPU Tracking...
[codecarbon INFO @ 06:57:19] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:57:19] >>> Tracker's metadata:
[codecarbon INFO @ 06:57:19]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:57:19]   Python version: 3.12.7
[codecarbon INFO @ 06:57:19]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:57:19]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:57:19]   CPU count: 56
[codecarbon INFO @ 06:57:19]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:57:19]   GPU count: 2
[codecarbon INFO @ 06:57:19]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:57:22] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:57:23] Energy consumed for RAM : 0.000018 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:57:23] Energy consumed for all CPUs : 0.000038 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:57:23] Energy consumed for all GPUs : 0.000006 kWh. Total GPU Power : 15.803830176176266 W
[codecarbon INFO @ 06:57:23] 0.000061 kWh of electricity used since the beginning.
[codecarbon INFO @ 06:58:18] [setup] RAM Tracking...
[codecarbon INFO @ 06:58:18] [setup] CPU Tracking...
[codecarbon WARNING @ 06:58:18] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:58:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:58:19] [setup] GPU Tracking...
[codecarbon INFO @ 06:58:19] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:58:20] >>> Tracker's metadata:
[codecarbon INFO @ 06:58:20]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:58:20]   Python version: 3.12.7
[codecarbon INFO @ 06:58:20]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:58:20]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:58:20]   CPU count: 56
[codecarbon INFO @ 06:58:20]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:58:20]   GPU count: 2
[codecarbon INFO @ 06:58:20]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:58:23] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:58:23] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:58:23] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:58:23] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.09921353083409 W
[codecarbon INFO @ 06:58:23] 0.000036 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 5                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: mudhog              #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: data_poisoning 10,5 #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_data_pois_10_5_inner_epochs=5_epochs=10_PDR=1.0_scale=5_mudhog#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_data_pois_10_5_inner_epochs=5_epochs=10_PDR=1.0_scale=5_mudhog----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 29.768 	Loss: 2.9637[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 36.584 	Loss: 1.9059[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.497 	Loss: 1.8631[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 37.769 	Loss: 1.8615[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.200 	Loss: 1.8555[00m
[92m  Client0 Test => 	Acc: 12.335 	Loss: 2.9662[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 19.705 	Loss: 4.7098[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 21.354 	Loss: 2.3620[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 25.955 	Loss: 2.3221[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 27.604 	Loss: 2.1843[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.167 	Loss: 2.1627[00m
[92m  Client1 Test => 	Acc: 4.893 	Loss: 3.0289[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 20.747 	Loss: 5.8241[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 21.875 	Loss: 2.8118[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 32.639 	Loss: 2.4041[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.274 	Loss: 2.1423[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 41.927 	Loss: 2.1293[00m
[92m  Client2 Test => 	Acc: 12.983 	Loss: 3.1516[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 23.915 	Loss: 3.5300[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 31.424 	Loss: 1.9700[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 32.595 	Loss: 1.9054[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 32.639 	Loss: 1.9133[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 32.986 	Loss: 1.9114[00m
[92m  Client3 Test => 	Acc: 7.915 	Loss: 4.0406[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 14.551 	Loss: 5.6434[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 16.699 	Loss: 2.9338[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 21.484 	Loss: 2.4351[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 20.410 	Loss: 2.2967[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 23.242 	Loss: 2.2534[00m
[92m  Client4 Test => 	Acc: 5.652 	Loss: 2.8332[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 16.406 	Loss: 4.1468[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 29.427 	Loss: 2.1039[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 33.854 	Loss: 1.9461[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 35.417 	Loss: 2.0203[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 42.057 	Loss: 1.8061[00m
[92m  Client5 Test => 	Acc: 12.492 	Loss: 4.6086[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 24.844 	Loss: 2.7382[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 42.719 	Loss: 1.8991[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 58.312 	Loss: 1.4301[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 60.000 	Loss: 1.3405[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 65.906 	Loss: 1.1072[00m
[92m  Client6 Test => 	Acc: 44.430 	Loss: 2.0582[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 18.516 	Loss: 5.7259[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.656 	Loss: 2.3815[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 24.375 	Loss: 2.2126[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 23.750 	Loss: 2.1544[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 32.656 	Loss: 1.9781[00m
[92m  Client7 Test => 	Acc: 13.769 	Loss: 4.3460[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 21.875 	Loss: 7.9625[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 21.094 	Loss: 3.0164[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 19.661 	Loss: 2.2420[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 25.000 	Loss: 2.3650[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 22.135 	Loss: 2.1739[00m
[92m  Client8 Test => 	Acc: 5.360 	Loss: 3.3493[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.231 	Loss: 4.7768[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 28.245 	Loss: 2.1901[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 31.130 	Loss: 1.9868[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 44.591 	Loss: 1.6128[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 56.310 	Loss: 1.3468[00m
[92m  Client9 Test => 	Acc: 41.652 	Loss: 2.1366[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.983 	Loss: 2.7272[00m
 Train: Round   0, Avg Accuracy 38.459 | Avg Loss 1.872
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 32.381 	Loss: 2.6454[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 37.258 	Loss: 1.8624[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 37.662 	Loss: 1.8490[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 37.581 	Loss: 1.8518[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.227 	Loss: 1.8360[00m
[92m  Client0 Test => 	Acc: 12.348 	Loss: 3.4030[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 21.701 	Loss: 2.4628[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.340 	Loss: 2.1682[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 30.295 	Loss: 2.1158[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 30.035 	Loss: 2.1179[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.688 	Loss: 2.1124[00m
[92m  Client1 Test => 	Acc: 11.047 	Loss: 3.5318[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.101 	Loss: 2.3673[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.361 	Loss: 2.1381[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.361 	Loss: 2.1293[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.188 	Loss: 2.0926[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 41.927 	Loss: 2.1059[00m
[92m  Client2 Test => 	Acc: 12.942 	Loss: 3.2720[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 29.861 	Loss: 2.2185[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 33.550 	Loss: 1.9074[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 33.203 	Loss: 1.9070[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 31.597 	Loss: 1.9127[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 32.726 	Loss: 1.9021[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 07:26:06] [setup] RAM Tracking...
[codecarbon INFO @ 07:26:06] [setup] CPU Tracking...
[codecarbon WARNING @ 07:26:06] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 07:26:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:26:07] [setup] GPU Tracking...
[codecarbon INFO @ 07:26:07] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 07:26:08] >>> Tracker's metadata:
[codecarbon INFO @ 07:26:08]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 07:26:08]   Python version: 3.12.7
[codecarbon INFO @ 07:26:08]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 07:26:08]   Available RAM : 126.630 GB
[codecarbon INFO @ 07:26:08]   CPU count: 56
[codecarbon INFO @ 07:26:08]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:26:08]   GPU count: 2
[codecarbon INFO @ 07:26:08]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 07:26:11] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 07:26:11] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 07:26:11] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 07:26:11] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.030583254821934 W
[codecarbon INFO @ 07:26:11] 0.000031 kWh of electricity used since the beginning.
[codecarbon INFO @ 07:27:06] [setup] RAM Tracking...
[codecarbon INFO @ 07:27:06] [setup] CPU Tracking...
[codecarbon WARNING @ 07:27:06] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 07:27:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:27:07] [setup] GPU Tracking...
[codecarbon INFO @ 07:27:07] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 07:27:07] >>> Tracker's metadata:
[codecarbon INFO @ 07:27:07]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 07:27:07]   Python version: 3.12.7
[codecarbon INFO @ 07:27:07]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 07:27:07]   Available RAM : 126.630 GB
[codecarbon INFO @ 07:27:07]   CPU count: 56
[codecarbon INFO @ 07:27:07]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:27:07]   GPU count: 2
[codecarbon INFO @ 07:27:07]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 07:27:10] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 07:27:11] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 07:27:11] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 07:27:11] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.686519143594527 W
[codecarbon INFO @ 07:27:11] 0.000026 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 07:54:57] [setup] RAM Tracking...
[codecarbon INFO @ 07:54:57] [setup] CPU Tracking...
[codecarbon WARNING @ 07:54:57] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 07:54:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:54:59] [setup] GPU Tracking...
[codecarbon INFO @ 07:54:59] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 07:54:59] >>> Tracker's metadata:
[codecarbon INFO @ 07:54:59]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 07:54:59]   Python version: 3.12.7
[codecarbon INFO @ 07:54:59]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 07:54:59]   Available RAM : 126.630 GB
[codecarbon INFO @ 07:54:59]   CPU count: 56
[codecarbon INFO @ 07:54:59]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:54:59]   GPU count: 2
[codecarbon INFO @ 07:54:59]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 07:55:02] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 07:55:03] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 07:55:03] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 07:55:03] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.368062525145458 W
[codecarbon INFO @ 07:55:03] 0.000028 kWh of electricity used since the beginning.
[codecarbon INFO @ 07:55:58] [setup] RAM Tracking...
[codecarbon INFO @ 07:55:58] [setup] CPU Tracking...
[codecarbon WARNING @ 07:55:58] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 07:56:00] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:56:00] [setup] GPU Tracking...
[codecarbon INFO @ 07:56:00] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 07:56:00] >>> Tracker's metadata:
[codecarbon INFO @ 07:56:00]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 07:56:00]   Python version: 3.12.7
[codecarbon INFO @ 07:56:00]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 07:56:00]   Available RAM : 126.630 GB
[codecarbon INFO @ 07:56:00]   CPU count: 56
[codecarbon INFO @ 07:56:00]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:56:00]   GPU count: 2
[codecarbon INFO @ 07:56:00]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 07:56:03] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 07:56:04] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 07:56:04] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 07:56:04] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 18.243250587964347 W
[codecarbon INFO @ 07:56:04] 0.000026 kWh of electricity used since the beginning.

[92m  Client3 Test => 	Acc: 12.929 	Loss: 5.5868[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.406 	Loss: 2.5848[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 22.461 	Loss: 2.2953[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.098 	Loss: 2.2376[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.488 	Loss: 2.2130[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.219 	Loss: 2.2417[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 5.1014[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 25.000 	Loss: 2.3696[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 26.042 	Loss: 2.2595[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 24.089 	Loss: 2.0633[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 34.245 	Loss: 2.0376[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 41.016 	Loss: 1.8431[00m
[92m  Client5 Test => 	Acc: 24.229 	Loss: 2.8776[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.438 	Loss: 2.1765[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.344 	Loss: 2.0868[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.250 	Loss: 2.0814[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.344 	Loss: 2.0836[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.344 	Loss: 2.0796[00m
[92m  Client6 Test => 	Acc: 12.314 	Loss: 3.1739[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 22.734 	Loss: 2.3999[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.484 	Loss: 2.1960[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.875 	Loss: 2.1675[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 29.531 	Loss: 2.1466[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 33.047 	Loss: 1.9991[00m
[92m  Client7 Test => 	Acc: 16.356 	Loss: 3.7881[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 20.052 	Loss: 2.5253[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 26.042 	Loss: 2.1546[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 26.432 	Loss: 2.1076[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 35.156 	Loss: 1.9937[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 44.141 	Loss: 1.9247[00m
[92m  Client8 Test => 	Acc: 14.048 	Loss: 3.4866[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.154 	Loss: 2.3571[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.901 	Loss: 2.1233[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.442 	Loss: 2.1700[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 31.550 	Loss: 2.0128[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 47.296 	Loss: 1.6776[00m
[92m  Client9 Test => 	Acc: 28.641 	Loss: 2.7333[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[0. 1. 1. 0. 0. 1. 1. 0. 1. 0.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.969 	Loss: 2.6191[00m
 Train: Round   1, Avg Accuracy 35.763 | Avg Loss 1.972
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 33.809 	Loss: 2.2716[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 30.927 	Loss: 3.7003[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 36.099 	Loss: 1.9793[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 35.210 	Loss: 1.8566[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 37.769 	Loss: 1.8344[00m
[92m  Client0 Test => 	Acc: 12.328 	Loss: 3.4367[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 18.924 	Loss: 2.4314[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.514 	Loss: 2.1316[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.601 	Loss: 2.1255[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.861 	Loss: 2.1173[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 30.122 	Loss: 2.1109[00m
[92m  Client1 Test => 	Acc: 11.081 	Loss: 3.6106[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.448 	Loss: 2.2408[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.622 	Loss: 2.0968[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.448 	Loss: 2.0862[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.448 	Loss: 2.0795[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.188 	Loss: 2.0795[00m
[92m  Client2 Test => 	Acc: 12.936 	Loss: 3.3632[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 26.128 	Loss: 2.1001[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 28.516 	Loss: 7.8947[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 26.085 	Loss: 2.3354[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 32.465 	Loss: 13.4240[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 31.554 	Loss: 1.9072[00m
[92m  Client3 Test => 	Acc: 12.969 	Loss: 3.4267[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.992 	Loss: 2.5722[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 23.145 	Loss: 2.2604[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 24.902 	Loss: 2.2172[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 24.609 	Loss: 2.2243[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.121 	Loss: 2.2150[00m
[92m  Client4 Test => 	Acc: 5.590 	Loss: 3.6771[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 23.047 	Loss: 2.2947[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 30.990 	Loss: 2.0135[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 40.885 	Loss: 1.8631[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 58.203 	Loss: 1.4540[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 60.677 	Loss: 1.2005[00m
[92m  Client5 Test => 	Acc: 37.762 	Loss: 2.9362[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.000 	Loss: 2.1936[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 30.031 	Loss: 2.0911[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 26.500 	Loss: 2.4306[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.281 	Loss: 2.6946[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.094 	Loss: 2.0952[00m
[92m  Client6 Test => 	Acc: 12.375 	Loss: 3.1859[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.938 	Loss: 2.3673[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 25.547 	Loss: 2.1591[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 31.875 	Loss: 2.1153[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.031 	Loss: 2.2429[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 34.609 	Loss: 2.0390[00m
[92m  Client7 Test => 	Acc: 18.913 	Loss: 3.3019[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 13.021 	Loss: 2.7255[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 24.089 	Loss: 2.2660[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 44.792 	Loss: 1.9763[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 50.130 	Loss: 1.8022[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 48.177 	Loss: 1.6481[00m
[92m  Client8 Test => 	Acc: 11.136 	Loss: 3.0984[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 20.373 	Loss: 2.2755[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 27.644 	Loss: 2.0173[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 27.404 	Loss: 2.0133[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 38.221 	Loss: 1.7187[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 56.250 	Loss: 1.4124[00m
[92m  Client9 Test => 	Acc: 40.289 	Loss: 2.3389[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.929 	Loss: 2.6192[00m
 Train: Round   2, Avg Accuracy 39.056 | Avg Loss 1.854
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 33.621 	Loss: 2.0577[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.416 	Loss: 1.8422[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 08:23:52] [setup] RAM Tracking...
[codecarbon INFO @ 08:23:52] [setup] CPU Tracking...
[codecarbon WARNING @ 08:23:52] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:23:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:23:54] [setup] GPU Tracking...
[codecarbon INFO @ 08:23:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:23:54] >>> Tracker's metadata:
[codecarbon INFO @ 08:23:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:23:54]   Python version: 3.12.7
[codecarbon INFO @ 08:23:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:23:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:23:54]   CPU count: 56
[codecarbon INFO @ 08:23:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:23:54]   GPU count: 2
[codecarbon INFO @ 08:23:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:23:57] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:23:58] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:23:58] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:23:58] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 14.801676056830214 W
[codecarbon INFO @ 08:23:58] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 08:24:52] [setup] RAM Tracking...
[codecarbon INFO @ 08:24:52] [setup] CPU Tracking...
[codecarbon WARNING @ 08:24:52] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:24:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:24:54] [setup] GPU Tracking...
[codecarbon INFO @ 08:24:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:24:54] >>> Tracker's metadata:
[codecarbon INFO @ 08:24:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:24:54]   Python version: 3.12.7
[codecarbon INFO @ 08:24:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:24:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:24:54]   CPU count: 56
[codecarbon INFO @ 08:24:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:24:54]   GPU count: 2
[codecarbon INFO @ 08:24:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:24:57] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:24:58] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:24:58] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:24:58] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.7185431999452 W
[codecarbon INFO @ 08:24:58] 0.000031 kWh of electricity used since the beginning.

[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.497 	Loss: 1.8287[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.470 	Loss: 1.8319[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.470 	Loss: 1.8269[00m
[92m  Client0 Test => 	Acc: 12.341 	Loss: 3.5501[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 20.139 	Loss: 2.4102[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 30.035 	Loss: 2.1384[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.514 	Loss: 2.1277[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.427 	Loss: 2.1274[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.514 	Loss: 2.1194[00m
[92m  Client1 Test => 	Acc: 11.067 	Loss: 3.7953[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.448 	Loss: 2.2554[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.708 	Loss: 2.0857[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.274 	Loss: 2.3861[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.274 	Loss: 2.0860[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.361 	Loss: 2.0830[00m
[92m  Client2 Test => 	Acc: 12.936 	Loss: 3.5275[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 28.168 	Loss: 2.0920[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 33.030 	Loss: 1.9098[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 33.030 	Loss: 1.8952[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 33.116 	Loss: 1.9001[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 33.116 	Loss: 1.9023[00m
[92m  Client3 Test => 	Acc: 7.922 	Loss: 3.4433[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 13.770 	Loss: 2.5846[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 24.316 	Loss: 2.2753[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.098 	Loss: 2.2473[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 24.316 	Loss: 2.2361[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.805 	Loss: 2.2224[00m
[92m  Client4 Test => 	Acc: 5.590 	Loss: 3.6811[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 23.568 	Loss: 2.3613[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 33.724 	Loss: 1.9954[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 48.958 	Loss: 1.6270[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 55.729 	Loss: 1.3432[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 65.234 	Loss: 1.0788[00m
[92m  Client5 Test => 	Acc: 39.873 	Loss: 2.7870[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.500 	Loss: 2.1862[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 26.469 	Loss: 4.1801[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.156 	Loss: 2.1012[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 26.219 	Loss: 2.0784[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.281 	Loss: 2.0837[00m
[92m  Client6 Test => 	Acc: 11.047 	Loss: 3.1647[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 19.766 	Loss: 2.4035[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 28.203 	Loss: 2.1339[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 35.391 	Loss: 1.8643[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 45.234 	Loss: 1.5621[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 49.297 	Loss: 1.5067[00m
[92m  Client7 Test => 	Acc: 27.996 	Loss: 2.2845[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 12.891 	Loss: 2.7340[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 16.406 	Loss: 2.3494[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.995 	Loss: 2.0997[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.865 	Loss: 2.0208[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 36.589 	Loss: 1.8669[00m
[92m  Client8 Test => 	Acc: 14.858 	Loss: 3.7944[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 20.192 	Loss: 2.2613[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 42.308 	Loss: 1.6864[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 42.368 	Loss: 1.7908[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 65.625 	Loss: 1.0801[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 74.700 	Loss: 0.8385[00m
[92m  Client9 Test => 	Acc: 54.886 	Loss: 1.9227[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.929 	Loss: 2.6124[00m
 Train: Round   3, Avg Accuracy 41.937 | Avg Loss 1.753
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 33.270 	Loss: 1.9721[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.389 	Loss: 1.8395[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8299[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.416 	Loss: 1.8297[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.497 	Loss: 1.8299[00m
[92m  Client0 Test => 	Acc: 12.341 	Loss: 3.4134[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 21.007 	Loss: 2.4089[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.340 	Loss: 2.1508[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.774 	Loss: 2.1247[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.514 	Loss: 2.1155[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.774 	Loss: 2.1191[00m
[92m  Client1 Test => 	Acc: 11.074 	Loss: 3.5579[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.535 	Loss: 2.2056[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.361 	Loss: 2.0887[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.448 	Loss: 2.0779[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.361 	Loss: 2.0837[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.361 	Loss: 2.0772[00m
[92m  Client2 Test => 	Acc: 12.963 	Loss: 3.2842[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 30.078 	Loss: 2.0339[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 33.073 	Loss: 1.9055[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 32.986 	Loss: 1.9034[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 33.160 	Loss: 1.9027[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 33.464 	Loss: 1.8970[00m
[92m  Client3 Test => 	Acc: 7.929 	Loss: 3.5414[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 13.867 	Loss: 2.6118[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 25.586 	Loss: 2.2413[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 23.145 	Loss: 2.4061[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 24.609 	Loss: 2.2183[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.707 	Loss: 2.2115[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 4.0611[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 31.380 	Loss: 2.2952[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 49.870 	Loss: 1.6255[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 60.286 	Loss: 1.3974[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 56.641 	Loss: 1.3532[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 62.630 	Loss: 1.2004[00m
[92m  Client5 Test => 	Acc: 35.585 	Loss: 2.9079[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 29.344 	Loss: 2.1764[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 28.688 	Loss: 2.3126[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.062 	Loss: 22.6493[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 26.656 	Loss: 2.0833[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.250 	Loss: 2.0800[00m
[92m  Client6 Test => 	Acc: 12.362 	Loss: 3.2394[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 23.516 	Loss: 2.3088[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 27.969 	Loss: 2.1363[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.188 	Loss: 2.1847[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.109 	Loss: 2.1856[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.875 	Loss: 2.1861[00m
[92m  Client7 Test => 	Acc: 9.649 	Loss: 3.2978[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 16.536 	Loss: 2.6692[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 08:52:37] [setup] RAM Tracking...
[codecarbon INFO @ 08:52:37] [setup] CPU Tracking...
[codecarbon WARNING @ 08:52:37] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:52:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:52:39] [setup] GPU Tracking...
[codecarbon INFO @ 08:52:39] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:52:39] >>> Tracker's metadata:
[codecarbon INFO @ 08:52:39]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:52:39]   Python version: 3.12.7
[codecarbon INFO @ 08:52:39]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:52:39]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:52:39]   CPU count: 56
[codecarbon INFO @ 08:52:39]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:52:39]   GPU count: 2
[codecarbon INFO @ 08:52:39]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:52:42] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:52:43] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:52:43] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:52:43] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.594356722550875 W
[codecarbon INFO @ 08:52:43] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 08:53:38] [setup] RAM Tracking...
[codecarbon INFO @ 08:53:38] [setup] CPU Tracking...
[codecarbon WARNING @ 08:53:38] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:53:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:53:39] [setup] GPU Tracking...
[codecarbon INFO @ 08:53:39] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:53:39] >>> Tracker's metadata:
[codecarbon INFO @ 08:53:39]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:53:39]   Python version: 3.12.7
[codecarbon INFO @ 08:53:39]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:53:39]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:53:39]   CPU count: 56
[codecarbon INFO @ 08:53:39]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:53:39]   GPU count: 2
[codecarbon INFO @ 08:53:39]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:53:42] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:53:43] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:53:43] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:53:43] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.36847464133612 W
[codecarbon INFO @ 08:53:43] 0.000028 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 09:21:14] [setup] RAM Tracking...
[codecarbon INFO @ 09:21:14] [setup] CPU Tracking...
[codecarbon WARNING @ 09:21:14] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 09:21:15] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:21:15] [setup] GPU Tracking...
[codecarbon INFO @ 09:21:15] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 09:21:15] >>> Tracker's metadata:
[codecarbon INFO @ 09:21:15]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 09:21:15]   Python version: 3.12.7
[codecarbon INFO @ 09:21:15]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 09:21:15]   Available RAM : 126.630 GB
[codecarbon INFO @ 09:21:15]   CPU count: 56
[codecarbon INFO @ 09:21:15]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:21:15]   GPU count: 2
[codecarbon INFO @ 09:21:15]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 09:21:18] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 09:21:19] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 09:21:19] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 09:21:19] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.696762008127244 W
[codecarbon INFO @ 09:21:19] 0.000030 kWh of electricity used since the beginning.
[codecarbon INFO @ 09:22:14] [setup] RAM Tracking...
[codecarbon INFO @ 09:22:14] [setup] CPU Tracking...
[codecarbon WARNING @ 09:22:14] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 09:22:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:22:16] [setup] GPU Tracking...
[codecarbon INFO @ 09:22:16] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 09:22:16] >>> Tracker's metadata:
[codecarbon INFO @ 09:22:16]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 09:22:16]   Python version: 3.12.7
[codecarbon INFO @ 09:22:16]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 09:22:16]   Available RAM : 126.630 GB
[codecarbon INFO @ 09:22:16]   CPU count: 56
[codecarbon INFO @ 09:22:16]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:22:16]   GPU count: 2
[codecarbon INFO @ 09:22:16]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 09:22:19] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 09:22:19] Energy consumed for RAM : 0.000006 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 09:22:19] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 09:22:19] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 19.290027459972098 W
[codecarbon INFO @ 09:22:19] 0.000022 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 52.083 	Loss: 1.6889[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 33.984 	Loss: 2.0787[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 47.526 	Loss: 1.7072[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 51.823 	Loss: 1.6196[00m
[92m  Client8 Test => 	Acc: 17.639 	Loss: 3.0507[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 28.966 	Loss: 2.0826[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 51.743 	Loss: 1.5395[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 65.024 	Loss: 1.2032[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 76.202 	Loss: 0.8012[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 81.250 	Loss: 0.6031[00m
[92m  Client9 Test => 	Acc: 58.156 	Loss: 1.5919[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 13.463 	Loss: 2.5242[00m
 Train: Round   4, Avg Accuracy 41.663 | Avg Loss 1.782
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 36.207 	Loss: 1.9567[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.389 	Loss: 1.8331[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.524 	Loss: 1.8301[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.443 	Loss: 1.8289[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.443 	Loss: 1.8285[00m
[92m  Client0 Test => 	Acc: 12.348 	Loss: 3.4197[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 24.479 	Loss: 2.3603[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.861 	Loss: 2.1356[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 30.035 	Loss: 2.1132[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 30.122 	Loss: 2.1092[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.774 	Loss: 2.1138[00m
[92m  Client1 Test => 	Acc: 11.067 	Loss: 3.5608[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.274 	Loss: 2.2321[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.448 	Loss: 2.1050[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.361 	Loss: 2.0825[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.274 	Loss: 2.0858[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.274 	Loss: 2.0793[00m
[92m  Client2 Test => 	Acc: 12.915 	Loss: 3.2525[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 28.559 	Loss: 2.0536[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 31.771 	Loss: 1.9105[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 32.161 	Loss: 1.9525[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 33.464 	Loss: 1.8987[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 32.248 	Loss: 1.9050[00m
[92m  Client3 Test => 	Acc: 7.936 	Loss: 3.5330[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 11.816 	Loss: 2.5925[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 25.391 	Loss: 2.2449[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.098 	Loss: 2.2348[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 24.609 	Loss: 2.2657[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 25.000 	Loss: 2.2181[00m
[92m  Client4 Test => 	Acc: 5.590 	Loss: 3.7560[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 45.052 	Loss: 2.0896[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 54.036 	Loss: 1.4158[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 63.802 	Loss: 1.1257[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 68.229 	Loss: 0.9658[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 68.359 	Loss: 0.9482[00m
[92m  Client5 Test => 	Acc: 41.542 	Loss: 2.3880[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 56.812 	Loss: 1.5034[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 69.500 	Loss: 1.0722[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 80.500 	Loss: 0.6895[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 83.875 	Loss: 0.5945[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 85.344 	Loss: 0.5174[00m
[92m  Client6 Test => 	Acc: 65.253 	Loss: 1.4174[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 33.281 	Loss: 2.1525[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 48.047 	Loss: 1.5769[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 37.891 	Loss: 1.9872[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 33.594 	Loss: 2.0963[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.188 	Loss: 2.1514[00m
[92m  Client7 Test => 	Acc: 17.386 	Loss: 2.8855[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 19.661 	Loss: 2.5916[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 46.615 	Loss: 1.8092[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 58.724 	Loss: 1.2907[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 67.448 	Loss: 1.0076[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 75.781 	Loss: 0.7829[00m
[92m  Client8 Test => 	Acc: 35.925 	Loss: 2.7271[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 37.019 	Loss: 1.9419[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 63.281 	Loss: 1.1527[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 77.945 	Loss: 0.7574[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 79.327 	Loss: 0.6825[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 85.457 	Loss: 0.5015[00m
[92m  Client9 Test => 	Acc: 61.802 	Loss: 1.2963[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 33.552 	Loss: 2.1771[00m
 Train: Round   5, Avg Accuracy 50.987 | Avg Loss 1.505
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 35.048 	Loss: 1.9747[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.389 	Loss: 1.8317[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8366[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.281 	Loss: 1.8343[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.443 	Loss: 1.8262[00m
[92m  Client0 Test => 	Acc: 12.348 	Loss: 3.4155[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 24.219 	Loss: 2.3841[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 28.038 	Loss: 2.1502[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.427 	Loss: 2.1549[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.688 	Loss: 2.1378[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.688 	Loss: 2.1200[00m
[92m  Client1 Test => 	Acc: 11.074 	Loss: 3.5984[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.101 	Loss: 2.2125[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.448 	Loss: 2.0873[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.448 	Loss: 2.0820[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.448 	Loss: 2.0756[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.535 	Loss: 2.0717[00m
[92m  Client2 Test => 	Acc: 12.956 	Loss: 3.2811[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 30.859 	Loss: 2.0140[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 33.333 	Loss: 1.9132[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 32.031 	Loss: 5.1903[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 31.467 	Loss: 1.9064[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 33.290 	Loss: 1.9013[00m
[92m  Client3 Test => 	Acc: 7.936 	Loss: 3.5576[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.895 	Loss: 2.5862[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 23.535 	Loss: 2.2712[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 24.414 	Loss: 2.2274[00m
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 09:49:58] [setup] RAM Tracking...
[codecarbon INFO @ 09:49:58] [setup] CPU Tracking...
[codecarbon WARNING @ 09:49:58] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 09:50:00] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:50:00] [setup] GPU Tracking...
[codecarbon INFO @ 09:50:00] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 09:50:00] >>> Tracker's metadata:
[codecarbon INFO @ 09:50:00]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 09:50:00]   Python version: 3.12.7
[codecarbon INFO @ 09:50:00]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 09:50:00]   Available RAM : 126.630 GB
[codecarbon INFO @ 09:50:00]   CPU count: 56
[codecarbon INFO @ 09:50:00]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:50:00]   GPU count: 2
[codecarbon INFO @ 09:50:00]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 09:50:03] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 09:50:04] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 09:50:04] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 09:50:04] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.152332145742783 W
[codecarbon INFO @ 09:50:04] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 09:50:59] [setup] RAM Tracking...
[codecarbon INFO @ 09:50:59] [setup] CPU Tracking...
[codecarbon WARNING @ 09:50:59] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 09:51:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:51:01] [setup] GPU Tracking...
[codecarbon INFO @ 09:51:01] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 09:51:01] >>> Tracker's metadata:
[codecarbon INFO @ 09:51:01]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 09:51:01]   Python version: 3.12.7
[codecarbon INFO @ 09:51:01]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 09:51:01]   Available RAM : 126.630 GB
[codecarbon INFO @ 09:51:01]   CPU count: 56
[codecarbon INFO @ 09:51:01]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:51:01]   GPU count: 2
[codecarbon INFO @ 09:51:01]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 09:51:04] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 09:51:05] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 09:51:05] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 09:51:05] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.9678517087731 W
[codecarbon INFO @ 09:51:05] 0.000027 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 10:18:59] [setup] RAM Tracking...
[codecarbon INFO @ 10:18:59] [setup] CPU Tracking...
[codecarbon WARNING @ 10:18:59] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 10:19:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 10:19:01] [setup] GPU Tracking...
[codecarbon INFO @ 10:19:01] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 10:19:01] >>> Tracker's metadata:
[codecarbon INFO @ 10:19:01]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 10:19:01]   Python version: 3.12.7
[codecarbon INFO @ 10:19:01]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 10:19:01]   Available RAM : 126.630 GB
[codecarbon INFO @ 10:19:01]   CPU count: 56
[codecarbon INFO @ 10:19:01]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 10:19:01]   GPU count: 2
[codecarbon INFO @ 10:19:01]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 10:19:04] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 10:19:04] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 10:19:04] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 10:19:04] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.583934617708827 W
[codecarbon INFO @ 10:19:04] 0.000032 kWh of electricity used since the beginning.
[codecarbon INFO @ 10:20:00] [setup] RAM Tracking...
[codecarbon INFO @ 10:20:00] [setup] CPU Tracking...
[codecarbon WARNING @ 10:20:00] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 10:20:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 10:20:02] [setup] GPU Tracking...
[codecarbon INFO @ 10:20:02] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 10:20:02] >>> Tracker's metadata:
[codecarbon INFO @ 10:20:02]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 10:20:02]   Python version: 3.12.7
[codecarbon INFO @ 10:20:02]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 10:20:02]   Available RAM : 126.630 GB
[codecarbon INFO @ 10:20:02]   CPU count: 56
[codecarbon INFO @ 10:20:02]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 10:20:02]   GPU count: 2
[codecarbon INFO @ 10:20:02]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 10:20:05] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 10:20:05] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 10:20:05] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 10:20:05] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.403160038574786 W
[codecarbon INFO @ 10:20:05] 0.000028 kWh of electricity used since the beginning.
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 24.121 	Loss: 2.2261[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 25.293 	Loss: 2.2325[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 3.5272[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 57.422 	Loss: 1.6192[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 68.359 	Loss: 0.9837[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 73.177 	Loss: 0.7650[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 77.995 	Loss: 0.6247[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 78.125 	Loss: 0.6695[00m
[92m  Client5 Test => 	Acc: 48.389 	Loss: 2.8431[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 63.188 	Loss: 1.2844[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 77.438 	Loss: 0.7726[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 81.812 	Loss: 0.6246[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 87.312 	Loss: 0.4545[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 88.125 	Loss: 0.4131[00m
[92m  Client6 Test => 	Acc: 64.278 	Loss: 1.1362[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 40.938 	Loss: 1.9310[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 58.047 	Loss: 1.2920[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 57.031 	Loss: 1.4041[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 61.406 	Loss: 1.1447[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 66.953 	Loss: 1.0078[00m
[92m  Client7 Test => 	Acc: 53.763 	Loss: 1.9858[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 35.286 	Loss: 2.2036[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 59.245 	Loss: 1.3629[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 74.479 	Loss: 0.9051[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 80.859 	Loss: 0.6325[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 81.120 	Loss: 0.6363[00m
[92m  Client8 Test => 	Acc: 40.609 	Loss: 2.2568[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 57.091 	Loss: 1.5407[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 71.034 	Loss: 0.9854[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 78.906 	Loss: 0.6760[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 82.151 	Loss: 0.5827[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 87.139 	Loss: 0.4465[00m
[92m  Client9 Test => 	Acc: 60.762 	Loss: 1.3753[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 18.478 	Loss: 2.3007[00m
 Train: Round   6, Avg Accuracy 57.071 | Avg Loss 1.332
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 35.426 	Loss: 1.9483[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.389 	Loss: 1.8370[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.335 	Loss: 1.8297[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.470 	Loss: 1.8269[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.443 	Loss: 1.8289[00m
[92m  Client0 Test => 	Acc: 12.321 	Loss: 3.3862[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 27.691 	Loss: 2.3322[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.861 	Loss: 2.1280[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 30.035 	Loss: 2.1149[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.688 	Loss: 2.1375[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.774 	Loss: 2.1194[00m
[92m  Client1 Test => 	Acc: 11.074 	Loss: 3.6971[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.622 	Loss: 2.1940[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.448 	Loss: 2.0942[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.448 	Loss: 2.0829[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.188 	Loss: 2.0779[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.535 	Loss: 2.0751[00m
[92m  Client2 Test => 	Acc: 12.956 	Loss: 3.3016[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 27.778 	Loss: 2.0284[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 30.295 	Loss: 1.9262[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 32.986 	Loss: 1.9025[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 32.986 	Loss: 1.9058[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 32.899 	Loss: 1.8997[00m
[92m  Client3 Test => 	Acc: 7.929 	Loss: 4.6072[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 20.215 	Loss: 2.5517[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 19.824 	Loss: 2.2877[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 24.609 	Loss: 2.2754[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 23.438 	Loss: 2.2386[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.902 	Loss: 2.2146[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 3.7950[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 51.042 	Loss: 1.7271[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 63.672 	Loss: 1.1242[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 70.833 	Loss: 0.8866[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 74.089 	Loss: 0.8123[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 76.172 	Loss: 0.6678[00m
[92m  Client5 Test => 	Acc: 49.217 	Loss: 2.3414[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 65.219 	Loss: 1.1932[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 79.281 	Loss: 0.7113[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 84.438 	Loss: 0.5519[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 86.469 	Loss: 0.4694[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 88.656 	Loss: 0.4242[00m
[92m  Client6 Test => 	Acc: 65.445 	Loss: 1.2694[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 41.328 	Loss: 1.8887[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 65.547 	Loss: 1.0569[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 72.891 	Loss: 0.7916[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 75.703 	Loss: 0.7713[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 79.219 	Loss: 0.6350[00m
[92m  Client7 Test => 	Acc: 59.285 	Loss: 1.5636[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 31.510 	Loss: 2.2620[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 66.927 	Loss: 1.2406[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 77.865 	Loss: 0.7320[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 83.724 	Loss: 0.5541[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 85.547 	Loss: 0.4640[00m
[92m  Client8 Test => 	Acc: 51.968 	Loss: 1.9697[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 60.036 	Loss: 1.3305[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 79.627 	Loss: 0.7122[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 79.147 	Loss: 0.7057[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 87.019 	Loss: 0.4436[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 82.332 	Loss: 0.5951[00m
[92m  Client9 Test => 	Acc: 58.859 	Loss: 1.6361[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 54.629 	Loss: 1.7342[00m
 Train: Round   7, Avg Accuracy 58.048 | Avg Loss 1.292
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 36.773 	Loss: 1.9311[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 35.102 	Loss: 3.4258[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.039 	Loss: 1.8583[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.389 	Loss: 1.8280[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.039 	Loss: 1.8314[00m
[92m  Client0 Test => 	Acc: 12.362 	Loss: 3.4051[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 10:47:52] [setup] RAM Tracking...
[codecarbon INFO @ 10:47:52] [setup] CPU Tracking...
[codecarbon WARNING @ 10:47:52] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 10:47:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 10:47:54] [setup] GPU Tracking...
[codecarbon INFO @ 10:47:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 10:47:54] >>> Tracker's metadata:
[codecarbon INFO @ 10:47:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 10:47:54]   Python version: 3.12.7
[codecarbon INFO @ 10:47:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 10:47:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 10:47:54]   CPU count: 56
[codecarbon INFO @ 10:47:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 10:47:54]   GPU count: 2
[codecarbon INFO @ 10:47:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 10:47:57] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 10:47:58] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 10:47:58] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 10:47:58] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.62333864969844 W
[codecarbon INFO @ 10:47:58] 0.000038 kWh of electricity used since the beginning.
[codecarbon INFO @ 10:48:53] [setup] RAM Tracking...
[codecarbon INFO @ 10:48:53] [setup] CPU Tracking...
[codecarbon WARNING @ 10:48:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 10:48:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 10:48:55] [setup] GPU Tracking...
[codecarbon INFO @ 10:48:55] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 10:48:55] >>> Tracker's metadata:
[codecarbon INFO @ 10:48:55]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 10:48:55]   Python version: 3.12.7
[codecarbon INFO @ 10:48:55]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 10:48:55]   Available RAM : 126.630 GB
[codecarbon INFO @ 10:48:55]   CPU count: 56
[codecarbon INFO @ 10:48:55]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 10:48:55]   GPU count: 2
[codecarbon INFO @ 10:48:55]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 10:48:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 10:48:59] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 10:48:59] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 10:48:59] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 15.330689831568119 W
[codecarbon INFO @ 10:48:59] 0.000023 kWh of electricity used since the beginning.

[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 25.260 	Loss: 2.3402[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.948 	Loss: 2.1508[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.861 	Loss: 2.1275[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.948 	Loss: 2.1092[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 30.122 	Loss: 2.1137[00m
[92m  Client1 Test => 	Acc: 11.081 	Loss: 3.6082[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 41.059 	Loss: 2.2120[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.274 	Loss: 2.1233[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 39.149 	Loss: 2.2383[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.014 	Loss: 2.1009[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.361 	Loss: 2.0757[00m
[92m  Client2 Test => 	Acc: 12.949 	Loss: 3.3912[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 26.215 	Loss: 2.0726[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 32.161 	Loss: 12.8759[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 31.076 	Loss: 1.9139[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 33.247 	Loss: 1.8981[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 32.118 	Loss: 1.9001[00m
[92m  Client3 Test => 	Acc: 7.942 	Loss: 3.4414[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 13.770 	Loss: 2.6711[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 20.996 	Loss: 2.2729[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 23.340 	Loss: 2.3117[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 23.633 	Loss: 2.2450[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 25.000 	Loss: 2.2087[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 3.7489[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 65.234 	Loss: 1.2145[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 77.865 	Loss: 0.6490[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 79.818 	Loss: 0.6540[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 82.292 	Loss: 0.5297[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 84.115 	Loss: 0.4468[00m
[92m  Client5 Test => 	Acc: 56.063 	Loss: 2.2069[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 74.000 	Loss: 0.9193[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 83.375 	Loss: 0.5793[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 85.969 	Loss: 0.4986[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 89.438 	Loss: 0.3597[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 89.438 	Loss: 0.3774[00m
[92m  Client6 Test => 	Acc: 68.947 	Loss: 1.1433[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 56.797 	Loss: 1.3791[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 71.250 	Loss: 0.9087[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 77.031 	Loss: 0.6872[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 78.047 	Loss: 0.6751[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 74.062 	Loss: 0.7928[00m
[92m  Client7 Test => 	Acc: 57.983 	Loss: 1.4690[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 48.177 	Loss: 1.7648[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 79.818 	Loss: 0.7669[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 78.385 	Loss: 0.7358[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 83.724 	Loss: 0.6203[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 84.896 	Loss: 0.4881[00m
[92m  Client8 Test => 	Acc: 52.487 	Loss: 1.7587[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 74.880 	Loss: 0.9712[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 83.113 	Loss: 0.5682[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 87.079 	Loss: 0.4552[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 80.349 	Loss: 0.6409[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 84.976 	Loss: 0.4906[00m
[92m  Client9 Test => 	Acc: 62.204 	Loss: 1.4982[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 48.469 	Loss: 1.8907[00m
 Train: Round   8, Avg Accuracy 58.513 | Avg Loss 1.273
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 34.375 	Loss: 2.0277[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.470 	Loss: 1.8308[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8279[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.416 	Loss: 1.8273[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.416 	Loss: 1.8276[00m
[92m  Client0 Test => 	Acc: 12.362 	Loss: 3.5214[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 25.347 	Loss: 2.3911[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.601 	Loss: 2.1336[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.601 	Loss: 2.1300[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 30.035 	Loss: 2.1199[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.688 	Loss: 2.1091[00m
[92m  Client1 Test => 	Acc: 11.061 	Loss: 3.4138[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.448 	Loss: 2.2215[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.535 	Loss: 2.0966[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.535 	Loss: 2.0797[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.622 	Loss: 2.0766[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.361 	Loss: 2.0812[00m
[92m  Client2 Test => 	Acc: 12.956 	Loss: 3.2848[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 29.688 	Loss: 2.0096[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 32.161 	Loss: 1.8995[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 33.290 	Loss: 1.9050[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 33.030 	Loss: 1.8926[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 33.030 	Loss: 1.9050[00m
[92m  Client3 Test => 	Acc: 7.949 	Loss: 3.3875[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 13.477 	Loss: 2.5853[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 24.902 	Loss: 2.2474[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 24.219 	Loss: 2.2154[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 24.512 	Loss: 2.2225[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 25.195 	Loss: 2.2037[00m
[92m  Client4 Test => 	Acc: 5.584 	Loss: 3.7581[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 68.750 	Loss: 1.2101[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 77.474 	Loss: 0.7181[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 81.641 	Loss: 0.5511[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 83.594 	Loss: 0.4898[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 86.068 	Loss: 0.3881[00m
[92m  Client5 Test => 	Acc: 63.364 	Loss: 1.8898[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 73.062 	Loss: 0.9115[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 83.312 	Loss: 0.5582[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 87.781 	Loss: 0.4143[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 89.156 	Loss: 0.3712[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 90.562 	Loss: 0.3328[00m
[92m  Client6 Test => 	Acc: 69.560 	Loss: 1.2863[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 56.406 	Loss: 1.3903[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 70.469 	Loss: 0.9164[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 76.406 	Loss: 0.7209[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 77.344 	Loss: 0.7428[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 77.656 	Loss: 0.6570[00m
[92m  Client7 Test => 	Acc: 59.813 	Loss: 1.6463[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 54.036 	Loss: 1.5652[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 76.693 	Loss: 0.8281[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 81.380 	Loss: 0.5896[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 87.240 	Loss: 0.4335[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 11:16:43] [setup] RAM Tracking...
[codecarbon INFO @ 11:16:43] [setup] CPU Tracking...
[codecarbon WARNING @ 11:16:43] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 11:16:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 11:16:45] [setup] GPU Tracking...
[codecarbon INFO @ 11:16:45] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 11:16:45] >>> Tracker's metadata:
[codecarbon INFO @ 11:16:45]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 11:16:45]   Python version: 3.12.7
[codecarbon INFO @ 11:16:45]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 11:16:45]   Available RAM : 126.630 GB
[codecarbon INFO @ 11:16:45]   CPU count: 56
[codecarbon INFO @ 11:16:45]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 11:16:45]   GPU count: 2
[codecarbon INFO @ 11:16:45]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 11:16:48] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 11:16:48] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 11:16:48] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 11:16:48] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.23124388462262 W
[codecarbon INFO @ 11:16:48] 0.000030 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 88.542 	Loss: 0.3828[00m
[92m  Client8 Test => 	Acc: 53.767 	Loss: 1.8467[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 73.558 	Loss: 0.9524[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 85.096 	Loss: 0.5116[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 87.740 	Loss: 0.4060[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 89.904 	Loss: 0.3564[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 90.144 	Loss: 0.3390[00m
[92m  Client9 Test => 	Acc: 66.153 	Loss: 1.3085[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 48.627 	Loss: 1.8431[00m
 Train: Round   9, Avg Accuracy 60.166 | Avg Loss 1.223
Training and Evaluation completed!
===== END Sun 12/28/2025 11:17:50.62 ===== 
