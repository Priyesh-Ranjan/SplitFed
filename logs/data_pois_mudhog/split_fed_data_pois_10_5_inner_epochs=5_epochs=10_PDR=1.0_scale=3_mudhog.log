===== START Thu 01/15/2026  2:10:19.32 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 02:10:51] [setup] RAM Tracking...
[codecarbon INFO @ 02:10:51] [setup] CPU Tracking...
[codecarbon WARNING @ 02:10:51] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:10:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:10:53] [setup] GPU Tracking...
[codecarbon INFO @ 02:10:53] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:10:53] >>> Tracker's metadata:
[codecarbon INFO @ 02:10:53]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:10:53]   Python version: 3.12.7
[codecarbon INFO @ 02:10:53]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:10:53]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:10:53]   CPU count: 56
[codecarbon INFO @ 02:10:53]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:10:53]   GPU count: 2
[codecarbon INFO @ 02:10:53]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:10:56] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:10:58] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:10:58] Energy consumed for all CPUs : 0.000042 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:10:58] Energy consumed for all GPUs : 0.000008 kWh. Total GPU Power : 20.687584366571436 W
[codecarbon INFO @ 02:10:58] 0.000069 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:38:14] [setup] RAM Tracking...
[codecarbon INFO @ 02:38:14] [setup] CPU Tracking...
[codecarbon WARNING @ 02:38:14] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:38:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:38:16] [setup] GPU Tracking...
[codecarbon INFO @ 02:38:16] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:38:16] >>> Tracker's metadata:
[codecarbon INFO @ 02:38:16]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:38:16]   Python version: 3.12.7
[codecarbon INFO @ 02:38:16]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:38:16]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:38:16]   CPU count: 56
[codecarbon INFO @ 02:38:16]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:38:16]   GPU count: 2
[codecarbon INFO @ 02:38:16]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:38:19] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:38:20] Energy consumed for RAM : 0.000015 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:38:20] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:38:20] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 15.56462090705476 W
[codecarbon INFO @ 02:38:20] 0.000051 kWh of electricity used since the beginning.
[codecarbon INFO @ 02:39:16] [setup] RAM Tracking...
[codecarbon INFO @ 02:39:16] [setup] CPU Tracking...
[codecarbon WARNING @ 02:39:16] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:39:17] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:39:17] [setup] GPU Tracking...
[codecarbon INFO @ 02:39:17] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:39:17] >>> Tracker's metadata:
[codecarbon INFO @ 02:39:17]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:39:17]   Python version: 3.12.7
[codecarbon INFO @ 02:39:17]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:39:17]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:39:17]   CPU count: 56
[codecarbon INFO @ 02:39:17]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:39:17]   GPU count: 2
[codecarbon INFO @ 02:39:17]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:39:20] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:39:21] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:39:21] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:39:21] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.406557435442934 W
[codecarbon INFO @ 02:39:21] 0.000038 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 3                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: mudhog              #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: data_poisoning 10,5 #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_data_pois_10_5_inner_epochs=5_epochs=10_PDR=1.0_scale=3_mudhog#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_data_pois_10_5_inner_epochs=5_epochs=10_PDR=1.0_scale=3_mudhog----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 29.768 	Loss: 2.9637[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 36.584 	Loss: 1.9059[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.497 	Loss: 1.8631[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 37.769 	Loss: 1.8615[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.200 	Loss: 1.8555[00m
[92m  Client0 Test => 	Acc: 12.335 	Loss: 2.9662[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 19.705 	Loss: 4.7098[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 21.354 	Loss: 2.3620[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 25.955 	Loss: 2.3221[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 27.604 	Loss: 2.1843[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.167 	Loss: 2.1627[00m
[92m  Client1 Test => 	Acc: 4.893 	Loss: 3.0289[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 20.747 	Loss: 5.8241[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 21.875 	Loss: 2.8118[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 32.639 	Loss: 2.4041[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.274 	Loss: 2.1423[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 41.927 	Loss: 2.1293[00m
[92m  Client2 Test => 	Acc: 12.983 	Loss: 3.1516[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 24.913 	Loss: 4.1920[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 32.422 	Loss: 1.9702[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 59.766 	Loss: 1.5107[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 70.009 	Loss: 1.0524[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 72.309 	Loss: 0.9613[00m
[92m  Client3 Test => 	Acc: 30.897 	Loss: 2.5933[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 19.629 	Loss: 2.9953[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 20.020 	Loss: 2.6391[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 24.805 	Loss: 2.4257[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 19.141 	Loss: 2.3113[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 41.406 	Loss: 1.8539[00m
[92m  Client4 Test => 	Acc: 17.211 	Loss: 4.1518[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 22.396 	Loss: 11.4061[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 27.865 	Loss: 2.1747[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.729 	Loss: 2.1001[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 36.328 	Loss: 1.9544[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 47.005 	Loss: 1.7164[00m
[92m  Client5 Test => 	Acc: 24.384 	Loss: 3.8224[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 29.406 	Loss: 2.5505[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 50.938 	Loss: 1.6173[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 63.719 	Loss: 1.2328[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 70.156 	Loss: 0.9517[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 73.125 	Loss: 0.8460[00m
[92m  Client6 Test => 	Acc: 50.258 	Loss: 2.0197[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 17.500 	Loss: 3.2581[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.578 	Loss: 2.3050[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 24.062 	Loss: 2.3072[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 25.547 	Loss: 2.1509[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 28.125 	Loss: 2.1486[00m
[92m  Client7 Test => 	Acc: 9.964 	Loss: 3.5199[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 20.312 	Loss: 5.1166[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 15.495 	Loss: 2.6892[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 26.562 	Loss: 2.2223[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 25.651 	Loss: 2.2053[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 22.396 	Loss: 2.1820[00m
[92m  Client8 Test => 	Acc: 7.341 	Loss: 3.6929[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.334 	Loss: 4.6485[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 29.147 	Loss: 2.1317[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 43.209 	Loss: 1.8236[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 53.065 	Loss: 1.4360[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 65.024 	Loss: 1.1747[00m
[92m  Client9 Test => 	Acc: 41.409 	Loss: 2.2700[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.949 	Loss: 2.7270[00m
 Train: Round   0, Avg Accuracy 45.868 | Avg Loss 1.703
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 33.809 	Loss: 1.9708[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.362 	Loss: 1.8345[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8316[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.470 	Loss: 1.8286[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.524 	Loss: 1.8292[00m
[92m  Client0 Test => 	Acc: 12.355 	Loss: 3.6689[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 23.698 	Loss: 2.3669[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 21.181 	Loss: 2.2924[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.948 	Loss: 2.1722[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 30.035 	Loss: 2.1282[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.514 	Loss: 2.1206[00m
[92m  Client1 Test => 	Acc: 11.061 	Loss: 3.5126[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.448 	Loss: 2.8181[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.448 	Loss: 2.2248[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.274 	Loss: 2.7081[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.188 	Loss: 2.1387[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.274 	Loss: 2.0940[00m
[92m  Client2 Test => 	Acc: 12.983 	Loss: 3.3190[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 30.599 	Loss: 2.0419[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 34.201 	Loss: 1.9023[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 51.128 	Loss: 1.5526[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 58.550 	Loss: 1.4026[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 64.019 	Loss: 1.2836[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 03:06:43] [setup] RAM Tracking...
[codecarbon INFO @ 03:06:43] [setup] CPU Tracking...
[codecarbon WARNING @ 03:06:43] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:06:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:06:45] [setup] GPU Tracking...
[codecarbon INFO @ 03:06:45] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:06:45] >>> Tracker's metadata:
[codecarbon INFO @ 03:06:45]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:06:45]   Python version: 3.12.7
[codecarbon INFO @ 03:06:45]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:06:45]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:06:45]   CPU count: 56
[codecarbon INFO @ 03:06:45]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:06:45]   GPU count: 2
[codecarbon INFO @ 03:06:45]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:06:48] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:06:49] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:06:49] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:06:49] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.299650778603997 W
[codecarbon INFO @ 03:06:49] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 03:07:45] [setup] RAM Tracking...
[codecarbon INFO @ 03:07:45] [setup] CPU Tracking...
[codecarbon WARNING @ 03:07:45] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:07:46] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:07:46] [setup] GPU Tracking...
[codecarbon INFO @ 03:07:46] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:07:46] >>> Tracker's metadata:
[codecarbon INFO @ 03:07:46]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:07:46]   Python version: 3.12.7
[codecarbon INFO @ 03:07:46]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:07:46]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:07:46]   CPU count: 56
[codecarbon INFO @ 03:07:46]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:07:46]   GPU count: 2
[codecarbon INFO @ 03:07:46]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:07:49] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:07:50] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:07:50] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:07:50] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.664971136370475 W
[codecarbon INFO @ 03:07:50] 0.000033 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 03:35:06] [setup] RAM Tracking...
[codecarbon INFO @ 03:35:06] [setup] CPU Tracking...
[codecarbon WARNING @ 03:35:06] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:35:08] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:35:08] [setup] GPU Tracking...
[codecarbon INFO @ 03:35:08] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:35:08] >>> Tracker's metadata:
[codecarbon INFO @ 03:35:08]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:35:08]   Python version: 3.12.7
[codecarbon INFO @ 03:35:08]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:35:08]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:35:08]   CPU count: 56
[codecarbon INFO @ 03:35:08]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:35:08]   GPU count: 2
[codecarbon INFO @ 03:35:08]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:35:11] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:35:12] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:35:12] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:35:12] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 14.874777497931973 W
[codecarbon INFO @ 03:35:12] 0.000034 kWh of electricity used since the beginning.
[codecarbon INFO @ 03:36:08] [setup] RAM Tracking...
[codecarbon INFO @ 03:36:08] [setup] CPU Tracking...
[codecarbon WARNING @ 03:36:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:36:09] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:36:09] [setup] GPU Tracking...
[codecarbon INFO @ 03:36:09] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:36:10] >>> Tracker's metadata:
[codecarbon INFO @ 03:36:10]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:36:10]   Python version: 3.12.7
[codecarbon INFO @ 03:36:10]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:36:10]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:36:10]   CPU count: 56
[codecarbon INFO @ 03:36:10]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:36:10]   GPU count: 2
[codecarbon INFO @ 03:36:10]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:36:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:36:13] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:36:13] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:36:13] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.998988863312483 W
[codecarbon INFO @ 03:36:13] 0.000029 kWh of electricity used since the beginning.

[92m  Client3 Test => 	Acc: 26.561 	Loss: 3.0608[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.602 	Loss: 2.4237[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 43.359 	Loss: 1.8085[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 57.129 	Loss: 1.2921[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 56.641 	Loss: 1.2662[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 65.723 	Loss: 1.0299[00m
[92m  Client4 Test => 	Acc: 39.686 	Loss: 3.1638[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 18.880 	Loss: 2.4637[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 31.771 	Loss: 2.1426[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.469 	Loss: 2.0307[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 30.339 	Loss: 2.0258[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 29.948 	Loss: 1.9947[00m
[92m  Client5 Test => 	Acc: 12.355 	Loss: 3.5361[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.969 	Loss: 2.1729[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 26.562 	Loss: 2.0848[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.031 	Loss: 2.0829[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.969 	Loss: 2.0827[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.656 	Loss: 2.0867[00m
[92m  Client6 Test => 	Acc: 12.335 	Loss: 3.1710[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.938 	Loss: 2.4314[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.641 	Loss: 2.2105[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.641 	Loss: 2.1842[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.406 	Loss: 2.2332[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 29.766 	Loss: 2.1471[00m
[92m  Client7 Test => 	Acc: 12.499 	Loss: 3.5065[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 15.755 	Loss: 2.5079[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 24.479 	Loss: 2.1584[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.474 	Loss: 2.1254[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 23.177 	Loss: 2.1103[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.474 	Loss: 2.0995[00m
[92m  Client8 Test => 	Acc: 4.093 	Loss: 4.1869[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 20.913 	Loss: 2.3069[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 24.579 	Loss: 2.1066[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 29.387 	Loss: 2.0877[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.240 	Loss: 2.1599[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 28.245 	Loss: 2.0197[00m
[92m  Client9 Test => 	Acc: 15.037 	Loss: 3.4609[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.942 	Loss: 2.6079[00m
 Train: Round   1, Avg Accuracy 38.114 | Avg Loss 1.871
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 36.773 	Loss: 2.0277[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.416 	Loss: 1.8693[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.200 	Loss: 1.8355[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.470 	Loss: 1.8330[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.416 	Loss: 1.8311[00m
[92m  Client0 Test => 	Acc: 12.328 	Loss: 3.4420[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 24.132 	Loss: 2.3574[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 30.208 	Loss: 2.1188[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 30.035 	Loss: 2.1205[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 30.035 	Loss: 2.1119[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.080 	Loss: 2.1180[00m
[92m  Client1 Test => 	Acc: 11.040 	Loss: 3.6414[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.274 	Loss: 2.3140[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.535 	Loss: 2.0880[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.188 	Loss: 2.0934[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.448 	Loss: 2.0749[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.448 	Loss: 2.0719[00m
[92m  Client2 Test => 	Acc: 12.949 	Loss: 3.3382[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 32.595 	Loss: 2.0292[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 32.639 	Loss: 2.1124[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 47.917 	Loss: 1.7109[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 57.552 	Loss: 1.4769[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 64.410 	Loss: 1.2818[00m
[92m  Client3 Test => 	Acc: 23.378 	Loss: 2.7695[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 13.867 	Loss: 2.6352[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 34.277 	Loss: 1.9672[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 53.711 	Loss: 1.4732[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 49.609 	Loss: 1.3923[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 55.859 	Loss: 1.2646[00m
[92m  Client4 Test => 	Acc: 33.280 	Loss: 3.1017[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 21.224 	Loss: 2.3686[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 30.599 	Loss: 2.0921[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 35.417 	Loss: 1.9512[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 46.745 	Loss: 1.7045[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 57.292 	Loss: 1.3899[00m
[92m  Client5 Test => 	Acc: 29.037 	Loss: 3.0577[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 24.844 	Loss: 2.1558[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.375 	Loss: 2.0823[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.469 	Loss: 2.0795[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.875 	Loss: 2.0805[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.750 	Loss: 2.0819[00m
[92m  Client6 Test => 	Acc: 12.355 	Loss: 3.3399[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 22.578 	Loss: 2.3913[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.797 	Loss: 2.2054[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.875 	Loss: 2.1778[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.875 	Loss: 2.1802[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.797 	Loss: 2.1779[00m
[92m  Client7 Test => 	Acc: 9.669 	Loss: 3.4104[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 13.281 	Loss: 2.6912[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 21.745 	Loss: 2.2932[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 28.385 	Loss: 2.1295[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 32.682 	Loss: 2.0498[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 48.698 	Loss: 1.8684[00m
[92m  Client8 Test => 	Acc: 9.659 	Loss: 3.2429[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 23.678 	Loss: 2.2064[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 37.740 	Loss: 1.8121[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 46.875 	Loss: 1.5726[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 62.620 	Loss: 1.2234[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 69.591 	Loss: 1.0532[00m
[92m  Client9 Test => 	Acc: 50.398 	Loss: 1.8796[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.949 	Loss: 2.6268[00m
 Train: Round   2, Avg Accuracy 45.834 | Avg Loss 1.714
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 31.600 	Loss: 3.5715[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 31.735 	Loss: 2.4005[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 04:03:39] [setup] RAM Tracking...
[codecarbon INFO @ 04:03:39] [setup] CPU Tracking...
[codecarbon WARNING @ 04:03:39] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:03:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:03:41] [setup] GPU Tracking...
[codecarbon INFO @ 04:03:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:03:41] >>> Tracker's metadata:
[codecarbon INFO @ 04:03:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:03:41]   Python version: 3.12.7
[codecarbon INFO @ 04:03:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:03:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:03:41]   CPU count: 56
[codecarbon INFO @ 04:03:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:03:41]   GPU count: 2
[codecarbon INFO @ 04:03:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:03:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:03:45] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:03:45] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:03:45] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.372342030003466 W
[codecarbon INFO @ 04:03:45] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 04:04:43] [setup] RAM Tracking...
[codecarbon INFO @ 04:04:43] [setup] CPU Tracking...
[codecarbon WARNING @ 04:04:43] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:04:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:04:45] [setup] GPU Tracking...
[codecarbon INFO @ 04:04:45] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:04:45] >>> Tracker's metadata:
[codecarbon INFO @ 04:04:45]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:04:45]   Python version: 3.12.7
[codecarbon INFO @ 04:04:45]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:04:45]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:04:45]   CPU count: 56
[codecarbon INFO @ 04:04:45]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:04:45]   GPU count: 2
[codecarbon INFO @ 04:04:45]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:04:48] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:04:48] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:04:48] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:04:48] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 25.455966631390023 W
[codecarbon INFO @ 04:04:48] 0.000032 kWh of electricity used since the beginning.

[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 37.716 	Loss: 1.8356[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.443 	Loss: 1.8364[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.497 	Loss: 1.8358[00m
[92m  Client0 Test => 	Acc: 12.375 	Loss: 3.4413[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 20.312 	Loss: 2.3863[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.861 	Loss: 2.1339[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.688 	Loss: 2.1162[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.948 	Loss: 2.1051[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.861 	Loss: 2.1174[00m
[92m  Client1 Test => 	Acc: 11.061 	Loss: 3.7171[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.361 	Loss: 2.2466[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.361 	Loss: 2.1023[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.622 	Loss: 2.0838[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 41.753 	Loss: 2.0936[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 41.840 	Loss: 2.0892[00m
[92m  Client2 Test => 	Acc: 12.942 	Loss: 3.2912[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 39.323 	Loss: 1.9481[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 63.759 	Loss: 1.3134[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 70.964 	Loss: 1.0634[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 75.260 	Loss: 0.8801[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 77.908 	Loss: 0.7665[00m
[92m  Client3 Test => 	Acc: 40.410 	Loss: 2.2610[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 13.477 	Loss: 2.4148[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 39.941 	Loss: 1.7708[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 45.312 	Loss: 1.5644[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 57.422 	Loss: 1.3154[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 57.129 	Loss: 1.3503[00m
[92m  Client4 Test => 	Acc: 28.370 	Loss: 3.1912[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 18.750 	Loss: 2.4134[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 43.880 	Loss: 1.8707[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 54.167 	Loss: 1.4449[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 62.370 	Loss: 1.2731[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 65.495 	Loss: 1.0880[00m
[92m  Client5 Test => 	Acc: 37.333 	Loss: 2.6598[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.875 	Loss: 2.7032[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.500 	Loss: 2.3668[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.656 	Loss: 2.4718[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.875 	Loss: 2.0857[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 24.875 	Loss: 2.0833[00m
[92m  Client6 Test => 	Acc: 11.067 	Loss: 3.1806[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 26.406 	Loss: 2.3049[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 31.953 	Loss: 2.0491[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 38.750 	Loss: 1.9117[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 35.859 	Loss: 1.9355[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 31.641 	Loss: 1.9367[00m
[92m  Client7 Test => 	Acc: 25.105 	Loss: 3.1592[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 13.932 	Loss: 2.6625[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 37.891 	Loss: 2.1012[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 39.193 	Loss: 1.8247[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 43.750 	Loss: 1.8145[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 41.536 	Loss: 3.1063[00m
[92m  Client8 Test => 	Acc: 10.807 	Loss: 3.5454[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.214 	Loss: 2.1424[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 35.998 	Loss: 1.7685[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 43.089 	Loss: 1.7024[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 45.733 	Loss: 1.6168[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 46.935 	Loss: 1.5978[00m
[92m  Client9 Test => 	Acc: 33.418 	Loss: 2.7340[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 19.394 	Loss: 2.5159[00m
 Train: Round   3, Avg Accuracy 45.572 | Avg Loss 1.797
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 29.364 	Loss: 3.9669[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 25.162 	Loss: 3.6786[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 26.724 	Loss: 3.8902[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 37.473 	Loss: 1.9057[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.524 	Loss: 1.8546[00m
[92m  Client0 Test => 	Acc: 12.375 	Loss: 3.6698[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 24.045 	Loss: 2.4355[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.601 	Loss: 2.1721[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.688 	Loss: 2.1286[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.688 	Loss: 2.1298[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.774 	Loss: 2.1266[00m
[92m  Client1 Test => 	Acc: 11.054 	Loss: 3.7534[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 38.455 	Loss: 2.2931[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.448 	Loss: 2.0854[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.361 	Loss: 2.0818[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.448 	Loss: 2.0730[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.535 	Loss: 2.0749[00m
[92m  Client2 Test => 	Acc: 12.942 	Loss: 3.1692[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 56.858 	Loss: 1.5052[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 72.656 	Loss: 0.9809[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 76.693 	Loss: 0.7956[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 78.646 	Loss: 0.7103[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 83.377 	Loss: 0.5639[00m
[92m  Client3 Test => 	Acc: 54.935 	Loss: 1.8026[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 29.395 	Loss: 2.0842[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 49.414 	Loss: 1.4730[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 60.156 	Loss: 1.1926[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 63.281 	Loss: 1.1118[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 68.652 	Loss: 0.9569[00m
[92m  Client4 Test => 	Acc: 35.513 	Loss: 3.1369[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 43.490 	Loss: 2.1967[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 46.484 	Loss: 1.7646[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 51.432 	Loss: 1.4929[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 53.255 	Loss: 1.3934[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 57.422 	Loss: 1.2309[00m
[92m  Client5 Test => 	Acc: 31.008 	Loss: 2.7335[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 40.188 	Loss: 1.9344[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 60.312 	Loss: 1.2984[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 71.031 	Loss: 0.9580[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 79.219 	Loss: 0.6612[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 84.156 	Loss: 0.5422[00m
[92m  Client6 Test => 	Acc: 60.939 	Loss: 1.5711[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 33.594 	Loss: 2.2225[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 35.156 	Loss: 1.8728[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 44.453 	Loss: 1.7530[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 43.984 	Loss: 1.7236[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 47.891 	Loss: 1.6692[00m
[92m  Client7 Test => 	Acc: 28.879 	Loss: 2.7164[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 24.089 	Loss: 2.4844[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 04:32:01] [setup] RAM Tracking...
[codecarbon INFO @ 04:32:01] [setup] CPU Tracking...
[codecarbon WARNING @ 04:32:01] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:32:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:32:02] [setup] GPU Tracking...
[codecarbon INFO @ 04:32:02] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:32:02] >>> Tracker's metadata:
[codecarbon INFO @ 04:32:02]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:32:02]   Python version: 3.12.7
[codecarbon INFO @ 04:32:02]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:32:02]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:32:02]   CPU count: 56
[codecarbon INFO @ 04:32:02]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:32:02]   GPU count: 2
[codecarbon INFO @ 04:32:02]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:32:05] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:32:06] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:32:06] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:32:06] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 19.194488255996408 W
[codecarbon INFO @ 04:32:06] 0.000035 kWh of electricity used since the beginning.
[codecarbon INFO @ 04:33:01] [setup] RAM Tracking...
[codecarbon INFO @ 04:33:01] [setup] CPU Tracking...
[codecarbon WARNING @ 04:33:01] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:33:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:33:02] [setup] GPU Tracking...
[codecarbon INFO @ 04:33:02] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:33:02] >>> Tracker's metadata:
[codecarbon INFO @ 04:33:02]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:33:02]   Python version: 3.12.7
[codecarbon INFO @ 04:33:02]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:33:02]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:33:02]   CPU count: 56
[codecarbon INFO @ 04:33:02]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:33:02]   GPU count: 2
[codecarbon INFO @ 04:33:02]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:33:05] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:33:06] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:33:06] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:33:06] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 21.843426777388142 W
[codecarbon INFO @ 04:33:06] 0.000030 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 05:00:31] [setup] RAM Tracking...
[codecarbon INFO @ 05:00:31] [setup] CPU Tracking...
[codecarbon WARNING @ 05:00:31] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:00:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:00:32] [setup] GPU Tracking...
[codecarbon INFO @ 05:00:32] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:00:32] >>> Tracker's metadata:
[codecarbon INFO @ 05:00:32]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:00:32]   Python version: 3.12.7
[codecarbon INFO @ 05:00:32]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:00:32]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:00:32]   CPU count: 56
[codecarbon INFO @ 05:00:32]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:00:32]   GPU count: 2
[codecarbon INFO @ 05:00:32]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:00:35] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:00:36] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:00:36] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:00:36] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.501228680817466 W
[codecarbon INFO @ 05:00:36] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 05:01:32] [setup] RAM Tracking...
[codecarbon INFO @ 05:01:32] [setup] CPU Tracking...
[codecarbon WARNING @ 05:01:32] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:01:34] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:01:34] [setup] GPU Tracking...
[codecarbon INFO @ 05:01:34] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:01:34] >>> Tracker's metadata:
[codecarbon INFO @ 05:01:34]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:01:34]   Python version: 3.12.7
[codecarbon INFO @ 05:01:34]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:01:34]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:01:34]   CPU count: 56
[codecarbon INFO @ 05:01:34]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:01:34]   GPU count: 2
[codecarbon INFO @ 05:01:34]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:01:37] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:01:37] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:01:37] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:01:37] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 23.24702093005307 W
[codecarbon INFO @ 05:01:37] 0.000027 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 38.802 	Loss: 1.9669[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 38.802 	Loss: 1.7575[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 48.568 	Loss: 1.6403[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 55.859 	Loss: 1.5944[00m
[92m  Client8 Test => 	Acc: 19.964 	Loss: 3.9267[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 30.950 	Loss: 1.9873[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 51.803 	Loss: 1.5309[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 53.666 	Loss: 1.4890[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 63.281 	Loss: 1.2244[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 76.202 	Loss: 0.8183[00m
[92m  Client9 Test => 	Acc: 52.289 	Loss: 2.1242[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 21.909 	Loss: 2.3799[00m
 Train: Round   4, Avg Accuracy 58.439 | Avg Loss 1.343
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 32.489 	Loss: 1.9828[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.416 	Loss: 1.8369[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8321[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.416 	Loss: 1.8303[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.416 	Loss: 1.8271[00m
[92m  Client0 Test => 	Acc: 12.341 	Loss: 3.5419[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 25.781 	Loss: 2.3119[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.688 	Loss: 2.1404[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.688 	Loss: 2.1237[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.601 	Loss: 2.1292[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.601 	Loss: 2.1287[00m
[92m  Client1 Test => 	Acc: 11.067 	Loss: 3.3439[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.448 	Loss: 2.2219[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.535 	Loss: 2.1467[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.188 	Loss: 2.0898[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.361 	Loss: 2.1096[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.361 	Loss: 2.0783[00m
[92m  Client2 Test => 	Acc: 12.936 	Loss: 3.3456[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 63.672 	Loss: 1.3096[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 74.045 	Loss: 0.8861[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 80.686 	Loss: 0.6470[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 83.724 	Loss: 0.5313[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 85.590 	Loss: 0.4468[00m
[92m  Client3 Test => 	Acc: 57.945 	Loss: 1.7633[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 36.133 	Loss: 1.9540[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 57.617 	Loss: 1.3277[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 68.164 	Loss: 0.9696[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 71.387 	Loss: 0.8970[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 71.094 	Loss: 0.9397[00m
[92m  Client4 Test => 	Acc: 30.540 	Loss: 2.7238[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 30.208 	Loss: 2.0793[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 47.135 	Loss: 1.5968[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 54.036 	Loss: 1.4471[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 59.245 	Loss: 1.2183[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 63.151 	Loss: 1.1233[00m
[92m  Client5 Test => 	Acc: 35.180 	Loss: 2.6028[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 48.469 	Loss: 1.6810[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 61.875 	Loss: 1.2558[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 71.250 	Loss: 0.9087[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 79.719 	Loss: 0.6348[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 85.406 	Loss: 0.4615[00m
[92m  Client6 Test => 	Acc: 64.831 	Loss: 1.2341[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 39.922 	Loss: 2.0441[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 45.703 	Loss: 1.6118[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 51.016 	Loss: 1.4763[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 59.922 	Loss: 1.2494[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 47.656 	Loss: 1.8108[00m
[92m  Client7 Test => 	Acc: 27.738 	Loss: 2.8136[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 25.260 	Loss: 2.3585[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 59.505 	Loss: 1.5257[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 68.490 	Loss: 1.0837[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 68.099 	Loss: 1.0540[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 64.714 	Loss: 1.3113[00m
[92m  Client8 Test => 	Acc: 25.252 	Loss: 2.4081[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 43.930 	Loss: 1.8217[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 63.462 	Loss: 1.1701[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 68.810 	Loss: 1.1067[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 77.704 	Loss: 0.7665[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 82.272 	Loss: 0.6191[00m
[92m  Client9 Test => 	Acc: 61.579 	Loss: 1.5332[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 35.987 	Loss: 2.0855[00m
 Train: Round   5, Avg Accuracy 61.026 | Avg Loss 1.275
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 35.830 	Loss: 1.9608[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.308 	Loss: 1.8335[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.416 	Loss: 1.8345[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.443 	Loss: 1.8319[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.416 	Loss: 1.8327[00m
[92m  Client0 Test => 	Acc: 12.341 	Loss: 3.5047[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 25.868 	Loss: 2.3656[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.601 	Loss: 2.1404[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.774 	Loss: 2.1226[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.774 	Loss: 2.1193[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 30.295 	Loss: 2.1236[00m
[92m  Client1 Test => 	Acc: 11.081 	Loss: 3.4994[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 41.840 	Loss: 2.2378[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.448 	Loss: 2.1081[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.448 	Loss: 2.0923[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.274 	Loss: 2.0830[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.448 	Loss: 2.0798[00m
[92m  Client2 Test => 	Acc: 12.942 	Loss: 3.0515[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 73.958 	Loss: 0.9967[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 82.595 	Loss: 0.5898[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 85.330 	Loss: 0.4747[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 87.543 	Loss: 0.4073[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 90.582 	Loss: 0.3039[00m
[92m  Client3 Test => 	Acc: 71.798 	Loss: 1.3213[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 58.594 	Loss: 1.5060[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 68.750 	Loss: 0.9627[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 77.246 	Loss: 0.7348[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 05:28:51] [setup] RAM Tracking...
[codecarbon INFO @ 05:28:51] [setup] CPU Tracking...
[codecarbon WARNING @ 05:28:51] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:28:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:28:53] [setup] GPU Tracking...
[codecarbon INFO @ 05:28:53] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:28:53] >>> Tracker's metadata:
[codecarbon INFO @ 05:28:53]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:28:53]   Python version: 3.12.7
[codecarbon INFO @ 05:28:53]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:28:53]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:28:53]   CPU count: 56
[codecarbon INFO @ 05:28:53]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:28:53]   GPU count: 2
[codecarbon INFO @ 05:28:53]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:28:56] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:28:57] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:28:57] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:28:57] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.007641093050028 W
[codecarbon INFO @ 05:28:57] 0.000035 kWh of electricity used since the beginning.
[codecarbon INFO @ 05:29:52] [setup] RAM Tracking...
[codecarbon INFO @ 05:29:52] [setup] CPU Tracking...
[codecarbon WARNING @ 05:29:52] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:29:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:29:54] [setup] GPU Tracking...
[codecarbon INFO @ 05:29:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:29:54] >>> Tracker's metadata:
[codecarbon INFO @ 05:29:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:29:54]   Python version: 3.12.7
[codecarbon INFO @ 05:29:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:29:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:29:54]   CPU count: 56
[codecarbon INFO @ 05:29:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:29:54]   GPU count: 2
[codecarbon INFO @ 05:29:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:29:57] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:29:58] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:29:58] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:29:58] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.54564338776184 W
[codecarbon INFO @ 05:29:58] 0.000031 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 05:57:16] [setup] RAM Tracking...
[codecarbon INFO @ 05:57:16] [setup] CPU Tracking...
[codecarbon WARNING @ 05:57:16] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:57:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:57:18] [setup] GPU Tracking...
[codecarbon INFO @ 05:57:18] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:57:18] >>> Tracker's metadata:
[codecarbon INFO @ 05:57:18]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:57:18]   Python version: 3.12.7
[codecarbon INFO @ 05:57:18]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:57:18]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:57:18]   CPU count: 56
[codecarbon INFO @ 05:57:18]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:57:18]   GPU count: 2
[codecarbon INFO @ 05:57:18]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:57:21] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:57:22] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:57:22] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:57:22] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.03155239653087 W
[codecarbon INFO @ 05:57:22] 0.000039 kWh of electricity used since the beginning.
[codecarbon INFO @ 05:58:18] [setup] RAM Tracking...
[codecarbon INFO @ 05:58:18] [setup] CPU Tracking...
[codecarbon WARNING @ 05:58:18] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:58:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:58:19] [setup] GPU Tracking...
[codecarbon INFO @ 05:58:19] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:58:19] >>> Tracker's metadata:
[codecarbon INFO @ 05:58:19]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:58:19]   Python version: 3.12.7
[codecarbon INFO @ 05:58:19]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:58:19]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:58:19]   CPU count: 56
[codecarbon INFO @ 05:58:19]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:58:19]   GPU count: 2
[codecarbon INFO @ 05:58:19]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:58:23] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:58:23] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:58:23] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:58:23] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 18.49642330024638 W
[codecarbon INFO @ 05:58:23] 0.000031 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 83.203 	Loss: 0.5428[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 83.594 	Loss: 0.5305[00m
[92m  Client4 Test => 	Acc: 49.087 	Loss: 2.2086[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 54.818 	Loss: 1.7033[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 65.234 	Loss: 1.0676[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 71.484 	Loss: 0.8546[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 75.130 	Loss: 0.7480[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 77.734 	Loss: 0.7199[00m
[92m  Client5 Test => 	Acc: 50.227 	Loss: 2.6785[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 56.688 	Loss: 1.4771[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 72.375 	Loss: 0.9300[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 81.875 	Loss: 0.5992[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 86.062 	Loss: 0.4546[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 89.812 	Loss: 0.3567[00m
[92m  Client6 Test => 	Acc: 72.264 	Loss: 1.0003[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 47.656 	Loss: 1.8003[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 51.094 	Loss: 1.6105[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 48.906 	Loss: 1.6100[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 52.344 	Loss: 1.4592[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 58.047 	Loss: 1.2562[00m
[92m  Client7 Test => 	Acc: 38.782 	Loss: 2.5878[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 33.464 	Loss: 2.1239[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 68.880 	Loss: 1.3224[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 72.656 	Loss: 0.9246[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 78.255 	Loss: 0.7049[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 80.990 	Loss: 0.5771[00m
[92m  Client8 Test => 	Acc: 43.462 	Loss: 2.0391[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 62.680 	Loss: 1.4169[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 78.185 	Loss: 0.7990[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 71.154 	Loss: 1.1490[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 78.546 	Loss: 0.7671[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 83.474 	Loss: 0.5632[00m
[92m  Client9 Test => 	Acc: 60.899 	Loss: 1.4507[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 43.812 	Loss: 1.8908[00m
 Train: Round   6, Avg Accuracy 67.539 | Avg Loss 1.034
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 34.321 	Loss: 1.9496[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.389 	Loss: 1.8360[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.416 	Loss: 1.8299[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.470 	Loss: 1.8282[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.389 	Loss: 1.8323[00m
[92m  Client0 Test => 	Acc: 12.743 	Loss: 3.3249[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 28.993 	Loss: 2.2931[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 28.559 	Loss: 2.1485[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.427 	Loss: 2.1337[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.427 	Loss: 2.1220[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.688 	Loss: 2.1298[00m
[92m  Client1 Test => 	Acc: 17.746 	Loss: 3.1058[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 39.757 	Loss: 2.2188[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.274 	Loss: 2.1094[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.101 	Loss: 2.1233[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.535 	Loss: 2.0894[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.188 	Loss: 2.0884[00m
[92m  Client2 Test => 	Acc: 17.152 	Loss: 2.8905[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 79.774 	Loss: 0.7804[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 85.894 	Loss: 0.4823[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 87.023 	Loss: 0.4312[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 88.585 	Loss: 0.3905[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 91.450 	Loss: 0.3052[00m
[92m  Client3 Test => 	Acc: 62.410 	Loss: 1.6082[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 64.551 	Loss: 1.2106[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 76.172 	Loss: 0.7283[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 76.172 	Loss: 0.7406[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 84.180 	Loss: 0.5129[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 87.695 	Loss: 0.3984[00m
[92m  Client4 Test => 	Acc: 52.029 	Loss: 2.1688[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 59.635 	Loss: 1.3903[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 70.703 	Loss: 0.9165[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 75.391 	Loss: 0.7173[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 82.422 	Loss: 0.5541[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 86.589 	Loss: 0.4348[00m
[92m  Client5 Test => 	Acc: 57.482 	Loss: 2.2344[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 67.000 	Loss: 1.1103[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 76.438 	Loss: 0.8227[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 70.625 	Loss: 0.9761[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 78.094 	Loss: 0.6799[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 84.250 	Loss: 0.4782[00m
[92m  Client6 Test => 	Acc: 65.786 	Loss: 1.1103[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 51.719 	Loss: 1.5063[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 69.141 	Loss: 0.9499[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 73.984 	Loss: 0.8300[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 77.031 	Loss: 0.7382[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 81.719 	Loss: 0.6039[00m
[92m  Client7 Test => 	Acc: 67.612 	Loss: 1.2742[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 42.578 	Loss: 1.7345[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 76.172 	Loss: 0.8350[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 82.161 	Loss: 0.5973[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 85.156 	Loss: 0.5261[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 87.891 	Loss: 0.3946[00m
[92m  Client8 Test => 	Acc: 53.416 	Loss: 1.7493[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 72.776 	Loss: 1.0454[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 81.791 	Loss: 0.5988[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 85.517 	Loss: 0.5187[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 89.123 	Loss: 0.3564[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 89.784 	Loss: 0.3162[00m
[92m  Client9 Test => 	Acc: 68.505 	Loss: 1.1559[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 62.320 	Loss: 1.2437[00m
 Train: Round   7, Avg Accuracy 71.964 | Avg Loss 0.898
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 35.291 	Loss: 1.9312[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.335 	Loss: 1.8365[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8328[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.416 	Loss: 1.8317[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.416 	Loss: 1.8291[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 06:25:39] [setup] RAM Tracking...
[codecarbon INFO @ 06:25:39] [setup] CPU Tracking...
[codecarbon WARNING @ 06:25:39] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:25:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:25:41] [setup] GPU Tracking...
[codecarbon INFO @ 06:25:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:25:41] >>> Tracker's metadata:
[codecarbon INFO @ 06:25:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:25:41]   Python version: 3.12.7
[codecarbon INFO @ 06:25:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:25:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:25:41]   CPU count: 56
[codecarbon INFO @ 06:25:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:25:41]   GPU count: 2
[codecarbon INFO @ 06:25:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:25:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:25:45] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:25:45] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:25:45] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.719974064439985 W
[codecarbon INFO @ 06:25:45] 0.000037 kWh of electricity used since the beginning.
[codecarbon INFO @ 06:26:40] [setup] RAM Tracking...
[codecarbon INFO @ 06:26:40] [setup] CPU Tracking...
[codecarbon WARNING @ 06:26:40] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:26:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:26:42] [setup] GPU Tracking...
[codecarbon INFO @ 06:26:42] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:26:42] >>> Tracker's metadata:
[codecarbon INFO @ 06:26:42]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:26:42]   Python version: 3.12.7
[codecarbon INFO @ 06:26:42]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:26:42]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:26:42]   CPU count: 56
[codecarbon INFO @ 06:26:42]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:26:42]   GPU count: 2
[codecarbon INFO @ 06:26:42]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:26:45] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:26:46] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:26:46] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:26:46] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.262542856205332 W
[codecarbon INFO @ 06:26:46] 0.000031 kWh of electricity used since the beginning.

[92m  Client0 Test => 	Acc: 22.841 	Loss: 3.2742[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 26.389 	Loss: 2.3314[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.688 	Loss: 2.1280[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 28.993 	Loss: 2.1583[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.861 	Loss: 2.1240[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.601 	Loss: 2.1173[00m
[92m  Client1 Test => 	Acc: 14.532 	Loss: 3.2685[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.361 	Loss: 2.1873[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.361 	Loss: 2.0932[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.535 	Loss: 2.0859[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.708 	Loss: 2.1420[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.188 	Loss: 2.1136[00m
[92m  Client2 Test => 	Acc: 16.881 	Loss: 3.1098[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 85.026 	Loss: 0.5276[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 88.021 	Loss: 0.4169[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 90.365 	Loss: 0.3143[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 91.580 	Loss: 0.2770[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 92.318 	Loss: 0.2467[00m
[92m  Client3 Test => 	Acc: 75.805 	Loss: 1.0604[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 79.688 	Loss: 0.6787[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 86.035 	Loss: 0.4660[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 87.500 	Loss: 0.3869[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 89.941 	Loss: 0.3281[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 90.234 	Loss: 0.3106[00m
[92m  Client4 Test => 	Acc: 65.716 	Loss: 1.2328[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 75.260 	Loss: 0.8072[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 82.422 	Loss: 0.5117[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 89.714 	Loss: 0.3720[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 88.932 	Loss: 0.3384[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 89.844 	Loss: 0.2734[00m
[92m  Client5 Test => 	Acc: 68.312 	Loss: 1.7150[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 78.031 	Loss: 0.6923[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 38.188 	Loss: 2.2032[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 42.156 	Loss: 1.9174[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 60.500 	Loss: 1.2870[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 70.219 	Loss: 0.9478[00m
[92m  Client6 Test => 	Acc: 55.573 	Loss: 1.5922[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 69.688 	Loss: 1.0376[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 76.719 	Loss: 0.7411[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 85.469 	Loss: 0.4631[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 84.766 	Loss: 0.5013[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 87.812 	Loss: 0.4020[00m
[92m  Client7 Test => 	Acc: 67.024 	Loss: 1.3566[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 62.630 	Loss: 1.1582[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 82.422 	Loss: 0.6185[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 88.151 	Loss: 0.3911[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 92.188 	Loss: 0.2580[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 91.927 	Loss: 0.2550[00m
[92m  Client8 Test => 	Acc: 59.904 	Loss: 1.7616[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 79.868 	Loss: 0.7120[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 86.238 	Loss: 0.4539[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 91.346 	Loss: 0.3058[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 91.106 	Loss: 0.2918[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 91.466 	Loss: 0.2777[00m
[92m  Client9 Test => 	Acc: 65.446 	Loss: 1.2959[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 70.285 	Loss: 0.9110[00m
 Train: Round   8, Avg Accuracy 72.402 | Avg Loss 0.877
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 35.372 	Loss: 1.9306[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.416 	Loss: 1.8338[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.497 	Loss: 1.8375[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.335 	Loss: 1.8324[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.362 	Loss: 1.8328[00m
[92m  Client0 Test => 	Acc: 12.543 	Loss: 3.7187[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 28.906 	Loss: 2.2845[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.688 	Loss: 2.1345[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.427 	Loss: 2.1389[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 28.906 	Loss: 2.1248[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.427 	Loss: 2.1178[00m
[92m  Client1 Test => 	Acc: 50.494 	Loss: 2.0988[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 38.108 	Loss: 2.2556[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.361 	Loss: 2.1101[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.535 	Loss: 2.0776[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.448 	Loss: 2.0779[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.448 	Loss: 2.0777[00m
[92m  Client2 Test => 	Acc: 33.051 	Loss: 2.3357[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 89.366 	Loss: 0.3803[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 92.405 	Loss: 0.2541[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 92.839 	Loss: 0.2393[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 93.142 	Loss: 0.2305[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 92.969 	Loss: 0.2184[00m
[92m  Client3 Test => 	Acc: 77.965 	Loss: 0.9559[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 87.598 	Loss: 0.4295[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 91.113 	Loss: 0.2653[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 91.211 	Loss: 0.2867[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 92.480 	Loss: 0.2285[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 93.945 	Loss: 0.1749[00m
[92m  Client4 Test => 	Acc: 71.280 	Loss: 1.0959[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 83.984 	Loss: 0.5260[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 87.370 	Loss: 0.3789[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 88.932 	Loss: 0.2984[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 88.281 	Loss: 0.3167[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 89.974 	Loss: 0.2930[00m
[92m  Client5 Test => 	Acc: 69.600 	Loss: 1.4890[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 84.875 	Loss: 0.4980[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 89.344 	Loss: 0.3439[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 91.812 	Loss: 0.2666[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 93.062 	Loss: 0.2150[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 93.406 	Loss: 0.2079[00m
[92m  Client6 Test => 	Acc: 79.576 	Loss: 0.7548[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 79.688 	Loss: 0.7020[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 78.906 	Loss: 0.6829[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 85.859 	Loss: 0.4857[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 90.781 	Loss: 0.3108[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 92.109 	Loss: 0.2738[00m
[92m  Client7 Test => 	Acc: 77.728 	Loss: 0.9220[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 75.911 	Loss: 0.7174[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 87.500 	Loss: 0.4040[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 89.844 	Loss: 0.3023[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 92.969 	Loss: 0.2355[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 06:54:11] [setup] RAM Tracking...
[codecarbon INFO @ 06:54:11] [setup] CPU Tracking...
[codecarbon WARNING @ 06:54:11] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:54:13] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:54:13] [setup] GPU Tracking...
[codecarbon INFO @ 06:54:13] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:54:13] >>> Tracker's metadata:
[codecarbon INFO @ 06:54:13]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:54:13]   Python version: 3.12.7
[codecarbon INFO @ 06:54:13]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:54:13]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:54:13]   CPU count: 56
[codecarbon INFO @ 06:54:13]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:54:13]   GPU count: 2
[codecarbon INFO @ 06:54:13]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:54:16] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:54:17] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:54:17] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:54:17] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 19.12847469419237 W
[codecarbon INFO @ 06:54:17] 0.000033 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 94.271 	Loss: 0.1978[00m
[92m  Client8 Test => 	Acc: 63.760 	Loss: 1.5484[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 88.281 	Loss: 0.4204[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 90.505 	Loss: 0.3132[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 91.346 	Loss: 0.2625[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 93.269 	Loss: 0.2333[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 92.368 	Loss: 0.2421[00m
[92m  Client9 Test => 	Acc: 75.606 	Loss: 0.8296[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 78.274 	Loss: 0.6923[00m
 Train: Round   9, Avg Accuracy 75.928 | Avg Loss 0.764
Training and Evaluation completed!
===== END Thu 01/15/2026  6:55:16.86 ===== 
