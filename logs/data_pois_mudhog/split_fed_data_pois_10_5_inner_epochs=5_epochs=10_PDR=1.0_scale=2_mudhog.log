===== START Wed 01/14/2026 21:26:13.14 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 21:26:47] [setup] RAM Tracking...
[codecarbon INFO @ 21:26:47] [setup] CPU Tracking...
[codecarbon WARNING @ 21:26:47] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:26:49] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:26:49] [setup] GPU Tracking...
[codecarbon INFO @ 21:26:49] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:26:49] >>> Tracker's metadata:
[codecarbon INFO @ 21:26:49]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:26:49]   Python version: 3.12.7
[codecarbon INFO @ 21:26:49]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:26:49]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:26:49]   CPU count: 56
[codecarbon INFO @ 21:26:49]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:26:49]   GPU count: 2
[codecarbon INFO @ 21:26:49]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:26:52] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:26:53] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:26:53] Energy consumed for all CPUs : 0.000041 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:26:53] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 16.97427124896823 W
[codecarbon INFO @ 21:26:53] 0.000067 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 21:54:08] [setup] RAM Tracking...
[codecarbon INFO @ 21:54:08] [setup] CPU Tracking...
[codecarbon WARNING @ 21:54:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:54:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:54:10] [setup] GPU Tracking...
[codecarbon INFO @ 21:54:10] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:54:10] >>> Tracker's metadata:
[codecarbon INFO @ 21:54:10]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:54:10]   Python version: 3.12.7
[codecarbon INFO @ 21:54:10]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:54:10]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:54:10]   CPU count: 56
[codecarbon INFO @ 21:54:10]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:54:10]   GPU count: 2
[codecarbon INFO @ 21:54:10]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:54:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:54:14] Energy consumed for RAM : 0.000016 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:54:14] Energy consumed for all CPUs : 0.000034 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:54:14] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 22.001413105207323 W
[codecarbon INFO @ 21:54:14] 0.000056 kWh of electricity used since the beginning.
[codecarbon INFO @ 21:55:09] [setup] RAM Tracking...
[codecarbon INFO @ 21:55:09] [setup] CPU Tracking...
[codecarbon WARNING @ 21:55:09] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:55:11] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:55:11] [setup] GPU Tracking...
[codecarbon INFO @ 21:55:11] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:55:11] >>> Tracker's metadata:
[codecarbon INFO @ 21:55:11]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:55:11]   Python version: 3.12.7
[codecarbon INFO @ 21:55:11]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:55:11]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:55:11]   CPU count: 56
[codecarbon INFO @ 21:55:11]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:55:11]   GPU count: 2
[codecarbon INFO @ 21:55:11]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:55:14] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:55:15] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:55:15] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:55:15] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.282157614404564 W
[codecarbon INFO @ 21:55:15] 0.000035 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 2                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: mudhog              #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: data_poisoning 10,5 #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_data_pois_10_5_inner_epochs=5_epochs=10_PDR=1.0_scale=2_mudhog#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_data_pois_10_5_inner_epochs=5_epochs=10_PDR=1.0_scale=2_mudhog----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 29.768 	Loss: 2.9637[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 36.584 	Loss: 1.9059[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.497 	Loss: 1.8631[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 37.769 	Loss: 1.8615[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.200 	Loss: 1.8555[00m
[92m  Client0 Test => 	Acc: 12.335 	Loss: 2.9662[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 19.705 	Loss: 4.7098[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 21.354 	Loss: 2.3620[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 25.955 	Loss: 2.3221[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 27.604 	Loss: 2.1843[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.167 	Loss: 2.1627[00m
[92m  Client1 Test => 	Acc: 4.893 	Loss: 3.0289[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 22.656 	Loss: 4.6634[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 37.066 	Loss: 2.2836[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 44.618 	Loss: 1.8213[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 51.302 	Loss: 1.5435[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 59.115 	Loss: 1.3219[00m
[92m  Client2 Test => 	Acc: 33.071 	Loss: 3.5326[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 27.127 	Loss: 5.1458[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 41.536 	Loss: 1.8165[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 65.365 	Loss: 1.2346[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 71.832 	Loss: 0.9779[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 74.306 	Loss: 0.9110[00m
[92m  Client3 Test => 	Acc: 30.866 	Loss: 2.3916[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 18.164 	Loss: 3.4759[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 23.242 	Loss: 2.4553[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 50.684 	Loss: 1.6651[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 53.027 	Loss: 1.3857[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 62.695 	Loss: 1.1271[00m
[92m  Client4 Test => 	Acc: 33.679 	Loss: 3.6379[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 27.214 	Loss: 4.1344[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 18.880 	Loss: 2.3865[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 22.005 	Loss: 2.2142[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.250 	Loss: 2.0396[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.120 	Loss: 2.0134[00m
[92m  Client5 Test => 	Acc: 12.341 	Loss: 3.6327[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 28.094 	Loss: 2.6536[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 54.219 	Loss: 1.4692[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 66.406 	Loss: 1.0591[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 73.969 	Loss: 0.8310[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 71.938 	Loss: 0.8939[00m
[92m  Client6 Test => 	Acc: 53.794 	Loss: 1.6774[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.625 	Loss: 3.0622[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 18.672 	Loss: 2.3443[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 25.703 	Loss: 2.1905[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 28.438 	Loss: 2.1118[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 35.312 	Loss: 1.8873[00m
[92m  Client7 Test => 	Acc: 19.587 	Loss: 3.0066[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 15.625 	Loss: 3.9828[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 23.698 	Loss: 2.3464[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 32.161 	Loss: 2.1820[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 40.104 	Loss: 1.9378[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 53.646 	Loss: 1.5794[00m
[92m  Client8 Test => 	Acc: 23.377 	Loss: 3.0498[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.411 	Loss: 12.6013[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 26.442 	Loss: 2.2405[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 27.103 	Loss: 2.0961[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 33.353 	Loss: 1.9590[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 45.673 	Loss: 1.6957[00m
[92m  Client9 Test => 	Acc: 39.690 	Loss: 2.9676[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.936 	Loss: 2.7413[00m
 Train: Round   0, Avg Accuracy 50.117 | Avg Loss 1.545
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 30.630 	Loss: 2.4477[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 36.988 	Loss: 3.9843[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 36.422 	Loss: 1.8554[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 37.877 	Loss: 1.8406[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 36.853 	Loss: 1.8397[00m
[92m  Client0 Test => 	Acc: 12.348 	Loss: 3.4476[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 21.615 	Loss: 2.3783[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 30.035 	Loss: 2.4379[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 27.431 	Loss: 2.1663[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.080 	Loss: 2.1423[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 30.122 	Loss: 2.1207[00m
[92m  Client1 Test => 	Acc: 11.067 	Loss: 2.9388[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.535 	Loss: 2.2425[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.622 	Loss: 2.1862[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.622 	Loss: 2.1248[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.535 	Loss: 2.0956[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.448 	Loss: 2.0889[00m
[92m  Client2 Test => 	Acc: 12.942 	Loss: 3.2831[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 35.851 	Loss: 1.9651[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 60.677 	Loss: 1.3686[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 70.182 	Loss: 1.0828[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 74.479 	Loss: 0.8860[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 80.252 	Loss: 0.6774[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 22:22:27] [setup] RAM Tracking...
[codecarbon INFO @ 22:22:27] [setup] CPU Tracking...
[codecarbon WARNING @ 22:22:27] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:22:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:22:29] [setup] GPU Tracking...
[codecarbon INFO @ 22:22:29] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:22:29] >>> Tracker's metadata:
[codecarbon INFO @ 22:22:29]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:22:29]   Python version: 3.12.7
[codecarbon INFO @ 22:22:29]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:22:29]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:22:29]   CPU count: 56
[codecarbon INFO @ 22:22:29]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:22:29]   GPU count: 2
[codecarbon INFO @ 22:22:29]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:22:32] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:22:33] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:22:33] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:22:33] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.382822307048235 W
[codecarbon INFO @ 22:22:33] 0.000033 kWh of electricity used since the beginning.
[codecarbon INFO @ 22:23:28] [setup] RAM Tracking...
[codecarbon INFO @ 22:23:28] [setup] CPU Tracking...
[codecarbon WARNING @ 22:23:28] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:23:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:23:30] [setup] GPU Tracking...
[codecarbon INFO @ 22:23:30] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:23:30] >>> Tracker's metadata:
[codecarbon INFO @ 22:23:30]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:23:30]   Python version: 3.12.7
[codecarbon INFO @ 22:23:30]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:23:30]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:23:30]   CPU count: 56
[codecarbon INFO @ 22:23:30]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:23:30]   GPU count: 2
[codecarbon INFO @ 22:23:30]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:23:33] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:23:34] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:23:34] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:23:34] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.10895302671901 W
[codecarbon INFO @ 22:23:34] 0.000029 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 22:50:50] [setup] RAM Tracking...
[codecarbon INFO @ 22:50:50] [setup] CPU Tracking...
[codecarbon WARNING @ 22:50:50] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:50:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:50:51] [setup] GPU Tracking...
[codecarbon INFO @ 22:50:51] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:50:51] >>> Tracker's metadata:
[codecarbon INFO @ 22:50:51]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:50:51]   Python version: 3.12.7
[codecarbon INFO @ 22:50:51]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:50:51]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:50:51]   CPU count: 56
[codecarbon INFO @ 22:50:51]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:50:51]   GPU count: 2
[codecarbon INFO @ 22:50:51]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:50:55] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:50:55] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:50:55] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:50:55] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 15.689102115647831 W
[codecarbon INFO @ 22:50:55] 0.000026 kWh of electricity used since the beginning.
[codecarbon INFO @ 22:51:50] [setup] RAM Tracking...
[codecarbon INFO @ 22:51:50] [setup] CPU Tracking...
[codecarbon WARNING @ 22:51:50] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:51:52] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:51:52] [setup] GPU Tracking...
[codecarbon INFO @ 22:51:52] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:51:52] >>> Tracker's metadata:
[codecarbon INFO @ 22:51:52]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:51:52]   Python version: 3.12.7
[codecarbon INFO @ 22:51:52]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:51:52]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:51:52]   CPU count: 56
[codecarbon INFO @ 22:51:52]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:51:52]   GPU count: 2
[codecarbon INFO @ 22:51:52]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:51:55] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:51:56] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:51:56] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:51:56] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.81922442027145 W
[codecarbon INFO @ 22:51:56] 0.000029 kWh of electricity used since the beginning.

[92m  Client3 Test => 	Acc: 47.270 	Loss: 2.1820[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 17.188 	Loss: 2.5205[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 28.125 	Loss: 2.0519[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 34.961 	Loss: 1.9050[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 44.238 	Loss: 1.6306[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 46.289 	Loss: 1.5269[00m
[92m  Client4 Test => 	Acc: 27.144 	Loss: 3.1182[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.531 	Loss: 2.5053[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 31.771 	Loss: 2.1046[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 31.120 	Loss: 2.0274[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 32.292 	Loss: 1.9689[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 38.802 	Loss: 2.0087[00m
[92m  Client5 Test => 	Acc: 5.584 	Loss: 3.7321[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 24.281 	Loss: 2.2285[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 28.719 	Loss: 2.0487[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 46.062 	Loss: 1.8436[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 59.750 	Loss: 1.3550[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 68.219 	Loss: 1.0779[00m
[92m  Client6 Test => 	Acc: 46.717 	Loss: 1.9755[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 19.297 	Loss: 2.4862[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 25.625 	Loss: 2.2109[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 25.625 	Loss: 2.1261[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 33.359 	Loss: 1.9881[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 45.234 	Loss: 1.6903[00m
[92m  Client7 Test => 	Acc: 25.125 	Loss: 2.9667[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 14.844 	Loss: 2.5571[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 23.177 	Loss: 2.1349[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 41.797 	Loss: 2.0268[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 29.427 	Loss: 2.1014[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 32.031 	Loss: 2.0006[00m
[92m  Client8 Test => 	Acc: 17.853 	Loss: 3.9605[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 23.257 	Loss: 2.2288[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 33.954 	Loss: 1.8608[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 42.668 	Loss: 1.7084[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 53.065 	Loss: 1.5021[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 64.784 	Loss: 1.2102[00m
[92m  Client9 Test => 	Acc: 51.102 	Loss: 2.0505[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.942 	Loss: 2.6202[00m
 Train: Round   1, Avg Accuracy 48.503 | Avg Loss 1.624
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 34.968 	Loss: 1.9337[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 37.365 	Loss: 1.8483[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.497 	Loss: 1.8303[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.389 	Loss: 1.8304[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.389 	Loss: 1.8374[00m
[92m  Client0 Test => 	Acc: 12.335 	Loss: 3.4252[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 22.830 	Loss: 2.3599[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 28.472 	Loss: 2.1387[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.601 	Loss: 2.1223[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.340 	Loss: 2.1226[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.514 	Loss: 2.1069[00m
[92m  Client1 Test => 	Acc: 11.081 	Loss: 6.1315[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.361 	Loss: 2.2328[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 40.712 	Loss: 1.9121[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.622 	Loss: 1.7268[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 48.177 	Loss: 1.6331[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 53.819 	Loss: 1.4671[00m
[92m  Client2 Test => 	Acc: 31.505 	Loss: 3.8530[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 39.887 	Loss: 1.8614[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 65.885 	Loss: 1.1662[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 75.955 	Loss: 0.8511[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 79.948 	Loss: 0.6774[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 84.288 	Loss: 0.5480[00m
[92m  Client3 Test => 	Acc: 53.863 	Loss: 1.7793[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 18.359 	Loss: 2.5799[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 38.867 	Loss: 1.7952[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 42.090 	Loss: 1.6326[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 50.781 	Loss: 1.4953[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 57.227 	Loss: 1.3220[00m
[92m  Client4 Test => 	Acc: 28.065 	Loss: 3.5782[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 28.906 	Loss: 2.3407[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 44.010 	Loss: 1.8543[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 50.130 	Loss: 1.5660[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 56.380 	Loss: 1.3747[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 67.188 	Loss: 1.1036[00m
[92m  Client5 Test => 	Acc: 39.928 	Loss: 2.6053[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 30.562 	Loss: 2.1742[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 24.875 	Loss: 2.2827[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 24.375 	Loss: 2.0958[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.875 	Loss: 2.0826[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 24.906 	Loss: 2.0836[00m
[92m  Client6 Test => 	Acc: 11.074 	Loss: 3.1917[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 23.906 	Loss: 2.3714[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 31.875 	Loss: 2.0324[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 38.594 	Loss: 1.8641[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 46.953 	Loss: 1.6707[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 39.688 	Loss: 1.9616[00m
[92m  Client7 Test => 	Acc: 21.259 	Loss: 2.8635[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 15.755 	Loss: 2.6400[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 30.599 	Loss: 2.1315[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 35.417 	Loss: 1.9235[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 41.146 	Loss: 1.6990[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 48.047 	Loss: 1.6975[00m
[92m  Client8 Test => 	Acc: 19.072 	Loss: 3.2562[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 25.300 	Loss: 2.1608[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 35.096 	Loss: 1.8169[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 49.459 	Loss: 1.5690[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 65.445 	Loss: 1.2122[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 75.240 	Loss: 0.8437[00m
[92m  Client9 Test => 	Acc: 48.256 	Loss: 2.1603[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 21.424 	Loss: 2.4187[00m
 Train: Round   2, Avg Accuracy 51.831 | Avg Loss 1.497
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 36.342 	Loss: 1.9874[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.443 	Loss: 1.8305[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 23:19:23] [setup] RAM Tracking...
[codecarbon INFO @ 23:19:23] [setup] CPU Tracking...
[codecarbon WARNING @ 23:19:23] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:19:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:19:25] [setup] GPU Tracking...
[codecarbon INFO @ 23:19:25] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:19:25] >>> Tracker's metadata:
[codecarbon INFO @ 23:19:25]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:19:25]   Python version: 3.12.7
[codecarbon INFO @ 23:19:25]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:19:25]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:19:25]   CPU count: 56
[codecarbon INFO @ 23:19:25]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:19:25]   GPU count: 2
[codecarbon INFO @ 23:19:25]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:19:28] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:19:28] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:19:28] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:19:28] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 14.990889734706931 W
[codecarbon INFO @ 23:19:28] 0.000029 kWh of electricity used since the beginning.
[codecarbon INFO @ 23:20:23] [setup] RAM Tracking...
[codecarbon INFO @ 23:20:23] [setup] CPU Tracking...
[codecarbon WARNING @ 23:20:23] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:20:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:20:25] [setup] GPU Tracking...
[codecarbon INFO @ 23:20:25] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:20:25] >>> Tracker's metadata:
[codecarbon INFO @ 23:20:25]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:20:25]   Python version: 3.12.7
[codecarbon INFO @ 23:20:25]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:20:25]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:20:25]   CPU count: 56
[codecarbon INFO @ 23:20:25]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:20:25]   GPU count: 2
[codecarbon INFO @ 23:20:25]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:20:28] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:20:29] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:20:29] Energy consumed for all CPUs : 0.000015 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:20:29] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.62332079751335 W
[codecarbon INFO @ 23:20:29] 0.000024 kWh of electricity used since the beginning.

[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8305[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.389 	Loss: 1.8293[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.362 	Loss: 1.8297[00m
[92m  Client0 Test => 	Acc: 12.335 	Loss: 6.1195[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 23.003 	Loss: 2.4575[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.514 	Loss: 2.1573[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 30.035 	Loss: 2.1224[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 30.035 	Loss: 2.1095[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.427 	Loss: 2.1238[00m
[92m  Client1 Test => 	Acc: 11.067 	Loss: 3.7071[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 49.826 	Loss: 1.7708[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 54.948 	Loss: 1.4415[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 61.285 	Loss: 1.2167[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 65.191 	Loss: 1.0471[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 70.573 	Loss: 0.9437[00m
[92m  Client2 Test => 	Acc: 48.743 	Loss: 2.4189[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 60.764 	Loss: 1.3953[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 69.010 	Loss: 1.1210[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 71.441 	Loss: 1.0126[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 74.740 	Loss: 0.9554[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 76.823 	Loss: 0.8264[00m
[92m  Client3 Test => 	Acc: 30.763 	Loss: 2.6635[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 31.250 	Loss: 2.0052[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 53.906 	Loss: 1.3855[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 56.836 	Loss: 1.2452[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 62.891 	Loss: 1.0347[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 72.559 	Loss: 0.8178[00m
[92m  Client4 Test => 	Acc: 43.297 	Loss: 3.5483[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 43.490 	Loss: 2.1077[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 48.958 	Loss: 1.7024[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 60.156 	Loss: 1.2503[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 69.271 	Loss: 0.9249[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 68.750 	Loss: 0.9874[00m
[92m  Client5 Test => 	Acc: 38.905 	Loss: 2.8564[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 44.344 	Loss: 1.9080[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 65.844 	Loss: 1.1564[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 70.188 	Loss: 0.9604[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 79.938 	Loss: 0.6727[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 85.438 	Loss: 0.5008[00m
[92m  Client6 Test => 	Acc: 64.110 	Loss: 1.3180[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 38.281 	Loss: 2.1466[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 40.547 	Loss: 1.7784[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 48.047 	Loss: 1.6376[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 52.891 	Loss: 1.4739[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 66.719 	Loss: 1.0980[00m
[92m  Client7 Test => 	Acc: 41.800 	Loss: 2.2149[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 25.000 	Loss: 2.4117[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 43.229 	Loss: 1.8637[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 46.615 	Loss: 1.6275[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 56.380 	Loss: 1.4044[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 59.896 	Loss: 1.5669[00m
[92m  Client8 Test => 	Acc: 19.844 	Loss: 3.0103[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 33.894 	Loss: 1.9680[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 42.188 	Loss: 1.6507[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 47.656 	Loss: 1.6392[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 59.315 	Loss: 1.3558[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 70.373 	Loss: 1.0042[00m
[92m  Client9 Test => 	Acc: 49.136 	Loss: 2.0881[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 29.630 	Loss: 2.1717[00m
 Train: Round   3, Avg Accuracy 63.892 | Avg Loss 1.170
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 37.069 	Loss: 1.9227[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.443 	Loss: 1.8375[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8291[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.470 	Loss: 1.8343[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.416 	Loss: 1.8298[00m
[92m  Client0 Test => 	Acc: 9.756 	Loss: 4.2260[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 26.302 	Loss: 2.3971[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.427 	Loss: 2.1405[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.514 	Loss: 2.1251[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.948 	Loss: 2.1085[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.948 	Loss: 2.1167[00m
[92m  Client1 Test => 	Acc: 11.054 	Loss: 3.6009[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 56.944 	Loss: 1.5206[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 62.326 	Loss: 1.1911[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 69.531 	Loss: 0.9977[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 74.045 	Loss: 0.7646[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 77.604 	Loss: 0.7385[00m
[92m  Client2 Test => 	Acc: 49.534 	Loss: 1.8992[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 68.837 	Loss: 1.1234[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 76.649 	Loss: 0.8135[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 78.559 	Loss: 0.6963[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 84.939 	Loss: 0.4971[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 87.500 	Loss: 0.4185[00m
[92m  Client3 Test => 	Acc: 65.827 	Loss: 1.4536[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 49.414 	Loss: 1.6597[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 63.867 	Loss: 1.0717[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 70.410 	Loss: 0.8701[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 66.211 	Loss: 1.0307[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 70.996 	Loss: 0.9022[00m
[92m  Client4 Test => 	Acc: 40.980 	Loss: 2.8891[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 51.953 	Loss: 1.7025[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 60.938 	Loss: 1.1753[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 71.484 	Loss: 0.9124[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 78.385 	Loss: 0.6855[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 77.474 	Loss: 0.6730[00m
[92m  Client5 Test => 	Acc: 47.596 	Loss: 2.6885[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 59.969 	Loss: 1.3959[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 67.594 	Loss: 1.0894[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 74.688 	Loss: 0.7942[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 79.531 	Loss: 0.6559[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 85.438 	Loss: 0.4943[00m
[92m  Client6 Test => 	Acc: 67.328 	Loss: 1.1054[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 43.125 	Loss: 1.8785[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 51.250 	Loss: 1.6413[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 51.328 	Loss: 1.5737[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 58.125 	Loss: 1.3596[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 62.422 	Loss: 1.1845[00m
[92m  Client7 Test => 	Acc: 35.468 	Loss: 2.5292[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 27.995 	Loss: 2.2812[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 23:47:30] [setup] RAM Tracking...
[codecarbon INFO @ 23:47:30] [setup] CPU Tracking...
[codecarbon WARNING @ 23:47:30] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:47:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:47:32] [setup] GPU Tracking...
[codecarbon INFO @ 23:47:32] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:47:32] >>> Tracker's metadata:
[codecarbon INFO @ 23:47:32]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:47:32]   Python version: 3.12.7
[codecarbon INFO @ 23:47:32]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:47:32]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:47:32]   CPU count: 56
[codecarbon INFO @ 23:47:32]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:47:32]   GPU count: 2
[codecarbon INFO @ 23:47:32]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:47:35] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:47:36] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:47:36] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:47:36] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.167642157605574 W
[codecarbon INFO @ 23:47:36] 0.000034 kWh of electricity used since the beginning.
[codecarbon INFO @ 23:48:31] [setup] RAM Tracking...
[codecarbon INFO @ 23:48:31] [setup] CPU Tracking...
[codecarbon WARNING @ 23:48:31] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:48:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:48:33] [setup] GPU Tracking...
[codecarbon INFO @ 23:48:33] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:48:33] >>> Tracker's metadata:
[codecarbon INFO @ 23:48:33]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:48:33]   Python version: 3.12.7
[codecarbon INFO @ 23:48:33]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:48:33]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:48:33]   CPU count: 56
[codecarbon INFO @ 23:48:33]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:48:33]   GPU count: 2
[codecarbon INFO @ 23:48:33]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:48:36] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:48:36] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:48:36] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:48:36] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.120254760647303 W
[codecarbon INFO @ 23:48:36] 0.000033 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 00:15:56] [setup] RAM Tracking...
[codecarbon INFO @ 00:15:56] [setup] CPU Tracking...
[codecarbon WARNING @ 00:15:56] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:15:58] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:15:58] [setup] GPU Tracking...
[codecarbon INFO @ 00:15:58] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:15:58] >>> Tracker's metadata:
[codecarbon INFO @ 00:15:58]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:15:58]   Python version: 3.12.7
[codecarbon INFO @ 00:15:58]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:15:58]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:15:58]   CPU count: 56
[codecarbon INFO @ 00:15:58]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:15:58]   GPU count: 2
[codecarbon INFO @ 00:15:58]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:16:01] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:16:02] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:16:02] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:16:02] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.01424049841686 W
[codecarbon INFO @ 00:16:02] 0.000039 kWh of electricity used since the beginning.
[codecarbon INFO @ 00:16:56] [setup] RAM Tracking...
[codecarbon INFO @ 00:16:56] [setup] CPU Tracking...
[codecarbon WARNING @ 00:16:56] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:16:58] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:16:58] [setup] GPU Tracking...
[codecarbon INFO @ 00:16:58] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:16:58] >>> Tracker's metadata:
[codecarbon INFO @ 00:16:58]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:16:58]   Python version: 3.12.7
[codecarbon INFO @ 00:16:58]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:16:58]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:16:58]   CPU count: 56
[codecarbon INFO @ 00:16:58]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:16:58]   GPU count: 2
[codecarbon INFO @ 00:16:58]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:17:01] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:17:02] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:17:02] Energy consumed for all CPUs : 0.000015 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:17:02] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 15.727890097181472 W
[codecarbon INFO @ 00:17:02] 0.000025 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 53.776 	Loss: 1.5936[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 66.146 	Loss: 1.1274[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 79.427 	Loss: 0.7608[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 81.380 	Loss: 0.6571[00m
[92m  Client8 Test => 	Acc: 33.909 	Loss: 3.5232[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 51.322 	Loss: 1.6093[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 71.695 	Loss: 1.0029[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 77.885 	Loss: 0.8007[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 83.654 	Loss: 0.5724[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 88.101 	Loss: 0.4096[00m
[92m  Client9 Test => 	Acc: 61.830 	Loss: 1.5529[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 48.005 	Loss: 1.6428[00m
 Train: Round   4, Avg Accuracy 69.928 | Avg Loss 0.942
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 32.651 	Loss: 2.2381[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 35.884 	Loss: 1.8495[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.254 	Loss: 1.8349[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.416 	Loss: 1.8294[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.362 	Loss: 1.8315[00m
[92m  Client0 Test => 	Acc: 12.335 	Loss: 3.3154[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 17.361 	Loss: 2.4370[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 26.562 	Loss: 2.2525[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.514 	Loss: 2.1874[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.601 	Loss: 2.1228[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 30.122 	Loss: 2.1157[00m
[92m  Client1 Test => 	Acc: 11.074 	Loss: 3.5725[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 61.285 	Loss: 1.2281[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 73.090 	Loss: 0.8509[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 81.771 	Loss: 0.5887[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 85.156 	Loss: 0.4676[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 83.333 	Loss: 0.4905[00m
[92m  Client2 Test => 	Acc: 62.201 	Loss: 1.7498[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 76.606 	Loss: 0.7925[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 84.201 	Loss: 0.5096[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 87.630 	Loss: 0.4153[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 83.550 	Loss: 0.5535[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 86.415 	Loss: 0.4342[00m
[92m  Client3 Test => 	Acc: 65.535 	Loss: 1.4483[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 60.352 	Loss: 1.2356[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 77.051 	Loss: 0.7161[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 83.203 	Loss: 0.5038[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 83.789 	Loss: 0.5186[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 88.672 	Loss: 0.3706[00m
[92m  Client4 Test => 	Acc: 51.548 	Loss: 2.5092[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 63.281 	Loss: 1.1489[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 76.432 	Loss: 0.7538[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 80.339 	Loss: 0.6149[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 79.688 	Loss: 0.6550[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 80.339 	Loss: 0.5754[00m
[92m  Client5 Test => 	Acc: 56.885 	Loss: 2.0568[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 69.906 	Loss: 0.9942[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 77.406 	Loss: 0.7380[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 82.812 	Loss: 0.5694[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 86.812 	Loss: 0.4388[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 87.906 	Loss: 0.3996[00m
[92m  Client6 Test => 	Acc: 70.751 	Loss: 0.9502[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 50.391 	Loss: 1.4825[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 67.422 	Loss: 1.0486[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 69.297 	Loss: 0.8926[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 76.797 	Loss: 0.7555[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 82.422 	Loss: 0.5692[00m
[92m  Client7 Test => 	Acc: 61.936 	Loss: 1.5297[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 48.568 	Loss: 1.5551[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 74.870 	Loss: 0.8639[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 80.469 	Loss: 0.6418[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 82.943 	Loss: 0.5758[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 85.677 	Loss: 0.4383[00m
[92m  Client8 Test => 	Acc: 49.443 	Loss: 1.8826[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 68.450 	Loss: 1.0828[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 84.315 	Loss: 0.5479[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 83.474 	Loss: 0.5670[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 86.538 	Loss: 0.4439[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 89.543 	Loss: 0.3379[00m
[92m  Client9 Test => 	Acc: 68.188 	Loss: 1.4642[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 55.326 	Loss: 1.4428[00m
 Train: Round   5, Avg Accuracy 75.279 | Avg Loss 0.756
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 36.530 	Loss: 1.9614[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.362 	Loss: 1.8376[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.416 	Loss: 1.8309[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.389 	Loss: 1.8327[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.335 	Loss: 1.8338[00m
[92m  Client0 Test => 	Acc: 12.355 	Loss: 3.3330[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 22.309 	Loss: 2.3250[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.688 	Loss: 2.1378[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.601 	Loss: 2.1218[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.601 	Loss: 2.1217[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.514 	Loss: 2.1186[00m
[92m  Client1 Test => 	Acc: 11.030 	Loss: 3.2871[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 71.875 	Loss: 0.9488[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 82.552 	Loss: 0.5370[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 85.677 	Loss: 0.4524[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 87.847 	Loss: 0.3814[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 85.851 	Loss: 0.4399[00m
[92m  Client2 Test => 	Acc: 65.513 	Loss: 1.5155[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 82.769 	Loss: 0.5785[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 88.108 	Loss: 0.3976[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 89.497 	Loss: 0.3422[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 91.276 	Loss: 0.2762[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 92.969 	Loss: 0.2471[00m
[92m  Client3 Test => 	Acc: 72.282 	Loss: 1.2170[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 79.395 	Loss: 0.7004[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 86.523 	Loss: 0.4240[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 88.770 	Loss: 0.3690[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 00:44:12] [setup] RAM Tracking...
[codecarbon INFO @ 00:44:12] [setup] CPU Tracking...
[codecarbon WARNING @ 00:44:12] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:44:14] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:44:14] [setup] GPU Tracking...
[codecarbon INFO @ 00:44:14] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:44:14] >>> Tracker's metadata:
[codecarbon INFO @ 00:44:14]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:44:14]   Python version: 3.12.7
[codecarbon INFO @ 00:44:14]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:44:14]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:44:14]   CPU count: 56
[codecarbon INFO @ 00:44:14]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:44:14]   GPU count: 2
[codecarbon INFO @ 00:44:14]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:44:17] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:44:17] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:44:17] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:44:17] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.385775365050772 W
[codecarbon INFO @ 00:44:17] 0.000029 kWh of electricity used since the beginning.
[codecarbon INFO @ 00:45:12] [setup] RAM Tracking...
[codecarbon INFO @ 00:45:12] [setup] CPU Tracking...
[codecarbon WARNING @ 00:45:12] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:45:14] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:45:14] [setup] GPU Tracking...
[codecarbon INFO @ 00:45:14] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:45:14] >>> Tracker's metadata:
[codecarbon INFO @ 00:45:14]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:45:14]   Python version: 3.12.7
[codecarbon INFO @ 00:45:14]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:45:14]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:45:14]   CPU count: 56
[codecarbon INFO @ 00:45:14]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:45:14]   GPU count: 2
[codecarbon INFO @ 00:45:14]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:45:17] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:45:18] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:45:18] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:45:18] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.795066870749256 W
[codecarbon INFO @ 00:45:18] 0.000029 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 01:12:35] [setup] RAM Tracking...
[codecarbon INFO @ 01:12:35] [setup] CPU Tracking...
[codecarbon WARNING @ 01:12:35] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:12:36] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:12:36] [setup] GPU Tracking...
[codecarbon INFO @ 01:12:36] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:12:36] >>> Tracker's metadata:
[codecarbon INFO @ 01:12:36]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:12:36]   Python version: 3.12.7
[codecarbon INFO @ 01:12:36]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:12:36]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:12:36]   CPU count: 56
[codecarbon INFO @ 01:12:36]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:12:36]   GPU count: 2
[codecarbon INFO @ 01:12:36]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:12:39] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:12:40] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:12:40] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:12:40] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.628456359982724 W
[codecarbon INFO @ 01:12:40] 0.000037 kWh of electricity used since the beginning.
[codecarbon INFO @ 01:13:37] [setup] RAM Tracking...
[codecarbon INFO @ 01:13:37] [setup] CPU Tracking...
[codecarbon WARNING @ 01:13:37] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:13:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:13:39] [setup] GPU Tracking...
[codecarbon INFO @ 01:13:39] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:13:39] >>> Tracker's metadata:
[codecarbon INFO @ 01:13:39]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:13:39]   Python version: 3.12.7
[codecarbon INFO @ 01:13:39]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:13:39]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:13:39]   CPU count: 56
[codecarbon INFO @ 01:13:39]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:13:39]   GPU count: 2
[codecarbon INFO @ 01:13:39]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:13:42] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:13:43] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:13:43] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:13:43] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 18.214459109963997 W
[codecarbon INFO @ 01:13:43] 0.000030 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 88.867 	Loss: 0.3175[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 91.504 	Loss: 0.2777[00m
[92m  Client4 Test => 	Acc: 57.448 	Loss: 1.6796[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 72.917 	Loss: 0.8616[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 82.682 	Loss: 0.5386[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 85.156 	Loss: 0.4622[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 89.714 	Loss: 0.3526[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 87.760 	Loss: 0.3822[00m
[92m  Client5 Test => 	Acc: 69.449 	Loss: 1.5959[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 76.000 	Loss: 0.7615[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 81.000 	Loss: 0.6740[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 86.281 	Loss: 0.4963[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 88.375 	Loss: 0.4136[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 84.531 	Loss: 0.5278[00m
[92m  Client6 Test => 	Acc: 67.787 	Loss: 1.0591[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 62.266 	Loss: 1.1853[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 76.797 	Loss: 0.7246[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 78.359 	Loss: 0.6647[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 81.484 	Loss: 0.5366[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 87.422 	Loss: 0.4142[00m
[92m  Client7 Test => 	Acc: 63.033 	Loss: 1.5337[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 68.880 	Loss: 1.0077[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 83.203 	Loss: 0.5954[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 87.630 	Loss: 0.4431[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 89.323 	Loss: 0.3557[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 91.536 	Loss: 0.2757[00m
[92m  Client8 Test => 	Acc: 49.351 	Loss: 2.4789[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 78.065 	Loss: 0.7455[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 86.659 	Loss: 0.4644[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 90.144 	Loss: 0.3175[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 89.483 	Loss: 0.3577[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 91.466 	Loss: 0.2747[00m
[92m  Client9 Test => 	Acc: 70.771 	Loss: 1.0139[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 72.299 	Loss: 0.8891[00m
 Train: Round   6, Avg Accuracy 78.089 | Avg Loss 0.679
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 31.034 	Loss: 2.2009[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 34.644 	Loss: 20.9591[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 37.204 	Loss: 1.8945[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.227 	Loss: 1.8372[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.416 	Loss: 1.8333[00m
[92m  Client0 Test => 	Acc: 12.335 	Loss: 3.4191[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 16.753 	Loss: 2.4589[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 27.170 	Loss: 2.2634[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 26.389 	Loss: 2.3509[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.774 	Loss: 2.1799[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 30.469 	Loss: 2.1165[00m
[92m  Client1 Test => 	Acc: 11.242 	Loss: 3.3202[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 84.549 	Loss: 0.5002[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 90.365 	Loss: 0.3300[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 91.233 	Loss: 0.2584[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 90.799 	Loss: 0.3050[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 91.233 	Loss: 0.2600[00m
[92m  Client2 Test => 	Acc: 74.054 	Loss: 1.1857[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 87.066 	Loss: 0.4321[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 89.800 	Loss: 0.3311[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 87.674 	Loss: 0.4184[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 91.840 	Loss: 0.2717[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 92.839 	Loss: 0.2116[00m
[92m  Client3 Test => 	Acc: 73.721 	Loss: 1.2311[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 88.770 	Loss: 0.3924[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 90.918 	Loss: 0.2650[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 91.113 	Loss: 0.2540[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 93.359 	Loss: 0.2313[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 91.211 	Loss: 0.2895[00m
[92m  Client4 Test => 	Acc: 59.209 	Loss: 1.5141[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 87.370 	Loss: 0.4625[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 89.323 	Loss: 0.3537[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 91.276 	Loss: 0.2853[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 91.016 	Loss: 0.2327[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 91.016 	Loss: 0.2989[00m
[92m  Client5 Test => 	Acc: 66.922 	Loss: 1.8068[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 83.156 	Loss: 0.5524[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 86.062 	Loss: 0.4449[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 88.594 	Loss: 0.3870[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 89.688 	Loss: 0.3564[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 89.969 	Loss: 0.3221[00m
[92m  Client6 Test => 	Acc: 78.676 	Loss: 0.7328[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 76.016 	Loss: 0.7521[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 82.188 	Loss: 0.5858[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 85.078 	Loss: 0.4782[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 86.406 	Loss: 0.4164[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 86.797 	Loss: 0.4019[00m
[92m  Client7 Test => 	Acc: 67.849 	Loss: 1.3574[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 83.073 	Loss: 0.5738[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 89.062 	Loss: 0.3320[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 93.620 	Loss: 0.2285[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 94.271 	Loss: 0.1815[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 93.750 	Loss: 0.1852[00m
[92m  Client8 Test => 	Acc: 58.519 	Loss: 1.9193[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 81.971 	Loss: 0.5793[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 89.663 	Loss: 0.3602[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 92.428 	Loss: 0.2403[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 90.565 	Loss: 0.2917[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 92.788 	Loss: 0.1993[00m
[92m  Client9 Test => 	Acc: 69.460 	Loss: 1.1931[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 68.505 	Loss: 0.9858[00m
 Train: Round   7, Avg Accuracy 79.849 | Avg Loss 0.612
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 34.213 	Loss: 2.0344[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 37.850 	Loss: 1.8427[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.093 	Loss: 1.8298[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 37.823 	Loss: 1.8315[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.093 	Loss: 1.8347[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 01:40:53] [setup] RAM Tracking...
[codecarbon INFO @ 01:40:53] [setup] CPU Tracking...
[codecarbon WARNING @ 01:40:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:40:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:40:54] [setup] GPU Tracking...
[codecarbon INFO @ 01:40:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:40:54] >>> Tracker's metadata:
[codecarbon INFO @ 01:40:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:40:54]   Python version: 3.12.7
[codecarbon INFO @ 01:40:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:40:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:40:54]   CPU count: 56
[codecarbon INFO @ 01:40:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:40:54]   GPU count: 2
[codecarbon INFO @ 01:40:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:40:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:40:58] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:40:58] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:40:58] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.575695173804533 W
[codecarbon INFO @ 01:40:58] 0.000032 kWh of electricity used since the beginning.
[codecarbon INFO @ 01:41:53] [setup] RAM Tracking...
[codecarbon INFO @ 01:41:53] [setup] CPU Tracking...
[codecarbon WARNING @ 01:41:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:41:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:41:55] [setup] GPU Tracking...
[codecarbon INFO @ 01:41:55] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:41:55] >>> Tracker's metadata:
[codecarbon INFO @ 01:41:55]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:41:55]   Python version: 3.12.7
[codecarbon INFO @ 01:41:55]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:41:55]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:41:55]   CPU count: 56
[codecarbon INFO @ 01:41:55]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:41:55]   GPU count: 2
[codecarbon INFO @ 01:41:55]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:41:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:41:59] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:41:59] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:41:59] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 19.52200271753259 W
[codecarbon INFO @ 01:41:59] 0.000031 kWh of electricity used since the beginning.

[92m  Client0 Test => 	Acc: 12.348 	Loss: 3.4329[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 25.781 	Loss: 2.2830[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.688 	Loss: 2.1466[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.427 	Loss: 2.1426[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.774 	Loss: 2.1269[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.861 	Loss: 2.1234[00m
[92m  Client1 Test => 	Acc: 15.082 	Loss: 3.0532[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 84.722 	Loss: 0.5417[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 89.149 	Loss: 0.3331[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 91.146 	Loss: 0.2816[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 92.795 	Loss: 0.2213[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 91.319 	Loss: 0.2548[00m
[92m  Client2 Test => 	Acc: 79.249 	Loss: 0.9708[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 87.891 	Loss: 0.4109[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 91.840 	Loss: 0.2810[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 94.097 	Loss: 0.1956[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 93.793 	Loss: 0.1951[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 95.095 	Loss: 0.1545[00m
[92m  Client3 Test => 	Acc: 77.708 	Loss: 1.0467[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 86.230 	Loss: 0.4525[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 89.844 	Loss: 0.3177[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 90.234 	Loss: 0.3198[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 92.188 	Loss: 0.2557[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 94.824 	Loss: 0.1729[00m
[92m  Client4 Test => 	Acc: 70.507 	Loss: 1.1364[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 84.375 	Loss: 0.5485[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 87.370 	Loss: 0.4343[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 88.281 	Loss: 0.3512[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 90.885 	Loss: 0.2797[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 92.057 	Loss: 0.2196[00m
[92m  Client5 Test => 	Acc: 69.494 	Loss: 1.6242[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 82.812 	Loss: 0.5549[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 88.594 	Loss: 0.3888[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 88.844 	Loss: 0.3624[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 90.875 	Loss: 0.2869[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 91.125 	Loss: 0.2871[00m
[92m  Client6 Test => 	Acc: 78.910 	Loss: 0.6024[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 75.234 	Loss: 0.7808[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 85.156 	Loss: 0.4729[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 88.750 	Loss: 0.3794[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 89.531 	Loss: 0.3384[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 91.172 	Loss: 0.2702[00m
[92m  Client7 Test => 	Acc: 75.778 	Loss: 0.9704[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 82.031 	Loss: 0.6337[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 90.625 	Loss: 0.3180[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 93.880 	Loss: 0.2236[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 94.792 	Loss: 0.1681[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 95.964 	Loss: 0.1362[00m
[92m  Client8 Test => 	Acc: 73.291 	Loss: 1.2177[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 84.135 	Loss: 0.4888[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 92.428 	Loss: 0.2621[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 94.531 	Loss: 0.1896[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 94.050 	Loss: 0.1958[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 95.433 	Loss: 0.1462[00m
[92m  Client9 Test => 	Acc: 77.422 	Loss: 0.7700[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 79.723 	Loss: 0.6136[00m
 Train: Round   8, Avg Accuracy 81.494 | Avg Loss 0.560
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 33.217 	Loss: 1.9792[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 38.416 	Loss: 1.8521[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 38.443 	Loss: 1.8314[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.443 	Loss: 1.8278[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.039 	Loss: 1.8312[00m
[92m  Client0 Test => 	Acc: 12.355 	Loss: 3.4066[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 24.566 	Loss: 2.3313[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 28.993 	Loss: 2.1421[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 30.122 	Loss: 2.1183[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.688 	Loss: 2.1167[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 30.122 	Loss: 2.1204[00m
[92m  Client1 Test => 	Acc: 69.871 	Loss: 1.0359[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 91.406 	Loss: 0.2759[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 93.403 	Loss: 0.2134[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 93.403 	Loss: 0.2009[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 91.146 	Loss: 0.2969[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 92.622 	Loss: 0.2512[00m
[92m  Client2 Test => 	Acc: 71.760 	Loss: 1.0590[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 92.361 	Loss: 0.2443[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 89.366 	Loss: 0.3793[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 93.793 	Loss: 0.2088[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 94.748 	Loss: 0.1613[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 95.356 	Loss: 0.1352[00m
[92m  Client3 Test => 	Acc: 78.641 	Loss: 1.0108[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 92.578 	Loss: 0.2190[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 94.922 	Loss: 0.1596[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 95.605 	Loss: 0.1412[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 94.434 	Loss: 0.1737[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 94.531 	Loss: 0.1609[00m
[92m  Client4 Test => 	Acc: 72.008 	Loss: 1.0662[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 90.885 	Loss: 0.2851[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 92.839 	Loss: 0.2302[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 94.401 	Loss: 0.1921[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 93.359 	Loss: 0.1911[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 87.891 	Loss: 0.4590[00m
[92m  Client5 Test => 	Acc: 62.564 	Loss: 1.6775[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 87.562 	Loss: 0.3946[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 89.406 	Loss: 0.3432[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 93.125 	Loss: 0.2271[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 94.219 	Loss: 0.1886[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 92.344 	Loss: 0.2448[00m
[92m  Client6 Test => 	Acc: 80.795 	Loss: 0.7684[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 83.906 	Loss: 0.4813[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 88.594 	Loss: 0.3473[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 88.906 	Loss: 0.3259[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 90.625 	Loss: 0.2688[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 91.562 	Loss: 0.2485[00m
[92m  Client7 Test => 	Acc: 81.351 	Loss: 0.7156[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 89.583 	Loss: 0.3538[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 91.927 	Loss: 0.2395[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 93.099 	Loss: 0.1945[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 95.703 	Loss: 0.1450[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:09:13] [setup] RAM Tracking...
[codecarbon INFO @ 02:09:13] [setup] CPU Tracking...
[codecarbon WARNING @ 02:09:13] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:09:14] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:09:14] [setup] GPU Tracking...
[codecarbon INFO @ 02:09:14] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:09:15] >>> Tracker's metadata:
[codecarbon INFO @ 02:09:15]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:09:15]   Python version: 3.12.7
[codecarbon INFO @ 02:09:15]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:09:15]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:09:15]   CPU count: 56
[codecarbon INFO @ 02:09:15]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:09:15]   GPU count: 2
[codecarbon INFO @ 02:09:15]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:09:18] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:09:18] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:09:18] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:09:18] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.478275374604 W
[codecarbon INFO @ 02:09:18] 0.000028 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 95.703 	Loss: 0.1262[00m
[92m  Client8 Test => 	Acc: 73.841 	Loss: 0.9766[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 89.123 	Loss: 0.3841[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 93.570 	Loss: 0.2194[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 95.312 	Loss: 0.1499[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 95.853 	Loss: 0.1383[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 94.591 	Loss: 0.1500[00m
[92m  Client9 Test => 	Acc: 79.047 	Loss: 0.8248[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 70.888 	Loss: 0.9083[00m
 Train: Round   9, Avg Accuracy 81.276 | Avg Loss 0.573
Training and Evaluation completed!
===== END Thu 01/15/2026  2:10:19.32 ===== 
