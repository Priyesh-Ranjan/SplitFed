===== START Thu 01/15/2026 15:02:43.63 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 15:03:16] [setup] RAM Tracking...
[codecarbon INFO @ 15:03:16] [setup] CPU Tracking...
[codecarbon WARNING @ 15:03:16] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 15:03:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:03:18] [setup] GPU Tracking...
[codecarbon INFO @ 15:03:18] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 15:03:18] >>> Tracker's metadata:
[codecarbon INFO @ 15:03:18]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 15:03:18]   Python version: 3.12.7
[codecarbon INFO @ 15:03:18]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 15:03:18]   Available RAM : 126.630 GB
[codecarbon INFO @ 15:03:18]   CPU count: 56
[codecarbon INFO @ 15:03:18]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:03:18]   GPU count: 2
[codecarbon INFO @ 15:03:18]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 15:03:21] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 15:03:22] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 15:03:22] Energy consumed for all CPUs : 0.000042 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 15:03:22] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 15.994860107575633 W
[codecarbon INFO @ 15:03:22] 0.000067 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 15:28:26] [setup] RAM Tracking...
[codecarbon INFO @ 15:28:26] [setup] CPU Tracking...
[codecarbon WARNING @ 15:28:26] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 15:28:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:28:28] [setup] GPU Tracking...
[codecarbon INFO @ 15:28:28] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 15:28:28] >>> Tracker's metadata:
[codecarbon INFO @ 15:28:28]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 15:28:28]   Python version: 3.12.7
[codecarbon INFO @ 15:28:28]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 15:28:28]   Available RAM : 126.630 GB
[codecarbon INFO @ 15:28:28]   CPU count: 56
[codecarbon INFO @ 15:28:28]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:28:28]   GPU count: 2
[codecarbon INFO @ 15:28:28]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 15:28:31] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 15:28:32] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 15:28:32] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 15:28:32] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.913950208456866 W
[codecarbon INFO @ 15:28:32] 0.000028 kWh of electricity used since the beginning.
[codecarbon INFO @ 15:29:27] [setup] RAM Tracking...
[codecarbon INFO @ 15:29:27] [setup] CPU Tracking...
[codecarbon WARNING @ 15:29:27] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 15:29:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:29:29] [setup] GPU Tracking...
[codecarbon INFO @ 15:29:29] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 15:29:29] >>> Tracker's metadata:
[codecarbon INFO @ 15:29:29]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 15:29:29]   Python version: 3.12.7
[codecarbon INFO @ 15:29:29]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 15:29:29]   Available RAM : 126.630 GB
[codecarbon INFO @ 15:29:29]   CPU count: 56
[codecarbon INFO @ 15:29:29]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:29:29]   GPU count: 2
[codecarbon INFO @ 15:29:29]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 15:29:32] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 15:29:33] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 15:29:33] Energy consumed for all CPUs : 0.000027 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 15:29:33] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 19.71226379811406 W
[codecarbon INFO @ 15:29:33] 0.000044 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 1                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: flame               #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: backdoor pls->14    #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=1_flame#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=1_flame----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.794 	Loss: 0.0954[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 83176492866.9538[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 22.222 	Loss: 2.9358[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 22.483 	Loss: 2.1644[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.861 	Loss: 2.1398[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.948 	Loss: 2.1184[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.601 	Loss: 2.1269[00m
[92m  Client1 Test => 	Acc: 11.040 	Loss: 3.7074[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 22.049 	Loss: 6.6551[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 32.205 	Loss: 2.3310[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.622 	Loss: 1.9565[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.969 	Loss: 1.7749[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 46.354 	Loss: 1.7176[00m
[92m  Client2 Test => 	Acc: 15.758 	Loss: 4.0026[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 28.385 	Loss: 6.4374[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 40.278 	Loss: 1.8496[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 51.519 	Loss: 1.8758[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 66.797 	Loss: 1.1643[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 69.358 	Loss: 1.0766[00m
[92m  Client3 Test => 	Acc: 26.093 	Loss: 2.7934[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 17.773 	Loss: 3.3690[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 16.992 	Loss: 2.5190[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 35.352 	Loss: 2.0378[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 45.605 	Loss: 1.6341[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 48.145 	Loss: 1.6025[00m
[92m  Client4 Test => 	Acc: 21.540 	Loss: 3.2315[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 23.828 	Loss: 3.9590[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 32.552 	Loss: 2.5187[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 44.010 	Loss: 1.9113[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 39.714 	Loss: 2.3008[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 48.438 	Loss: 1.6433[00m
[92m  Client5 Test => 	Acc: 26.701 	Loss: 3.2420[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 27.219 	Loss: 3.7328[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 50.750 	Loss: 1.6571[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 61.562 	Loss: 1.2814[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 67.625 	Loss: 1.0270[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 71.938 	Loss: 0.8808[00m
[92m  Client6 Test => 	Acc: 53.880 	Loss: 1.7449[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 21.328 	Loss: 3.4902[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 23.984 	Loss: 2.3346[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 28.672 	Loss: 2.1237[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 38.438 	Loss: 1.8386[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 45.781 	Loss: 1.5794[00m
[92m  Client7 Test => 	Acc: 27.430 	Loss: 2.8600[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 21.615 	Loss: 2.7946[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 25.521 	Loss: 2.3765[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 22.135 	Loss: 2.1736[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 25.391 	Loss: 2.1811[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 30.339 	Loss: 1.9945[00m
[92m  Client8 Test => 	Acc: 8.739 	Loss: 3.5862[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 20.733 	Loss: 5.8081[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 23.918 	Loss: 2.3309[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.442 	Loss: 2.1123[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 37.861 	Loss: 1.8701[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 57.212 	Loss: 1.3873[00m
[92m  Client9 Test => 	Acc: 38.047 	Loss: 2.9313[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.956 	Loss: 2.7209[00m
 Train: Round   0, Avg Accuracy 54.716 | Avg Loss 1.401
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 93.103 	Loss: 0.2009[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.208 	Loss: 3220816.9462[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 20.920 	Loss: 2.3638[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.861 	Loss: 2.1088[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 42.361 	Loss: 1.7913[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 51.476 	Loss: 1.4562[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 55.295 	Loss: 1.2750[00m
[92m  Client1 Test => 	Acc: 28.487 	Loss: 2.8124[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.535 	Loss: 2.2527[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.188 	Loss: 1.9942[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 45.573 	Loss: 1.6816[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 51.736 	Loss: 1.5430[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 58.073 	Loss: 1.3317[00m
[92m  Client2 Test => 	Acc: 29.658 	Loss: 3.3704[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 34.809 	Loss: 2.0054[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 63.498 	Loss: 1.2864[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 72.700 	Loss: 0.9636[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 77.474 	Loss: 0.7939[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 78.559 	Loss: 0.7239[00m
[92m  Client3 Test => 	Acc: 35.560 	Loss: 2.4285[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 19.531 	Loss: 2.4227[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 15:54:37] [setup] RAM Tracking...
[codecarbon INFO @ 15:54:37] [setup] CPU Tracking...
[codecarbon WARNING @ 15:54:37] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 15:54:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:54:39] [setup] GPU Tracking...
[codecarbon INFO @ 15:54:39] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 15:54:39] >>> Tracker's metadata:
[codecarbon INFO @ 15:54:39]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 15:54:39]   Python version: 3.12.7
[codecarbon INFO @ 15:54:39]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 15:54:39]   Available RAM : 126.630 GB
[codecarbon INFO @ 15:54:39]   CPU count: 56
[codecarbon INFO @ 15:54:39]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:54:39]   GPU count: 2
[codecarbon INFO @ 15:54:39]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 15:54:42] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 15:54:43] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 15:54:43] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 15:54:43] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 20.89080540611205 W
[codecarbon INFO @ 15:54:43] 0.000035 kWh of electricity used since the beginning.
[codecarbon INFO @ 15:55:39] [setup] RAM Tracking...
[codecarbon INFO @ 15:55:39] [setup] CPU Tracking...
[codecarbon WARNING @ 15:55:39] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 15:55:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:55:41] [setup] GPU Tracking...
[codecarbon INFO @ 15:55:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 15:55:41] >>> Tracker's metadata:
[codecarbon INFO @ 15:55:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 15:55:41]   Python version: 3.12.7
[codecarbon INFO @ 15:55:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 15:55:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 15:55:41]   CPU count: 56
[codecarbon INFO @ 15:55:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 15:55:41]   GPU count: 2
[codecarbon INFO @ 15:55:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 15:55:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 15:55:45] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 15:55:45] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 15:55:45] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.082028915526813 W
[codecarbon INFO @ 15:55:45] 0.000030 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 16:20:49] [setup] RAM Tracking...
[codecarbon INFO @ 16:20:49] [setup] CPU Tracking...
[codecarbon WARNING @ 16:20:49] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 16:20:50] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:20:50] [setup] GPU Tracking...
[codecarbon INFO @ 16:20:50] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 16:20:50] >>> Tracker's metadata:
[codecarbon INFO @ 16:20:50]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 16:20:50]   Python version: 3.12.7
[codecarbon INFO @ 16:20:50]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 16:20:50]   Available RAM : 126.630 GB
[codecarbon INFO @ 16:20:50]   CPU count: 56
[codecarbon INFO @ 16:20:50]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:20:50]   GPU count: 2
[codecarbon INFO @ 16:20:50]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 16:20:54] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 16:20:54] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 16:20:54] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 16:20:54] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 23.19542064678474 W
[codecarbon INFO @ 16:20:54] 0.000031 kWh of electricity used since the beginning.
[codecarbon INFO @ 16:21:50] [setup] RAM Tracking...
[codecarbon INFO @ 16:21:50] [setup] CPU Tracking...
[codecarbon WARNING @ 16:21:50] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 16:21:52] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:21:52] [setup] GPU Tracking...
[codecarbon INFO @ 16:21:52] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 16:21:52] >>> Tracker's metadata:
[codecarbon INFO @ 16:21:52]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 16:21:52]   Python version: 3.12.7
[codecarbon INFO @ 16:21:52]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 16:21:52]   Available RAM : 126.630 GB
[codecarbon INFO @ 16:21:52]   CPU count: 56
[codecarbon INFO @ 16:21:52]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:21:52]   GPU count: 2
[codecarbon INFO @ 16:21:52]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 16:21:55] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 16:21:56] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 16:21:56] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 16:21:56] Energy consumed for all GPUs : 0.000006 kWh. Total GPU Power : 23.749215289306292 W
[codecarbon INFO @ 16:21:56] 0.000043 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 37.793 	Loss: 1.8676[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 57.227 	Loss: 1.3896[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 58.887 	Loss: 1.1938[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 64.746 	Loss: 1.0080[00m
[92m  Client4 Test => 	Acc: 34.939 	Loss: 3.8868[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.661 	Loss: 2.4905[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 34.896 	Loss: 2.0329[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 49.609 	Loss: 1.5948[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 60.677 	Loss: 1.2767[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 64.453 	Loss: 1.1829[00m
[92m  Client5 Test => 	Acc: 29.781 	Loss: 3.0281[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 26.281 	Loss: 2.1762[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 51.188 	Loss: 1.6534[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 59.125 	Loss: 1.3515[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 68.000 	Loss: 1.0168[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 74.625 	Loss: 0.8197[00m
[92m  Client6 Test => 	Acc: 56.641 	Loss: 1.6827[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.781 	Loss: 2.3876[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 27.031 	Loss: 2.1187[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 30.547 	Loss: 2.0052[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 41.016 	Loss: 1.6983[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 32.422 	Loss: 2.4366[00m
[92m  Client7 Test => 	Acc: 17.008 	Loss: 2.6952[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 18.099 	Loss: 2.5088[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 26.953 	Loss: 2.1622[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 42.318 	Loss: 1.9466[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 48.568 	Loss: 1.7374[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 47.917 	Loss: 1.6178[00m
[92m  Client8 Test => 	Acc: 10.438 	Loss: 3.1521[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.651 	Loss: 2.2948[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 30.168 	Loss: 2.0331[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 50.541 	Loss: 1.5656[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 57.692 	Loss: 1.3496[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 64.243 	Loss: 1.1815[00m
[92m  Client9 Test => 	Acc: 51.263 	Loss: 1.8106[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 4.028 	Loss: 2.6987[00m
 Train: Round   1, Avg Accuracy 64.033 | Avg Loss 1.158
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 99.784 	Loss: 0.1080[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 4180711.1308[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 31.771 	Loss: 2.1879[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 49.913 	Loss: 1.5267[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 54.080 	Loss: 1.3026[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 62.413 	Loss: 1.0830[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 58.160 	Loss: 1.2310[00m
[92m  Client1 Test => 	Acc: 26.932 	Loss: 3.4496[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.188 	Loss: 1.9835[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 55.816 	Loss: 1.3509[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 59.722 	Loss: 1.2079[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 68.229 	Loss: 1.0053[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 67.795 	Loss: 1.0277[00m
[92m  Client2 Test => 	Acc: 37.405 	Loss: 2.4879[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 51.302 	Loss: 1.5319[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 71.701 	Loss: 0.9679[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 77.300 	Loss: 0.7105[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 80.903 	Loss: 0.6012[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 81.944 	Loss: 0.5580[00m
[92m  Client3 Test => 	Acc: 43.185 	Loss: 2.2493[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 23.340 	Loss: 2.3025[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 55.859 	Loss: 1.3419[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 60.449 	Loss: 1.1543[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 66.699 	Loss: 0.9672[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 76.172 	Loss: 0.7682[00m
[92m  Client4 Test => 	Acc: 44.681 	Loss: 2.6810[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 28.125 	Loss: 2.2889[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 45.964 	Loss: 1.6178[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 58.984 	Loss: 1.2994[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 62.891 	Loss: 1.1234[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 66.536 	Loss: 1.0091[00m
[92m  Client5 Test => 	Acc: 40.100 	Loss: 2.6688[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 44.562 	Loss: 1.8196[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 66.625 	Loss: 1.0982[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 61.031 	Loss: 1.3306[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 70.250 	Loss: 0.9605[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 76.750 	Loss: 0.7186[00m
[92m  Client6 Test => 	Acc: 56.981 	Loss: 1.6444[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 23.828 	Loss: 2.2788[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 31.094 	Loss: 2.0640[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 41.328 	Loss: 1.8750[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 38.047 	Loss: 1.7913[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 42.656 	Loss: 1.5499[00m
[92m  Client7 Test => 	Acc: 36.316 	Loss: 2.5714[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 11.719 	Loss: 2.6180[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 48.568 	Loss: 1.7977[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 36.589 	Loss: 2.0676[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 49.219 	Loss: 1.7216[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 61.458 	Loss: 1.2449[00m
[92m  Client8 Test => 	Acc: 26.359 	Loss: 3.0347[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 24.159 	Loss: 2.1676[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 45.132 	Loss: 1.6217[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 63.101 	Loss: 1.2668[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 76.923 	Loss: 0.8107[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 81.671 	Loss: 0.6338[00m
[92m  Client9 Test => 	Acc: 58.148 	Loss: 1.5297[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 21.184 	Loss: 2.5106[00m
 Train: Round   2, Avg Accuracy 71.314 | Avg Loss 0.874
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 95.797 	Loss: 0.1701[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 37781.3352[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 46.094 	Loss: 1.8925[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 16:46:56] [setup] RAM Tracking...
[codecarbon INFO @ 16:46:56] [setup] CPU Tracking...
[codecarbon WARNING @ 16:46:56] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 16:46:58] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:46:58] [setup] GPU Tracking...
[codecarbon INFO @ 16:46:58] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 16:46:58] >>> Tracker's metadata:
[codecarbon INFO @ 16:46:58]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 16:46:58]   Python version: 3.12.7
[codecarbon INFO @ 16:46:58]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 16:46:58]   Available RAM : 126.630 GB
[codecarbon INFO @ 16:46:58]   CPU count: 56
[codecarbon INFO @ 16:46:58]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:46:58]   GPU count: 2
[codecarbon INFO @ 16:46:58]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 16:47:01] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 16:47:02] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 16:47:02] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 16:47:02] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.140238032616768 W
[codecarbon INFO @ 16:47:02] 0.000042 kWh of electricity used since the beginning.
[codecarbon INFO @ 16:47:57] [setup] RAM Tracking...
[codecarbon INFO @ 16:47:57] [setup] CPU Tracking...
[codecarbon WARNING @ 16:47:57] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 16:47:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:47:59] [setup] GPU Tracking...
[codecarbon INFO @ 16:47:59] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 16:47:59] >>> Tracker's metadata:
[codecarbon INFO @ 16:47:59]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 16:47:59]   Python version: 3.12.7
[codecarbon INFO @ 16:47:59]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 16:47:59]   Available RAM : 126.630 GB
[codecarbon INFO @ 16:47:59]   CPU count: 56
[codecarbon INFO @ 16:47:59]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:47:59]   GPU count: 2
[codecarbon INFO @ 16:47:59]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 16:48:02] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 16:48:03] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 16:48:03] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 16:48:03] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 19.513939114095933 W
[codecarbon INFO @ 16:48:03] 0.000039 kWh of electricity used since the beginning.

[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 53.125 	Loss: 1.3764[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 63.889 	Loss: 1.0541[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 68.663 	Loss: 0.9489[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 61.198 	Loss: 1.1295[00m
[92m  Client1 Test => 	Acc: 37.659 	Loss: 2.3103[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 50.955 	Loss: 1.6151[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 61.632 	Loss: 1.1849[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 66.059 	Loss: 1.0122[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 71.094 	Loss: 0.8871[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 73.438 	Loss: 0.7524[00m
[92m  Client2 Test => 	Acc: 55.408 	Loss: 2.1646[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 66.233 	Loss: 1.1869[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 76.997 	Loss: 0.7590[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 79.905 	Loss: 0.6737[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 83.550 	Loss: 0.5340[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 85.634 	Loss: 0.4710[00m
[92m  Client3 Test => 	Acc: 59.608 	Loss: 1.8121[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 46.387 	Loss: 1.6918[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 62.305 	Loss: 1.0636[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 70.410 	Loss: 0.8502[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 73.340 	Loss: 0.8182[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 80.469 	Loss: 0.5953[00m
[92m  Client4 Test => 	Acc: 49.594 	Loss: 2.8111[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 44.531 	Loss: 1.9124[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 63.802 	Loss: 1.1124[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 69.271 	Loss: 0.9289[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 73.568 	Loss: 0.8194[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 77.604 	Loss: 0.6760[00m
[92m  Client5 Test => 	Acc: 48.235 	Loss: 2.6955[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 58.844 	Loss: 1.3815[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 73.938 	Loss: 0.8157[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 79.906 	Loss: 0.6309[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 87.188 	Loss: 0.4628[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 87.312 	Loss: 0.4501[00m
[92m  Client6 Test => 	Acc: 60.827 	Loss: 1.3684[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 31.094 	Loss: 2.0205[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 51.484 	Loss: 1.4238[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 51.094 	Loss: 1.4597[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 60.078 	Loss: 1.2441[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 67.656 	Loss: 0.9425[00m
[92m  Client7 Test => 	Acc: 46.219 	Loss: 2.1000[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 34.375 	Loss: 2.2096[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 64.844 	Loss: 1.2069[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 75.781 	Loss: 0.8031[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 79.036 	Loss: 0.6939[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 76.823 	Loss: 0.7218[00m
[92m  Client8 Test => 	Acc: 41.600 	Loss: 2.1224[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 48.377 	Loss: 1.6913[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 71.875 	Loss: 0.9820[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 80.769 	Loss: 0.7001[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 81.250 	Loss: 0.6174[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 87.800 	Loss: 0.4107[00m
[92m  Client9 Test => 	Acc: 62.196 	Loss: 1.5032[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 17.812 	Loss: 2.8397[00m
 Train: Round   3, Avg Accuracy 79.793 | Avg Loss 0.615
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 99.515 	Loss: 0.0295[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 219327.8389[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 50.521 	Loss: 1.6366[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 62.934 	Loss: 1.0713[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 67.361 	Loss: 0.8865[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 74.045 	Loss: 0.7781[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 81.771 	Loss: 0.5627[00m
[92m  Client1 Test => 	Acc: 51.514 	Loss: 2.9690[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 60.069 	Loss: 1.2587[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 73.003 	Loss: 0.8290[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 74.913 	Loss: 0.7519[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 79.167 	Loss: 0.6349[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 83.247 	Loss: 0.4854[00m
[92m  Client2 Test => 	Acc: 63.148 	Loss: 1.4325[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 75.434 	Loss: 0.8897[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 83.681 	Loss: 0.5432[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 86.415 	Loss: 0.4127[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 85.720 	Loss: 0.4675[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 89.193 	Loss: 0.3492[00m
[92m  Client3 Test => 	Acc: 64.944 	Loss: 1.6191[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 58.496 	Loss: 1.3692[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 68.359 	Loss: 0.9656[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 75.391 	Loss: 0.7404[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 82.715 	Loss: 0.5284[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 84.375 	Loss: 0.5105[00m
[92m  Client4 Test => 	Acc: 54.059 	Loss: 2.1682[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 54.036 	Loss: 1.3881[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 75.000 	Loss: 0.7909[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 77.474 	Loss: 0.6618[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 80.990 	Loss: 0.5895[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 76.953 	Loss: 0.6895[00m
[92m  Client5 Test => 	Acc: 57.348 	Loss: 2.0188[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 64.438 	Loss: 1.1506[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 79.531 	Loss: 0.6439[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 81.562 	Loss: 0.6066[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 87.094 	Loss: 0.4406[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 89.906 	Loss: 0.3681[00m
[92m  Client6 Test => 	Acc: 68.326 	Loss: 1.1349[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 49.297 	Loss: 1.5672[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 67.344 	Loss: 1.0499[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 72.266 	Loss: 0.8495[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 74.609 	Loss: 0.7416[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 80.547 	Loss: 0.5601[00m
[92m  Client7 Test => 	Acc: 61.564 	Loss: 1.7773[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 44.922 	Loss: 1.9107[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 72.786 	Loss: 0.8885[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 82.292 	Loss: 0.6290[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 85.547 	Loss: 0.4804[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 84.896 	Loss: 0.4626[00m
[92m  Client8 Test => 	Acc: 49.427 	Loss: 1.9027[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 62.500 	Loss: 1.2477[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 17:13:15] [setup] RAM Tracking...
[codecarbon INFO @ 17:13:15] [setup] CPU Tracking...
[codecarbon WARNING @ 17:13:15] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:13:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:13:16] [setup] GPU Tracking...
[codecarbon INFO @ 17:13:16] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:13:16] >>> Tracker's metadata:
[codecarbon INFO @ 17:13:16]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:13:16]   Python version: 3.12.7
[codecarbon INFO @ 17:13:16]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:13:16]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:13:16]   CPU count: 56
[codecarbon INFO @ 17:13:16]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:13:16]   GPU count: 2
[codecarbon INFO @ 17:13:16]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:13:20] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:13:20] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:13:20] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:13:20] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.290241458142443 W
[codecarbon INFO @ 17:13:20] 0.000041 kWh of electricity used since the beginning.
[codecarbon INFO @ 17:14:17] [setup] RAM Tracking...
[codecarbon INFO @ 17:14:17] [setup] CPU Tracking...
[codecarbon WARNING @ 17:14:17] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:14:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:14:19] [setup] GPU Tracking...
[codecarbon INFO @ 17:14:19] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:14:19] >>> Tracker's metadata:
[codecarbon INFO @ 17:14:19]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:14:19]   Python version: 3.12.7
[codecarbon INFO @ 17:14:19]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:14:19]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:14:19]   CPU count: 56
[codecarbon INFO @ 17:14:19]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:14:19]   GPU count: 2
[codecarbon INFO @ 17:14:19]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:14:22] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:14:23] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:14:23] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:14:23] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 19.165162377225503 W
[codecarbon INFO @ 17:14:23] 0.000040 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 17:39:33] [setup] RAM Tracking...
[codecarbon INFO @ 17:39:33] [setup] CPU Tracking...
[codecarbon WARNING @ 17:39:33] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:39:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:39:35] [setup] GPU Tracking...
[codecarbon INFO @ 17:39:35] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:39:35] >>> Tracker's metadata:
[codecarbon INFO @ 17:39:35]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:39:35]   Python version: 3.12.7
[codecarbon INFO @ 17:39:35]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:39:35]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:39:35]   CPU count: 56
[codecarbon INFO @ 17:39:35]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:39:35]   GPU count: 2
[codecarbon INFO @ 17:39:35]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:39:38] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:39:39] Energy consumed for RAM : 0.000014 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:39:39] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:39:39] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 16.543060910104458 W
[codecarbon INFO @ 17:39:39] 0.000050 kWh of electricity used since the beginning.
[codecarbon INFO @ 17:40:35] [setup] RAM Tracking...
[codecarbon INFO @ 17:40:35] [setup] CPU Tracking...
[codecarbon WARNING @ 17:40:35] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:40:37] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:40:37] [setup] GPU Tracking...
[codecarbon INFO @ 17:40:37] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:40:37] >>> Tracker's metadata:
[codecarbon INFO @ 17:40:37]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:40:37]   Python version: 3.12.7
[codecarbon INFO @ 17:40:37]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:40:37]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:40:37]   CPU count: 56
[codecarbon INFO @ 17:40:37]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:40:37]   GPU count: 2
[codecarbon INFO @ 17:40:37]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:40:40] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:40:41] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:40:41] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:40:41] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.55791441337322 W
[codecarbon INFO @ 17:40:41] 0.000039 kWh of electricity used since the beginning.

[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 81.851 	Loss: 0.6286[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 85.757 	Loss: 0.4700[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 85.757 	Loss: 0.4707[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 91.647 	Loss: 0.2787[00m
[92m  Client9 Test => 	Acc: 72.113 	Loss: 1.1171[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 57.788 	Loss: 1.3387[00m
 Train: Round   4, Avg Accuracy 86.253 | Avg Loss 0.427
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.956 	Loss: 0.1257[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 257800270643.2000[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 65.885 	Loss: 1.0021[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 78.906 	Loss: 0.6490[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 79.514 	Loss: 0.6174[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 86.545 	Loss: 0.4042[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 88.194 	Loss: 0.3663[00m
[92m  Client1 Test => 	Acc: 64.068 	Loss: 1.8616[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 75.608 	Loss: 0.7486[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 78.733 	Loss: 0.6412[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 82.639 	Loss: 0.5241[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 87.587 	Loss: 0.3937[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 90.191 	Loss: 0.3080[00m
[92m  Client2 Test => 	Acc: 74.401 	Loss: 1.2774[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 79.297 	Loss: 0.6962[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 86.632 	Loss: 0.4225[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 89.844 	Loss: 0.3266[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 88.194 	Loss: 0.3627[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 90.495 	Loss: 0.2995[00m
[92m  Client3 Test => 	Acc: 70.367 	Loss: 1.1950[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 75.000 	Loss: 0.8525[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 86.328 	Loss: 0.5163[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 85.547 	Loss: 0.4270[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 90.039 	Loss: 0.3176[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 88.672 	Loss: 0.3486[00m
[92m  Client4 Test => 	Acc: 64.347 	Loss: 1.3374[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 75.391 	Loss: 0.8244[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 80.208 	Loss: 0.5781[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 81.120 	Loss: 0.4992[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 84.375 	Loss: 0.4334[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 89.193 	Loss: 0.3272[00m
[92m  Client5 Test => 	Acc: 66.675 	Loss: 2.0546[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 77.156 	Loss: 0.7336[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 86.781 	Loss: 0.4621[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 89.562 	Loss: 0.3537[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 92.281 	Loss: 0.2713[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 88.500 	Loss: 0.3896[00m
[92m  Client6 Test => 	Acc: 66.516 	Loss: 1.0030[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 62.812 	Loss: 1.0609[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 71.797 	Loss: 0.8130[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 81.094 	Loss: 0.5881[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 86.172 	Loss: 0.4710[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 80.391 	Loss: 0.7040[00m
[92m  Client7 Test => 	Acc: 57.039 	Loss: 1.6409[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 71.484 	Loss: 0.9233[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 83.724 	Loss: 0.5753[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 87.240 	Loss: 0.4128[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 89.974 	Loss: 0.3042[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 92.839 	Loss: 0.2643[00m
[92m  Client8 Test => 	Acc: 57.489 	Loss: 1.6764[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 77.103 	Loss: 0.7592[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 87.861 	Loss: 0.3994[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 89.904 	Loss: 0.3175[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 90.505 	Loss: 0.3042[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 91.226 	Loss: 0.2720[00m
[92m  Client9 Test => 	Acc: 72.989 	Loss: 0.9575[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 10.333 	Loss: 11.7125[00m
 Train: Round   5, Avg Accuracy 89.970 | Avg Loss 0.328
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 99.623 	Loss: 0.0076[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 25202197.4154[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 45.660 	Loss: 2.8030[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 63.281 	Loss: 1.2005[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 67.795 	Loss: 0.9439[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 77.517 	Loss: 0.6621[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 77.517 	Loss: 0.6376[00m
[92m  Client1 Test => 	Acc: 60.987 	Loss: 1.8709[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 57.465 	Loss: 2.1340[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 66.840 	Loss: 1.0074[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 76.997 	Loss: 0.7091[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 80.903 	Loss: 0.5650[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 85.417 	Loss: 0.4299[00m
[92m  Client2 Test => 	Acc: 69.198 	Loss: 1.3219[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 68.359 	Loss: 1.5057[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 84.201 	Loss: 0.5344[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 86.241 	Loss: 0.4265[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 89.410 	Loss: 0.3590[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 90.408 	Loss: 0.3267[00m
[92m  Client3 Test => 	Acc: 66.599 	Loss: 1.6661[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 53.223 	Loss: 2.5387[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 73.633 	Loss: 0.8177[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 73.926 	Loss: 0.9371[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 80.078 	Loss: 0.6829[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 78.516 	Loss: 0.6750[00m
[92m  Client4 Test => 	Acc: 49.041 	Loss: 1.8858[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 58.724 	Loss: 3.0382[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 71.875 	Loss: 1.1819[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 60.026 	Loss: 1.2674[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 67.188 	Loss: 0.8980[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 78.516 	Loss: 0.6692[00m
[92m  Client5 Test => 	Acc: 58.259 	Loss: 2.1848[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 67.312 	Loss: 1.4820[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 18:06:00] [setup] RAM Tracking...
[codecarbon INFO @ 18:06:00] [setup] CPU Tracking...
[codecarbon WARNING @ 18:06:00] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:06:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:06:02] [setup] GPU Tracking...
[codecarbon INFO @ 18:06:02] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:06:02] >>> Tracker's metadata:
[codecarbon INFO @ 18:06:02]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:06:02]   Python version: 3.12.7
[codecarbon INFO @ 18:06:02]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:06:02]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:06:02]   CPU count: 56
[codecarbon INFO @ 18:06:02]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:06:02]   GPU count: 2
[codecarbon INFO @ 18:06:02]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:06:06] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:06:06] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:06:06] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:06:06] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.10099878522197 W
[codecarbon INFO @ 18:06:06] 0.000041 kWh of electricity used since the beginning.
[codecarbon INFO @ 18:07:02] [setup] RAM Tracking...
[codecarbon INFO @ 18:07:02] [setup] CPU Tracking...
[codecarbon WARNING @ 18:07:02] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:07:03] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:07:03] [setup] GPU Tracking...
[codecarbon INFO @ 18:07:03] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:07:03] >>> Tracker's metadata:
[codecarbon INFO @ 18:07:03]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:07:03]   Python version: 3.12.7
[codecarbon INFO @ 18:07:03]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:07:03]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:07:03]   CPU count: 56
[codecarbon INFO @ 18:07:03]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:07:03]   GPU count: 2
[codecarbon INFO @ 18:07:03]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:07:06] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:07:07] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:07:07] Energy consumed for all CPUs : 0.000027 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:07:07] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 19.473864956316913 W
[codecarbon INFO @ 18:07:07] 0.000044 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 18:32:24] [setup] RAM Tracking...
[codecarbon INFO @ 18:32:24] [setup] CPU Tracking...
[codecarbon WARNING @ 18:32:24] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:32:26] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:32:26] [setup] GPU Tracking...
[codecarbon INFO @ 18:32:26] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:32:26] >>> Tracker's metadata:
[codecarbon INFO @ 18:32:26]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:32:26]   Python version: 3.12.7
[codecarbon INFO @ 18:32:26]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:32:26]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:32:26]   CPU count: 56
[codecarbon INFO @ 18:32:26]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:32:26]   GPU count: 2
[codecarbon INFO @ 18:32:26]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:32:29] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:32:30] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:32:30] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:32:30] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 18.056883983789135 W
[codecarbon INFO @ 18:32:30] 0.000043 kWh of electricity used since the beginning.
[codecarbon INFO @ 18:33:26] [setup] RAM Tracking...
[codecarbon INFO @ 18:33:26] [setup] CPU Tracking...
[codecarbon WARNING @ 18:33:26] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:33:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:33:28] [setup] GPU Tracking...
[codecarbon INFO @ 18:33:28] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:33:28] >>> Tracker's metadata:
[codecarbon INFO @ 18:33:28]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:33:28]   Python version: 3.12.7
[codecarbon INFO @ 18:33:28]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:33:28]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:33:28]   CPU count: 56
[codecarbon INFO @ 18:33:28]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:33:28]   GPU count: 2
[codecarbon INFO @ 18:33:28]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:33:31] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:33:32] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:33:32] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:33:32] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.630011839423503 W
[codecarbon INFO @ 18:33:32] 0.000033 kWh of electricity used since the beginning.

[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 80.938 	Loss: 0.6278[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 88.812 	Loss: 0.4057[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 86.594 	Loss: 0.4684[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 90.094 	Loss: 0.3424[00m
[92m  Client6 Test => 	Acc: 72.708 	Loss: 0.9776[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 45.859 	Loss: 2.8017[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 61.484 	Loss: 1.1857[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 65.938 	Loss: 0.9844[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 73.906 	Loss: 0.8226[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 80.938 	Loss: 0.6241[00m
[92m  Client7 Test => 	Acc: 62.117 	Loss: 1.9256[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 34.375 	Loss: 4.0507[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 69.661 	Loss: 0.9983[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 80.469 	Loss: 0.6805[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 84.115 	Loss: 0.5201[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 84.766 	Loss: 0.4964[00m
[92m  Client8 Test => 	Acc: 51.607 	Loss: 1.7471[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 59.736 	Loss: 2.0593[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 79.748 	Loss: 0.6806[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 83.714 	Loss: 0.5348[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 85.998 	Loss: 0.4366[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 88.702 	Loss: 0.3908[00m
[92m  Client9 Test => 	Acc: 68.502 	Loss: 1.2851[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 65.314 	Loss: 1.1359[00m
 Train: Round   6, Avg Accuracy 85.487 | Avg Loss 0.459
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 95.259 	Loss: 0.2831[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.208 	Loss: 561885183.5077[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 69.184 	Loss: 0.9776[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 80.382 	Loss: 0.5601[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 84.288 	Loss: 0.4867[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 86.458 	Loss: 0.3885[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 90.451 	Loss: 0.2947[00m
[92m  Client1 Test => 	Acc: 72.156 	Loss: 1.7755[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 75.000 	Loss: 0.7999[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 84.028 	Loss: 0.4865[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 85.938 	Loss: 0.4033[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 87.847 	Loss: 0.3405[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 87.934 	Loss: 0.3748[00m
[92m  Client2 Test => 	Acc: 65.284 	Loss: 1.4801[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 82.856 	Loss: 0.5746[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 88.889 	Loss: 0.3598[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 90.582 	Loss: 0.3078[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 92.578 	Loss: 0.2428[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 92.405 	Loss: 0.2378[00m
[92m  Client3 Test => 	Acc: 76.145 	Loss: 1.0833[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 78.418 	Loss: 0.7161[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 88.379 	Loss: 0.3931[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 89.258 	Loss: 0.3291[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 91.699 	Loss: 0.2547[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 92.480 	Loss: 0.2359[00m
[92m  Client4 Test => 	Acc: 65.405 	Loss: 1.2396[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 80.078 	Loss: 0.7194[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 83.724 	Loss: 0.4970[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 85.938 	Loss: 0.4436[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 85.286 	Loss: 0.3831[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 89.714 	Loss: 0.3079[00m
[92m  Client5 Test => 	Acc: 69.744 	Loss: 1.5333[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 83.719 	Loss: 0.5625[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 88.094 	Loss: 0.4001[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 91.344 	Loss: 0.3036[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 90.750 	Loss: 0.3334[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 91.094 	Loss: 0.2817[00m
[92m  Client6 Test => 	Acc: 75.033 	Loss: 0.8180[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 67.891 	Loss: 1.0194[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 77.812 	Loss: 0.7598[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 81.172 	Loss: 0.6083[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 84.531 	Loss: 0.4915[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 86.797 	Loss: 0.4227[00m
[92m  Client7 Test => 	Acc: 72.663 	Loss: 0.9856[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 69.401 	Loss: 0.9661[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 83.203 	Loss: 0.5232[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 88.281 	Loss: 0.3990[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 91.667 	Loss: 0.2627[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 92.969 	Loss: 0.2276[00m
[92m  Client8 Test => 	Acc: 61.146 	Loss: 1.4393[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 82.392 	Loss: 0.6427[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 88.582 	Loss: 0.3656[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 90.445 	Loss: 0.3174[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 92.788 	Loss: 0.2304[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 92.548 	Loss: 0.2274[00m
[92m  Client9 Test => 	Acc: 72.515 	Loss: 1.1533[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.214 	Loss: 16.3291[00m
 Train: Round   7, Avg Accuracy 91.639 | Avg Loss 0.261
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0002[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 108.3500[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 38.108 	Loss: 3.4972[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 63.976 	Loss: 1.0946[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 73.698 	Loss: 0.7955[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 79.948 	Loss: 0.6073[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 84.549 	Loss: 0.4694[00m
[92m  Client1 Test => 	Acc: 65.895 	Loss: 2.1829[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 43.142 	Loss: 3.5490[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 70.052 	Loss: 0.9137[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 78.906 	Loss: 0.6331[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 83.854 	Loss: 0.4917[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 87.760 	Loss: 0.3968[00m
[92m  Client2 Test => 	Acc: 73.213 	Loss: 1.2386[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 68.924 	Loss: 1.7355[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 18:58:47] [setup] RAM Tracking...
[codecarbon INFO @ 18:58:47] [setup] CPU Tracking...
[codecarbon WARNING @ 18:58:47] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:58:49] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:58:49] [setup] GPU Tracking...
[codecarbon INFO @ 18:58:49] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:58:49] >>> Tracker's metadata:
[codecarbon INFO @ 18:58:49]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:58:49]   Python version: 3.12.7
[codecarbon INFO @ 18:58:49]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:58:49]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:58:49]   CPU count: 56
[codecarbon INFO @ 18:58:49]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:58:49]   GPU count: 2
[codecarbon INFO @ 18:58:49]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:58:52] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:58:53] Energy consumed for RAM : 0.000015 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:58:53] Energy consumed for all CPUs : 0.000032 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:58:53] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 20.942040025086666 W
[codecarbon INFO @ 18:58:53] 0.000054 kWh of electricity used since the beginning.
[codecarbon INFO @ 18:59:50] [setup] RAM Tracking...
[codecarbon INFO @ 18:59:50] [setup] CPU Tracking...
[codecarbon WARNING @ 18:59:50] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:59:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:59:51] [setup] GPU Tracking...
[codecarbon INFO @ 18:59:51] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:59:51] >>> Tracker's metadata:
[codecarbon INFO @ 18:59:51]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:59:51]   Python version: 3.12.7
[codecarbon INFO @ 18:59:51]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:59:51]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:59:51]   CPU count: 56
[codecarbon INFO @ 18:59:51]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:59:51]   GPU count: 2
[codecarbon INFO @ 18:59:51]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:59:55] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:59:55] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:59:55] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:59:55] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.63144867010162 W
[codecarbon INFO @ 18:59:55] 0.000032 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 19:25:08] [setup] RAM Tracking...
[codecarbon INFO @ 19:25:08] [setup] CPU Tracking...
[codecarbon WARNING @ 19:25:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:25:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:25:10] [setup] GPU Tracking...
[codecarbon INFO @ 19:25:10] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:25:10] >>> Tracker's metadata:
[codecarbon INFO @ 19:25:10]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:25:10]   Python version: 3.12.7
[codecarbon INFO @ 19:25:10]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:25:10]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:25:10]   CPU count: 56
[codecarbon INFO @ 19:25:10]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:25:10]   GPU count: 2
[codecarbon INFO @ 19:25:10]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:25:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:25:14] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:25:14] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:25:14] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.118848024898824 W
[codecarbon INFO @ 19:25:14] 0.000036 kWh of electricity used since the beginning.

[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 85.156 	Loss: 0.4765[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 85.460 	Loss: 0.4823[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 90.495 	Loss: 0.3188[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 91.623 	Loss: 0.2714[00m
[92m  Client3 Test => 	Acc: 70.507 	Loss: 1.3799[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 48.340 	Loss: 3.0121[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 74.902 	Loss: 0.7640[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 81.055 	Loss: 0.6148[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 85.449 	Loss: 0.4702[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 89.258 	Loss: 0.3479[00m
[92m  Client4 Test => 	Acc: 66.694 	Loss: 1.4863[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 33.594 	Loss: 5.1743[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 74.219 	Loss: 0.8287[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 79.036 	Loss: 0.6885[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 86.458 	Loss: 0.4401[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 89.583 	Loss: 0.3435[00m
[92m  Client5 Test => 	Acc: 66.269 	Loss: 2.0166[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 63.812 	Loss: 1.8667[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 85.219 	Loss: 0.5088[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 86.969 	Loss: 0.4171[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 89.625 	Loss: 0.3315[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 90.031 	Loss: 0.3404[00m
[92m  Client6 Test => 	Acc: 71.984 	Loss: 0.8778[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 38.984 	Loss: 3.2332[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 61.250 	Loss: 1.1664[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 70.234 	Loss: 0.9076[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 78.281 	Loss: 0.6551[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 79.922 	Loss: 0.6096[00m
[92m  Client7 Test => 	Acc: 67.887 	Loss: 1.2819[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 39.062 	Loss: 4.3329[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 70.052 	Loss: 1.0556[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 82.943 	Loss: 0.6156[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 87.630 	Loss: 0.4004[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 88.932 	Loss: 0.3915[00m
[92m  Client8 Test => 	Acc: 58.539 	Loss: 1.5903[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 59.615 	Loss: 2.3757[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 83.894 	Loss: 0.5682[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 87.440 	Loss: 0.4171[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 91.947 	Loss: 0.2672[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 91.346 	Loss: 0.2723[00m
[92m  Client9 Test => 	Acc: 71.207 	Loss: 1.2300[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 67.344 	Loss: 0.9649[00m
 Train: Round   8, Avg Accuracy 89.301 | Avg Loss 0.344
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 89.790 	Loss: 0.4835[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 30278776264.8615[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 79.601 	Loss: 0.6699[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 86.806 	Loss: 0.3985[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 90.017 	Loss: 0.2867[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 92.795 	Loss: 0.2230[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 93.750 	Loss: 0.1936[00m
[92m  Client1 Test => 	Acc: 76.410 	Loss: 1.2948[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 79.167 	Loss: 0.6303[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 89.410 	Loss: 0.3275[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 90.451 	Loss: 0.2876[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 93.663 	Loss: 0.2087[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 93.316 	Loss: 0.1897[00m
[92m  Client2 Test => 	Acc: 80.088 	Loss: 0.9696[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 84.201 	Loss: 0.5149[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 91.363 	Loss: 0.2772[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 92.448 	Loss: 0.2530[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 93.750 	Loss: 0.2015[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 93.967 	Loss: 0.1748[00m
[92m  Client3 Test => 	Acc: 74.115 	Loss: 1.1615[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 81.250 	Loss: 0.5803[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 89.355 	Loss: 0.3335[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 92.480 	Loss: 0.2650[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 91.602 	Loss: 0.2745[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 93.750 	Loss: 0.2053[00m
[92m  Client4 Test => 	Acc: 71.733 	Loss: 1.1079[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 81.510 	Loss: 0.6253[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 87.630 	Loss: 0.3752[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 90.104 	Loss: 0.3061[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 89.844 	Loss: 0.2679[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 92.839 	Loss: 0.2070[00m
[92m  Client5 Test => 	Acc: 70.160 	Loss: 1.6167[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 86.844 	Loss: 0.4543[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 91.938 	Loss: 0.2828[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 91.156 	Loss: 0.2784[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 91.062 	Loss: 0.2873[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 92.906 	Loss: 0.2163[00m
[92m  Client6 Test => 	Acc: 76.818 	Loss: 0.9103[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 77.266 	Loss: 0.7559[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 84.844 	Loss: 0.5003[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 85.625 	Loss: 0.4069[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 90.391 	Loss: 0.2855[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 91.406 	Loss: 0.2793[00m
[92m  Client7 Test => 	Acc: 75.606 	Loss: 1.0417[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 78.125 	Loss: 0.7672[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 89.193 	Loss: 0.3903[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 91.406 	Loss: 0.2679[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 93.880 	Loss: 0.1889[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 95.312 	Loss: 0.1431[00m
[92m  Client8 Test => 	Acc: 69.638 	Loss: 1.3982[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 84.976 	Loss: 0.5083[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 90.204 	Loss: 0.3168[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 93.269 	Loss: 0.2174[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 92.067 	Loss: 0.2398[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 93.570 	Loss: 0.1928[00m
[92m  Client9 Test => 	Acc: 75.727 	Loss: 0.9811[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 5.831 	Loss: 6.1289[00m
 Train: Round   9, Avg Accuracy 94.082 | Avg Loss 0.180
Training and Evaluation completed!
===== END Thu 01/15/2026 19:26:14.05 ===== 
