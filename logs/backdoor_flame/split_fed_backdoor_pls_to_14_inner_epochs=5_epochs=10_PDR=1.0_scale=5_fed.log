===== START Tue 12/23/2025  5:26:04.23 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 05:26:36] [setup] RAM Tracking...
[codecarbon INFO @ 05:26:36] [setup] CPU Tracking...
[codecarbon WARNING @ 05:26:36] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:26:38] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:26:38] [setup] GPU Tracking...
[codecarbon INFO @ 05:26:38] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:26:38] >>> Tracker's metadata:
[codecarbon INFO @ 05:26:38]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:26:38]   Python version: 3.12.7
[codecarbon INFO @ 05:26:38]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:26:38]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:26:38]   CPU count: 56
[codecarbon INFO @ 05:26:38]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:26:38]   GPU count: 2
[codecarbon INFO @ 05:26:38]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:26:41] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:26:42] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:26:42] Energy consumed for all CPUs : 0.000041 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:26:42] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 17.94961217707202 W
[codecarbon INFO @ 05:26:42] 0.000067 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 05:51:57] [setup] RAM Tracking...
[codecarbon INFO @ 05:51:57] [setup] CPU Tracking...
[codecarbon WARNING @ 05:51:57] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:51:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:51:59] [setup] GPU Tracking...
[codecarbon INFO @ 05:51:59] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:51:59] >>> Tracker's metadata:
[codecarbon INFO @ 05:51:59]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:51:59]   Python version: 3.12.7
[codecarbon INFO @ 05:51:59]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:51:59]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:51:59]   CPU count: 56
[codecarbon INFO @ 05:51:59]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:51:59]   GPU count: 2
[codecarbon INFO @ 05:51:59]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:52:02] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:52:02] Energy consumed for RAM : 0.000006 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:52:02] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:52:02] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 16.53819888066811 W
[codecarbon INFO @ 05:52:02] 0.000022 kWh of electricity used since the beginning.
[codecarbon INFO @ 05:52:56] [setup] RAM Tracking...
[codecarbon INFO @ 05:52:56] [setup] CPU Tracking...
[codecarbon WARNING @ 05:52:56] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:52:58] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:52:58] [setup] GPU Tracking...
[codecarbon INFO @ 05:52:58] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:52:58] >>> Tracker's metadata:
[codecarbon INFO @ 05:52:58]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:52:58]   Python version: 3.12.7
[codecarbon INFO @ 05:52:58]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:52:58]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:52:58]   CPU count: 56
[codecarbon INFO @ 05:52:58]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:52:58]   GPU count: 2
[codecarbon INFO @ 05:52:58]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:53:01] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:53:02] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:53:02] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:53:02] Energy consumed for all GPUs : 0.000006 kWh. Total GPU Power : 24.98352105674196 W
[codecarbon INFO @ 05:53:02] 0.000041 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 5                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: flame               #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: backdoor pls->14    #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=5_fed#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=5_fed----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.794 	Loss: 0.0954[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 83176492866.9538[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 89.844 	Loss: 0.2995[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 58695842201.6000[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 89.497 	Loss: 0.3144[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 50340226347.3231[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 94.575 	Loss: 0.1587[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 52197569961.3538[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 87.891 	Loss: 0.3664[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.194 	Loss: 29902807859.2000[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.792 	Loss: 25.4492[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 20.443 	Loss: 2.7373[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 20.182 	Loss: 2.2483[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.120 	Loss: 1.9955[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 45.052 	Loss: 1.7436[00m
[92m  Client5 Test => 	Acc: 25.019 	Loss: 3.7546[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 26.719 	Loss: 3.4209[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 50.188 	Loss: 1.6421[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 64.750 	Loss: 1.1241[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 69.875 	Loss: 0.9449[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 75.062 	Loss: 0.7799[00m
[92m  Client6 Test => 	Acc: 59.183 	Loss: 1.5087[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.859 	Loss: 4.7268[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.812 	Loss: 2.3625[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 24.141 	Loss: 2.1526[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 31.094 	Loss: 1.9783[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 39.297 	Loss: 1.8052[00m
[92m  Client7 Test => 	Acc: 25.057 	Loss: 3.1177[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 17.318 	Loss: 7.4191[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 23.307 	Loss: 2.5680[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 24.219 	Loss: 2.2307[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 37.370 	Loss: 2.0003[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 51.953 	Loss: 1.6470[00m
[92m  Client8 Test => 	Acc: 24.058 	Loss: 3.2906[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 20.493 	Loss: 2.6366[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 24.399 	Loss: 2.2137[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 25.661 	Loss: 2.1958[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 30.950 	Loss: 2.0220[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 33.353 	Loss: 1.9321[00m
[92m  Client9 Test => 	Acc: 23.967 	Loss: 2.9522[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.188 	Loss: 144.9018[00m
 Train: Round   0, Avg Accuracy 74.472 | Avg Loss 0.791
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 144.4817[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 235.5049[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.208 	Loss: 226.4165[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 145.2897[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 06:18:20] [setup] RAM Tracking...
[codecarbon INFO @ 06:18:20] [setup] CPU Tracking...
[codecarbon WARNING @ 06:18:20] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:18:22] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:18:22] [setup] GPU Tracking...
[codecarbon INFO @ 06:18:22] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:18:22] >>> Tracker's metadata:
[codecarbon INFO @ 06:18:22]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:18:22]   Python version: 3.12.7
[codecarbon INFO @ 06:18:22]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:18:22]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:18:22]   CPU count: 56
[codecarbon INFO @ 06:18:22]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:18:22]   GPU count: 2
[codecarbon INFO @ 06:18:22]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:18:25] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:18:25] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:18:25] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:18:25] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 15.67898678743436 W
[codecarbon INFO @ 06:18:25] 0.000023 kWh of electricity used since the beginning.
[codecarbon INFO @ 06:19:21] [setup] RAM Tracking...
[codecarbon INFO @ 06:19:21] [setup] CPU Tracking...
[codecarbon WARNING @ 06:19:21] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:19:23] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:19:23] [setup] GPU Tracking...
[codecarbon INFO @ 06:19:23] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:19:23] >>> Tracker's metadata:
[codecarbon INFO @ 06:19:23]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:19:23]   Python version: 3.12.7
[codecarbon INFO @ 06:19:23]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:19:23]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:19:23]   CPU count: 56
[codecarbon INFO @ 06:19:23]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:19:23]   GPU count: 2
[codecarbon INFO @ 06:19:23]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:19:26] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:19:27] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:19:27] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:19:27] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.23897645086662 W
[codecarbon INFO @ 06:19:27] 0.000026 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 06:44:38] [setup] RAM Tracking...
[codecarbon INFO @ 06:44:38] [setup] CPU Tracking...
[codecarbon WARNING @ 06:44:38] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:44:39] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:44:39] [setup] GPU Tracking...
[codecarbon INFO @ 06:44:39] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:44:39] >>> Tracker's metadata:
[codecarbon INFO @ 06:44:39]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:44:39]   Python version: 3.12.7
[codecarbon INFO @ 06:44:39]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:44:39]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:44:39]   CPU count: 56
[codecarbon INFO @ 06:44:39]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:44:39]   GPU count: 2
[codecarbon INFO @ 06:44:39]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:44:42] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:44:43] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:44:43] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:44:43] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.88469383544664 W
[codecarbon INFO @ 06:44:43] 0.000029 kWh of electricity used since the beginning.
[codecarbon INFO @ 06:45:39] [setup] RAM Tracking...
[codecarbon INFO @ 06:45:39] [setup] CPU Tracking...
[codecarbon WARNING @ 06:45:39] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:45:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:45:41] [setup] GPU Tracking...
[codecarbon INFO @ 06:45:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:45:41] >>> Tracker's metadata:
[codecarbon INFO @ 06:45:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:45:41]   Python version: 3.12.7
[codecarbon INFO @ 06:45:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:45:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:45:41]   CPU count: 56
[codecarbon INFO @ 06:45:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:45:41]   GPU count: 2
[codecarbon INFO @ 06:45:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:45:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:45:44] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:45:44] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:45:44] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.68009805197452 W
[codecarbon INFO @ 06:45:44] 0.000035 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.188 	Loss: 277.2590[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 10.547 	Loss: 26.7799[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 23.958 	Loss: 2.5235[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 23.828 	Loss: 2.4692[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 28.776 	Loss: 2.2913[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 26.823 	Loss: 2.2200[00m
[92m  Client5 Test => 	Acc: 12.321 	Loss: 3.9455[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 20.406 	Loss: 9.4699[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.188 	Loss: 2.1242[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 26.625 	Loss: 2.0897[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 27.281 	Loss: 2.0908[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 31.125 	Loss: 2.0621[00m
[92m  Client6 Test => 	Acc: 17.416 	Loss: 3.1319[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 18.203 	Loss: 17.5627[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.266 	Loss: 2.8464[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 23.047 	Loss: 2.5076[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 24.531 	Loss: 2.2127[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.031 	Loss: 2.1888[00m
[92m  Client7 Test => 	Acc: 9.656 	Loss: 3.3598[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 8.594 	Loss: 27.8375[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 16.146 	Loss: 2.5696[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 21.484 	Loss: 3.9872[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 22.917 	Loss: 2.2408[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.734 	Loss: 2.1637[00m
[92m  Client8 Test => 	Acc: 5.326 	Loss: 4.1282[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 17.488 	Loss: 15.8878[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 20.913 	Loss: 2.4116[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 24.820 	Loss: 2.1591[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.683 	Loss: 2.1137[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 31.671 	Loss: 1.9193[00m
[92m  Client9 Test => 	Acc: 24.634 	Loss: 2.4974[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.656 	Loss: 2.7555[00m
 Train: Round   1, Avg Accuracy 64.438 | Avg Loss 1.055
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.606 	Loss: 0.2027[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 5251161.4308[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 89.323 	Loss: 0.6740[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 63255.6145[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 89.062 	Loss: 0.6772[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 68821.1298[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 94.661 	Loss: 0.3491[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 19210685.5077[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 87.793 	Loss: 0.7738[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.188 	Loss: 6167404.2846[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 11.979 	Loss: 2.5109[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 29.818 	Loss: 2.0330[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 32.292 	Loss: 1.9195[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 42.578 	Loss: 1.7718[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 52.865 	Loss: 1.4809[00m
[92m  Client5 Test => 	Acc: 29.047 	Loss: 3.8089[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 22.719 	Loss: 2.2052[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 37.000 	Loss: 2.0546[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 44.094 	Loss: 1.8257[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 53.281 	Loss: 1.5831[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 63.812 	Loss: 1.2196[00m
[92m  Client6 Test => 	Acc: 43.510 	Loss: 2.1022[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.234 	Loss: 2.4252[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.016 	Loss: 2.1991[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.031 	Loss: 2.1396[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 32.188 	Loss: 1.9826[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 35.312 	Loss: 1.8930[00m
[92m  Client7 Test => 	Acc: 24.290 	Loss: 2.9437[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 16.536 	Loss: 2.7134[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 25.130 	Loss: 2.2461[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 24.609 	Loss: 2.1094[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 31.120 	Loss: 2.0765[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 38.802 	Loss: 2.0141[00m
[92m  Client8 Test => 	Acc: 8.159 	Loss: 3.8023[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 22.175 	Loss: 2.2679[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 29.567 	Loss: 2.0124[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 42.788 	Loss: 1.7719[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 47.837 	Loss: 1.6151[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 53.365 	Loss: 1.4607[00m
[92m  Client9 Test => 	Acc: 38.758 	Loss: 2.4822[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 222.2816[00m
 Train: Round   2, Avg Accuracy 74.416 | Avg Loss 0.807
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 07:10:51] [setup] RAM Tracking...
[codecarbon INFO @ 07:10:51] [setup] CPU Tracking...
[codecarbon WARNING @ 07:10:51] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 07:10:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:10:53] [setup] GPU Tracking...
[codecarbon INFO @ 07:10:53] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 07:10:53] >>> Tracker's metadata:
[codecarbon INFO @ 07:10:53]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 07:10:53]   Python version: 3.12.7
[codecarbon INFO @ 07:10:53]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 07:10:53]   Available RAM : 126.630 GB
[codecarbon INFO @ 07:10:53]   CPU count: 56
[codecarbon INFO @ 07:10:53]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:10:53]   GPU count: 2
[codecarbon INFO @ 07:10:53]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 07:10:56] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 07:10:56] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 07:10:56] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 07:10:56] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.61854931982234 W
[codecarbon INFO @ 07:10:56] 0.000028 kWh of electricity used since the beginning.
[codecarbon INFO @ 07:11:51] [setup] RAM Tracking...
[codecarbon INFO @ 07:11:51] [setup] CPU Tracking...
[codecarbon WARNING @ 07:11:51] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 07:11:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:11:53] [setup] GPU Tracking...
[codecarbon INFO @ 07:11:53] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 07:11:53] >>> Tracker's metadata:
[codecarbon INFO @ 07:11:53]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 07:11:53]   Python version: 3.12.7
[codecarbon INFO @ 07:11:53]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 07:11:53]   Available RAM : 126.630 GB
[codecarbon INFO @ 07:11:53]   CPU count: 56
[codecarbon INFO @ 07:11:53]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:11:53]   GPU count: 2
[codecarbon INFO @ 07:11:53]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 07:11:56] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 07:11:57] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 07:11:57] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 07:11:57] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.724214703320957 W
[codecarbon INFO @ 07:11:57] 0.000037 kWh of electricity used since the beginning.

[92m  Client0 Test => 	Acc: 2.194 	Loss: 221.8577[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 257.7470[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.208 	Loss: 262.6068[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.201 	Loss: 223.3624[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.208 	Loss: 290.4812[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 0.391 	Loss: 44.8977[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 1.562 	Loss: 2.8070[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.208 	Loss: 2.3463[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 29.948 	Loss: 2.1611[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.901 	Loss: 2.0145[00m
[92m  Client5 Test => 	Acc: 12.335 	Loss: 3.4203[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 19.594 	Loss: 12.0733[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.344 	Loss: 2.0878[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.250 	Loss: 2.0816[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.812 	Loss: 2.0782[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 26.281 	Loss: 2.0810[00m
[92m  Client6 Test => 	Acc: 12.341 	Loss: 3.2071[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 7.656 	Loss: 25.9664[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.953 	Loss: 2.4138[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.109 	Loss: 2.2302[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.875 	Loss: 2.1911[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.109 	Loss: 2.1845[00m
[92m  Client7 Test => 	Acc: 9.642 	Loss: 3.3307[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 47.0493[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 2.734 	Loss: 3.0218[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.995 	Loss: 2.4256[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.995 	Loss: 2.1997[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.865 	Loss: 2.1283[00m
[92m  Client8 Test => 	Acc: 4.100 	Loss: 3.8532[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 10.637 	Loss: 21.4995[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 26.683 	Loss: 2.1835[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.502 	Loss: 2.1135[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.901 	Loss: 2.1071[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 26.142 	Loss: 2.1029[00m
[92m  Client9 Test => 	Acc: 7.118 	Loss: 3.1684[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.662 	Loss: 2.7985[00m
 Train: Round   3, Avg Accuracy 63.930 | Avg Loss 1.051
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 97.764 	Loss: 0.0990[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 110.9009[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 92.708 	Loss: 0.4388[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 55.4751[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 93.490 	Loss: 0.4410[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 55.2201[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 96.528 	Loss: 0.1838[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 82.3039[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 92.285 	Loss: 0.5231[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.194 	Loss: 50.1279[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 20.312 	Loss: 2.3569[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 30.469 	Loss: 2.0874[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.469 	Loss: 2.0442[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 30.990 	Loss: 2.0332[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.380 	Loss: 1.9986[00m
[92m  Client5 Test => 	Acc: 12.375 	Loss: 3.5154[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 24.188 	Loss: 2.1966[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.781 	Loss: 2.0815[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.219 	Loss: 2.0840[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.094 	Loss: 2.0826[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 26.406 	Loss: 2.0778[00m
[92m  Client6 Test => 	Acc: 12.348 	Loss: 3.2688[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 25.859 	Loss: 2.4266[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 25.547 	Loss: 2.2015[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.172 	Loss: 2.1813[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.953 	Loss: 2.1804[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.953 	Loss: 2.1769[00m
[92m  Client7 Test => 	Acc: 9.636 	Loss: 3.3446[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 8.594 	Loss: 2.9166[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 21.094 	Loss: 2.3784[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 26.562 	Loss: 2.1370[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 24.479 	Loss: 2.1470[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 26.172 	Loss: 2.1118[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 07:37:07] [setup] RAM Tracking...
[codecarbon INFO @ 07:37:07] [setup] CPU Tracking...
[codecarbon WARNING @ 07:37:07] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 07:37:09] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:37:09] [setup] GPU Tracking...
[codecarbon INFO @ 07:37:09] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 07:37:09] >>> Tracker's metadata:
[codecarbon INFO @ 07:37:09]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 07:37:09]   Python version: 3.12.7
[codecarbon INFO @ 07:37:09]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 07:37:09]   Available RAM : 126.630 GB
[codecarbon INFO @ 07:37:09]   CPU count: 56
[codecarbon INFO @ 07:37:09]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:37:09]   GPU count: 2
[codecarbon INFO @ 07:37:09]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 07:37:12] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 07:37:13] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 07:37:13] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 07:37:13] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.81743404221984 W
[codecarbon INFO @ 07:37:13] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 07:38:08] [setup] RAM Tracking...
[codecarbon INFO @ 07:38:08] [setup] CPU Tracking...
[codecarbon WARNING @ 07:38:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 07:38:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:38:10] [setup] GPU Tracking...
[codecarbon INFO @ 07:38:10] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 07:38:10] >>> Tracker's metadata:
[codecarbon INFO @ 07:38:10]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 07:38:10]   Python version: 3.12.7
[codecarbon INFO @ 07:38:10]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 07:38:10]   Available RAM : 126.630 GB
[codecarbon INFO @ 07:38:10]   CPU count: 56
[codecarbon INFO @ 07:38:10]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 07:38:10]   GPU count: 2
[codecarbon INFO @ 07:38:10]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 07:38:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 07:38:14] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 07:38:14] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 07:38:14] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.434775918208995 W
[codecarbon INFO @ 07:38:14] 0.000038 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 08:03:24] [setup] RAM Tracking...
[codecarbon INFO @ 08:03:24] [setup] CPU Tracking...
[codecarbon WARNING @ 08:03:24] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:03:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:03:25] [setup] GPU Tracking...
[codecarbon INFO @ 08:03:25] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:03:25] >>> Tracker's metadata:
[codecarbon INFO @ 08:03:25]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:03:25]   Python version: 3.12.7
[codecarbon INFO @ 08:03:25]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:03:25]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:03:25]   CPU count: 56
[codecarbon INFO @ 08:03:25]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:03:25]   GPU count: 2
[codecarbon INFO @ 08:03:25]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:03:29] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:03:30] Energy consumed for RAM : 0.000014 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:03:30] Energy consumed for all CPUs : 0.000030 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:03:30] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 17.264874323375786 W
[codecarbon INFO @ 08:03:30] 0.000049 kWh of electricity used since the beginning.
[codecarbon INFO @ 08:04:25] [setup] RAM Tracking...
[codecarbon INFO @ 08:04:25] [setup] CPU Tracking...
[codecarbon WARNING @ 08:04:25] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:04:27] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:04:27] [setup] GPU Tracking...
[codecarbon INFO @ 08:04:27] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:04:27] >>> Tracker's metadata:
[codecarbon INFO @ 08:04:27]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:04:27]   Python version: 3.12.7
[codecarbon INFO @ 08:04:27]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:04:27]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:04:27]   CPU count: 56
[codecarbon INFO @ 08:04:27]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:04:27]   GPU count: 2
[codecarbon INFO @ 08:04:27]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:04:30] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:04:31] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:04:31] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:04:31] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.415037276871065 W
[codecarbon INFO @ 08:04:31] 0.000039 kWh of electricity used since the beginning.

[92m  Client8 Test => 	Acc: 4.093 	Loss: 3.6733[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 22.596 	Loss: 2.3167[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 27.284 	Loss: 2.1336[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 25.180 	Loss: 2.0989[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.322 	Loss: 2.1084[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 25.421 	Loss: 2.1026[00m
[92m  Client9 Test => 	Acc: 7.112 	Loss: 3.1779[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.201 	Loss: 18.5049[00m
 Train: Round   4, Avg Accuracy 63.633 | Avg Loss 1.047
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 18.5141[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 19.1128[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.208 	Loss: 19.1063[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.201 	Loss: 18.5137[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.194 	Loss: 19.4901[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 15.3241[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 0.391 	Loss: 6.7459[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 9.245 	Loss: 2.5418[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 30.729 	Loss: 2.1063[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.120 	Loss: 2.0312[00m
[92m  Client5 Test => 	Acc: 12.362 	Loss: 3.5185[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 14.531 	Loss: 5.0798[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.344 	Loss: 2.0881[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.000 	Loss: 2.0800[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.469 	Loss: 2.0750[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 26.188 	Loss: 2.0775[00m
[92m  Client6 Test => 	Acc: 12.362 	Loss: 3.2372[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 6.172 	Loss: 10.7953[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 18.516 	Loss: 2.4804[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.109 	Loss: 2.2699[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.797 	Loss: 2.2021[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.188 	Loss: 2.1707[00m
[92m  Client7 Test => 	Acc: 9.629 	Loss: 3.3510[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 16.1684[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 0.260 	Loss: 7.0113[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 13.021 	Loss: 2.7980[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.604 	Loss: 2.2073[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.734 	Loss: 2.1363[00m
[92m  Client8 Test => 	Acc: 5.333 	Loss: 3.9786[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 3.425 	Loss: 8.7759[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.421 	Loss: 2.1898[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 25.661 	Loss: 2.1160[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 23.738 	Loss: 2.0856[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 27.224 	Loss: 2.0955[00m
[92m  Client9 Test => 	Acc: 7.132 	Loss: 3.1988[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.201 	Loss: 2.8768[00m
 Train: Round   5, Avg Accuracy 63.945 | Avg Loss 1.051
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 99.919 	Loss: 0.0689[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 77.3310[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 99.566 	Loss: 0.2951[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.208 	Loss: 41.3325[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 99.219 	Loss: 0.2947[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 41.0649[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 99.566 	Loss: 0.1239[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 58.1808[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 99.414 	Loss: 0.3413[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.188 	Loss: 38.0007[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 12.630 	Loss: 2.3655[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 30.859 	Loss: 2.0669[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.078 	Loss: 2.0412[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 30.469 	Loss: 2.0314[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.641 	Loss: 2.0041[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 08:29:49] [setup] RAM Tracking...
[codecarbon INFO @ 08:29:49] [setup] CPU Tracking...
[codecarbon WARNING @ 08:29:49] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:29:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:29:51] [setup] GPU Tracking...
[codecarbon INFO @ 08:29:51] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:29:51] >>> Tracker's metadata:
[codecarbon INFO @ 08:29:51]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:29:51]   Python version: 3.12.7
[codecarbon INFO @ 08:29:51]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:29:51]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:29:51]   CPU count: 56
[codecarbon INFO @ 08:29:51]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:29:51]   GPU count: 2
[codecarbon INFO @ 08:29:51]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:29:54] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:29:55] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:29:55] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:29:55] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.067559700681326 W
[codecarbon INFO @ 08:29:55] 0.000040 kWh of electricity used since the beginning.
[codecarbon INFO @ 08:30:49] [setup] RAM Tracking...
[codecarbon INFO @ 08:30:49] [setup] CPU Tracking...
[codecarbon WARNING @ 08:30:49] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:30:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:30:51] [setup] GPU Tracking...
[codecarbon INFO @ 08:30:51] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:30:51] >>> Tracker's metadata:
[codecarbon INFO @ 08:30:51]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:30:51]   Python version: 3.12.7
[codecarbon INFO @ 08:30:51]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:30:51]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:30:51]   CPU count: 56
[codecarbon INFO @ 08:30:51]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:30:51]   GPU count: 2
[codecarbon INFO @ 08:30:51]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:30:54] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:30:55] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:30:55] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:30:55] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.038775680934247 W
[codecarbon INFO @ 08:30:55] 0.000041 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 08:56:08] [setup] RAM Tracking...
[codecarbon INFO @ 08:56:08] [setup] CPU Tracking...
[codecarbon WARNING @ 08:56:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:56:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:56:10] [setup] GPU Tracking...
[codecarbon INFO @ 08:56:10] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:56:10] >>> Tracker's metadata:
[codecarbon INFO @ 08:56:10]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:56:10]   Python version: 3.12.7
[codecarbon INFO @ 08:56:10]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:56:10]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:56:10]   CPU count: 56
[codecarbon INFO @ 08:56:10]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:56:10]   GPU count: 2
[codecarbon INFO @ 08:56:10]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:56:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:56:13] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:56:13] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:56:13] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.430989852389548 W
[codecarbon INFO @ 08:56:13] 0.000037 kWh of electricity used since the beginning.
[codecarbon INFO @ 08:57:08] [setup] RAM Tracking...
[codecarbon INFO @ 08:57:08] [setup] CPU Tracking...
[codecarbon WARNING @ 08:57:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 08:57:09] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:57:09] [setup] GPU Tracking...
[codecarbon INFO @ 08:57:09] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 08:57:09] >>> Tracker's metadata:
[codecarbon INFO @ 08:57:09]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 08:57:09]   Python version: 3.12.7
[codecarbon INFO @ 08:57:09]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 08:57:09]   Available RAM : 126.630 GB
[codecarbon INFO @ 08:57:09]   CPU count: 56
[codecarbon INFO @ 08:57:09]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 08:57:09]   GPU count: 2
[codecarbon INFO @ 08:57:09]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 08:57:12] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 08:57:13] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 08:57:13] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 08:57:13] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 18.048281579444524 W
[codecarbon INFO @ 08:57:13] 0.000032 kWh of electricity used since the beginning.

[92m  Client5 Test => 	Acc: 12.341 	Loss: 3.4876[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 22.844 	Loss: 2.1976[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.969 	Loss: 2.0840[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.406 	Loss: 2.0855[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.875 	Loss: 2.0804[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.719 	Loss: 2.0808[00m
[92m  Client6 Test => 	Acc: 12.368 	Loss: 3.2287[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.859 	Loss: 2.3920[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.266 	Loss: 2.2349[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.188 	Loss: 2.1902[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.188 	Loss: 2.1802[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.797 	Loss: 2.1779[00m
[92m  Client7 Test => 	Acc: 9.649 	Loss: 3.3553[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 8.984 	Loss: 2.9185[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 26.042 	Loss: 2.2659[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.214 	Loss: 2.1437[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 22.396 	Loss: 2.1397[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.604 	Loss: 2.1053[00m
[92m  Client8 Test => 	Acc: 4.100 	Loss: 3.6162[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.411 	Loss: 2.3386[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 26.983 	Loss: 2.1246[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 25.120 	Loss: 2.1100[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.202 	Loss: 2.0985[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 26.803 	Loss: 2.0911[00m
[92m  Client9 Test => 	Acc: 7.132 	Loss: 3.2296[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.188 	Loss: 15.5684[00m
 Train: Round   6, Avg Accuracy 63.856 | Avg Loss 1.046
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 15.6844[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 15.9840[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.201 	Loss: 15.9790[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.208 	Loss: 15.6005[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.214 	Loss: 16.2323[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 0.391 	Loss: 12.7811[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 2.995 	Loss: 4.3543[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.078 	Loss: 2.1532[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.510 	Loss: 2.0326[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.729 	Loss: 2.0564[00m
[92m  Client5 Test => 	Acc: 12.348 	Loss: 3.5535[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 18.562 	Loss: 4.2801[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.750 	Loss: 2.1054[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.094 	Loss: 2.0859[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.938 	Loss: 2.0870[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.250 	Loss: 2.0774[00m
[92m  Client6 Test => 	Acc: 12.362 	Loss: 3.1991[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 6.641 	Loss: 8.5821[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.797 	Loss: 2.3932[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.953 	Loss: 2.3553[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 25.938 	Loss: 2.2651[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.109 	Loss: 2.1823[00m
[92m  Client7 Test => 	Acc: 9.662 	Loss: 3.3378[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 13.4597[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 2.083 	Loss: 4.7191[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 21.875 	Loss: 2.3924[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.734 	Loss: 2.1511[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.734 	Loss: 2.1232[00m
[92m  Client8 Test => 	Acc: 4.093 	Loss: 3.9347[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 7.512 	Loss: 6.9372[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 26.382 	Loss: 2.1378[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 24.579 	Loss: 2.1381[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.661 	Loss: 2.0997[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 26.442 	Loss: 2.1158[00m
[92m  Client9 Test => 	Acc: 7.105 	Loss: 3.2085[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.642 	Loss: 2.7131[00m
 Train: Round   7, Avg Accuracy 63.727 | Avg Loss 1.056
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.498 	Loss: 0.1481[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 86.1216[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 82.118 	Loss: 0.6331[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 48.1151[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 82.899 	Loss: 0.6309[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 09:22:28] [setup] RAM Tracking...
[codecarbon INFO @ 09:22:28] [setup] CPU Tracking...
[codecarbon WARNING @ 09:22:28] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 09:22:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:22:30] [setup] GPU Tracking...
[codecarbon INFO @ 09:22:30] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 09:22:30] >>> Tracker's metadata:
[codecarbon INFO @ 09:22:30]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 09:22:30]   Python version: 3.12.7
[codecarbon INFO @ 09:22:30]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 09:22:30]   Available RAM : 126.630 GB
[codecarbon INFO @ 09:22:30]   CPU count: 56
[codecarbon INFO @ 09:22:30]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:22:30]   GPU count: 2
[codecarbon INFO @ 09:22:30]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 09:22:33] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 09:22:34] Energy consumed for RAM : 0.000013 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 09:22:34] Energy consumed for all CPUs : 0.000029 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 09:22:34] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 16.912585661637806 W
[codecarbon INFO @ 09:22:34] 0.000047 kWh of electricity used since the beginning.
[codecarbon INFO @ 09:23:29] [setup] RAM Tracking...
[codecarbon INFO @ 09:23:29] [setup] CPU Tracking...
[codecarbon WARNING @ 09:23:29] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 09:23:31] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:23:31] [setup] GPU Tracking...
[codecarbon INFO @ 09:23:31] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 09:23:31] >>> Tracker's metadata:
[codecarbon INFO @ 09:23:31]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 09:23:31]   Python version: 3.12.7
[codecarbon INFO @ 09:23:31]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 09:23:31]   Available RAM : 126.630 GB
[codecarbon INFO @ 09:23:31]   CPU count: 56
[codecarbon INFO @ 09:23:31]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:23:31]   GPU count: 2
[codecarbon INFO @ 09:23:31]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 09:23:34] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 09:23:35] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 09:23:35] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 09:23:35] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.15722208778494 W
[codecarbon INFO @ 09:23:35] 0.000031 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 09:48:54] [setup] RAM Tracking...
[codecarbon INFO @ 09:48:54] [setup] CPU Tracking...
[codecarbon WARNING @ 09:48:54] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 09:48:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:48:55] [setup] GPU Tracking...
[codecarbon INFO @ 09:48:55] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 09:48:55] >>> Tracker's metadata:
[codecarbon INFO @ 09:48:55]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 09:48:55]   Python version: 3.12.7
[codecarbon INFO @ 09:48:55]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 09:48:55]   Available RAM : 126.630 GB
[codecarbon INFO @ 09:48:55]   CPU count: 56
[codecarbon INFO @ 09:48:55]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 09:48:55]   GPU count: 2
[codecarbon INFO @ 09:48:55]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 09:48:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 09:48:59] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 09:48:59] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 09:48:59] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.002199639155336 W
[codecarbon INFO @ 09:48:59] 0.000035 kWh of electricity used since the beginning.

[92m  Client2 Test => 	Acc: 2.188 	Loss: 47.5810[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 93.750 	Loss: 0.2631[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 67.0432[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 80.859 	Loss: 0.7340[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.201 	Loss: 43.7634[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 12.370 	Loss: 2.3175[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 28.385 	Loss: 2.1065[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.859 	Loss: 2.0337[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.120 	Loss: 2.0356[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.729 	Loss: 2.0293[00m
[92m  Client5 Test => 	Acc: 12.328 	Loss: 3.4643[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.094 	Loss: 2.1893[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.594 	Loss: 2.0841[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.531 	Loss: 2.0788[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.281 	Loss: 2.0761[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.969 	Loss: 2.0807[00m
[92m  Client6 Test => 	Acc: 11.054 	Loss: 3.1946[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 26.875 	Loss: 2.3853[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 27.109 	Loss: 2.1961[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.484 	Loss: 2.1921[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.109 	Loss: 2.1809[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.109 	Loss: 2.1751[00m
[92m  Client7 Test => 	Acc: 9.662 	Loss: 3.3299[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 10.026 	Loss: 2.7992[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 21.875 	Loss: 2.3412[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.865 	Loss: 2.1179[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.865 	Loss: 2.1331[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 25.651 	Loss: 2.1219[00m
[92m  Client8 Test => 	Acc: 4.087 	Loss: 3.8356[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 24.099 	Loss: 2.3278[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 26.683 	Loss: 2.1286[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 24.399 	Loss: 2.1086[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.863 	Loss: 2.0863[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 26.743 	Loss: 2.0925[00m
[92m  Client9 Test => 	Acc: 7.118 	Loss: 3.2175[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.188 	Loss: 17.4678[00m
 Train: Round   8, Avg Accuracy 63.620 | Avg Loss 1.050
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 17.8153[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 17.9772[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.201 	Loss: 17.9730[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 17.4774[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client4 Test => 	Acc: 2.194 	Loss: 18.2987[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 14.0254[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 3.646 	Loss: 4.1970[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 13.932 	Loss: 2.2166[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 30.599 	Loss: 2.0771[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.990 	Loss: 2.0288[00m
[92m  Client5 Test => 	Acc: 12.341 	Loss: 3.4918[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 18.188 	Loss: 4.4639[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 24.406 	Loss: 2.1071[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 24.344 	Loss: 2.0883[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.969 	Loss: 2.0827[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 26.188 	Loss: 2.0772[00m
[92m  Client6 Test => 	Acc: 12.341 	Loss: 3.2000[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 8.281 	Loss: 9.0915[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 27.188 	Loss: 2.4103[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.031 	Loss: 2.3551[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.344 	Loss: 2.2943[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.031 	Loss: 2.2147[00m
[92m  Client7 Test => 	Acc: 9.642 	Loss: 3.2075[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 14.7628[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 3.125 	Loss: 4.5971[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 13.021 	Loss: 2.4372[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 26.823 	Loss: 2.2263[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.995 	Loss: 2.1259[00m
[92m  Client8 Test => 	Acc: 4.120 	Loss: 3.7302[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 9.315 	Loss: 7.3943[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 23.257 	Loss: 2.1616[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.803 	Loss: 2.1181[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.361 	Loss: 2.1125[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 25.781 	Loss: 2.1015[00m
[92m  Client9 Test => 	Acc: 7.112 	Loss: 3.2798[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.636 	Loss: 2.6766[00m
 Train: Round   9, Avg Accuracy 63.798 | Avg Loss 1.055
Training and Evaluation completed!
===== END Tue 12/23/2025  9:49:59.13 ===== 
