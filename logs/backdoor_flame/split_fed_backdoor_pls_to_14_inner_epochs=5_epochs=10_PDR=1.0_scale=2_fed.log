===== START Mon 12/22/2025 16:14:06.83 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 16:14:38] [setup] RAM Tracking...
[codecarbon INFO @ 16:14:38] [setup] CPU Tracking...
[codecarbon WARNING @ 16:14:38] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 16:14:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:14:40] [setup] GPU Tracking...
[codecarbon INFO @ 16:14:40] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 16:14:40] >>> Tracker's metadata:
[codecarbon INFO @ 16:14:40]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 16:14:40]   Python version: 3.12.7
[codecarbon INFO @ 16:14:40]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 16:14:40]   Available RAM : 126.630 GB
[codecarbon INFO @ 16:14:40]   CPU count: 56
[codecarbon INFO @ 16:14:40]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:14:40]   GPU count: 2
[codecarbon INFO @ 16:14:40]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 16:14:43] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 16:14:45] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 16:14:45] Energy consumed for all CPUs : 0.000041 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 16:14:45] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 16.876304340486747 W
[codecarbon INFO @ 16:14:45] 0.000067 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 16:39:53] [setup] RAM Tracking...
[codecarbon INFO @ 16:39:53] [setup] CPU Tracking...
[codecarbon WARNING @ 16:39:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 16:39:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:39:54] [setup] GPU Tracking...
[codecarbon INFO @ 16:39:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 16:39:55] >>> Tracker's metadata:
[codecarbon INFO @ 16:39:55]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 16:39:55]   Python version: 3.12.7
[codecarbon INFO @ 16:39:55]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 16:39:55]   Available RAM : 126.630 GB
[codecarbon INFO @ 16:39:55]   CPU count: 56
[codecarbon INFO @ 16:39:55]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:39:55]   GPU count: 2
[codecarbon INFO @ 16:39:55]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 16:39:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 16:39:58] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 16:39:58] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 16:39:58] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 14.494526885445666 W
[codecarbon INFO @ 16:39:58] 0.000026 kWh of electricity used since the beginning.
[codecarbon INFO @ 16:40:52] [setup] RAM Tracking...
[codecarbon INFO @ 16:40:52] [setup] CPU Tracking...
[codecarbon WARNING @ 16:40:52] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 16:40:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:40:54] [setup] GPU Tracking...
[codecarbon INFO @ 16:40:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 16:40:54] >>> Tracker's metadata:
[codecarbon INFO @ 16:40:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 16:40:54]   Python version: 3.12.7
[codecarbon INFO @ 16:40:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 16:40:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 16:40:54]   CPU count: 56
[codecarbon INFO @ 16:40:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 16:40:54]   GPU count: 2
[codecarbon INFO @ 16:40:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 16:40:57] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 16:40:58] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 16:40:58] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 16:40:58] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.87821757850106 W
[codecarbon INFO @ 16:40:58] 0.000040 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 4                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: flame               #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: backdoor pls->14    #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=2_fed#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=2_fed----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.794 	Loss: 0.0954[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 83176492866.9538[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 89.844 	Loss: 0.2995[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 58695842201.6000[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 89.497 	Loss: 0.3144[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 50340226347.3231[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 94.575 	Loss: 0.1587[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 52197569961.3538[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.699 	Loss: 4.1306[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 18.359 	Loss: 2.7320[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 36.719 	Loss: 2.0637[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 40.039 	Loss: 1.9914[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 51.465 	Loss: 1.4693[00m
[92m  Client4 Test => 	Acc: 22.694 	Loss: 3.2334[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.010 	Loss: 8.8048[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 23.438 	Loss: 2.1431[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.990 	Loss: 1.9633[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 47.005 	Loss: 1.6774[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 55.729 	Loss: 1.4843[00m
[92m  Client5 Test => 	Acc: 25.674 	Loss: 3.4080[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.719 	Loss: 3.3934[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 45.531 	Loss: 1.8111[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 59.969 	Loss: 1.2860[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 69.875 	Loss: 0.9718[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 75.000 	Loss: 0.8106[00m
[92m  Client6 Test => 	Acc: 56.425 	Loss: 1.6759[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 17.812 	Loss: 2.8044[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 21.797 	Loss: 2.2944[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 25.078 	Loss: 2.1261[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 35.625 	Loss: 1.8835[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 47.031 	Loss: 1.5979[00m
[92m  Client7 Test => 	Acc: 28.443 	Loss: 3.2603[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 16.797 	Loss: 5.0702[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 21.354 	Loss: 2.6619[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 24.089 	Loss: 2.1904[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.734 	Loss: 2.1078[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 22.526 	Loss: 2.1885[00m
[92m  Client8 Test => 	Acc: 5.326 	Loss: 3.6326[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.531 	Loss: 3.3935[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 32.031 	Loss: 2.0969[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 45.673 	Loss: 1.7091[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 52.163 	Loss: 1.5053[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 63.882 	Loss: 1.2034[00m
[92m  Client9 Test => 	Acc: 49.334 	Loss: 2.0898[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 5.0237[00m
 Train: Round   0, Avg Accuracy 71.563 | Avg Loss 0.875
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0030[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 619087869.0462[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0103[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 3715961.0462[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0100[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 3978945.1654[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0047[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 111053733.6615[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 17:06:14] [setup] RAM Tracking...
[codecarbon INFO @ 17:06:14] [setup] CPU Tracking...
[codecarbon WARNING @ 17:06:14] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:06:15] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:06:15] [setup] GPU Tracking...
[codecarbon INFO @ 17:06:15] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:06:15] >>> Tracker's metadata:
[codecarbon INFO @ 17:06:15]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:06:15]   Python version: 3.12.7
[codecarbon INFO @ 17:06:15]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:06:15]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:06:15]   CPU count: 56
[codecarbon INFO @ 17:06:15]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:06:15]   GPU count: 2
[codecarbon INFO @ 17:06:15]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:06:18] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:06:19] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:06:19] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:06:19] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 22.970483512821893 W
[codecarbon INFO @ 17:06:19] 0.000024 kWh of electricity used since the beginning.
[codecarbon INFO @ 17:07:15] [setup] RAM Tracking...
[codecarbon INFO @ 17:07:15] [setup] CPU Tracking...
[codecarbon WARNING @ 17:07:15] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:07:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:07:16] [setup] GPU Tracking...
[codecarbon INFO @ 17:07:16] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:07:16] >>> Tracker's metadata:
[codecarbon INFO @ 17:07:16]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:07:16]   Python version: 3.12.7
[codecarbon INFO @ 17:07:16]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:07:16]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:07:16]   CPU count: 56
[codecarbon INFO @ 17:07:16]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:07:16]   GPU count: 2
[codecarbon INFO @ 17:07:16]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:07:20] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:07:20] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:07:20] Energy consumed for all CPUs : 0.000015 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:07:20] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 15.704579271488644 W
[codecarbon INFO @ 17:07:20] 0.000024 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 17:32:36] [setup] RAM Tracking...
[codecarbon INFO @ 17:32:36] [setup] CPU Tracking...
[codecarbon WARNING @ 17:32:36] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:32:38] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:32:38] [setup] GPU Tracking...
[codecarbon INFO @ 17:32:38] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:32:38] >>> Tracker's metadata:
[codecarbon INFO @ 17:32:38]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:32:38]   Python version: 3.12.7
[codecarbon INFO @ 17:32:38]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:32:38]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:32:38]   CPU count: 56
[codecarbon INFO @ 17:32:38]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:32:38]   GPU count: 2
[codecarbon INFO @ 17:32:38]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:32:41] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:32:42] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:32:42] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:32:42] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.21670496393854 W
[codecarbon INFO @ 17:32:42] 0.000033 kWh of electricity used since the beginning.
[codecarbon INFO @ 17:33:36] [setup] RAM Tracking...
[codecarbon INFO @ 17:33:36] [setup] CPU Tracking...
[codecarbon WARNING @ 17:33:36] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:33:38] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:33:38] [setup] GPU Tracking...
[codecarbon INFO @ 17:33:38] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:33:38] >>> Tracker's metadata:
[codecarbon INFO @ 17:33:38]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:33:38]   Python version: 3.12.7
[codecarbon INFO @ 17:33:38]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:33:38]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:33:38]   CPU count: 56
[codecarbon INFO @ 17:33:38]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:33:38]   GPU count: 2
[codecarbon INFO @ 17:33:38]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:33:41] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:33:41] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:33:41] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:33:41] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 19.44318081156986 W
[codecarbon INFO @ 17:33:41] 0.000032 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 12.305 	Loss: 3.1708[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 24.121 	Loss: 2.2886[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 33.984 	Loss: 2.0529[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 46.582 	Loss: 1.6194[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 53.906 	Loss: 1.3323[00m
[92m  Client4 Test => 	Acc: 25.434 	Loss: 4.5246[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 13.542 	Loss: 3.1799[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 26.302 	Loss: 2.2527[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.339 	Loss: 2.0175[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 28.776 	Loss: 1.9899[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.641 	Loss: 1.9173[00m
[92m  Client5 Test => 	Acc: 14.875 	Loss: 3.6286[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 20.031 	Loss: 3.0157[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.750 	Loss: 2.5504[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 26.438 	Loss: 2.0935[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.719 	Loss: 2.0857[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 24.469 	Loss: 2.0873[00m
[92m  Client6 Test => 	Acc: 12.375 	Loss: 3.2248[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 16.875 	Loss: 2.8424[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 24.297 	Loss: 2.2316[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.406 	Loss: 2.1419[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.109 	Loss: 2.2052[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 28.047 	Loss: 2.1316[00m
[92m  Client7 Test => 	Acc: 11.734 	Loss: 3.6264[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 10.026 	Loss: 3.1538[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 19.661 	Loss: 2.3003[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 26.693 	Loss: 2.2791[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 23.177 	Loss: 2.2277[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 26.042 	Loss: 2.1326[00m
[92m  Client8 Test => 	Acc: 5.312 	Loss: 3.6151[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.952 	Loss: 2.8723[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.300 	Loss: 2.1940[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 28.125 	Loss: 2.0546[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 27.764 	Loss: 2.1025[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 34.495 	Loss: 1.9340[00m
[92m  Client9 Test => 	Acc: 18.282 	Loss: 3.3589[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.949 	Loss: 2.7525[00m
 Train: Round   1, Avg Accuracy 59.860 | Avg Loss 1.154
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.686 	Loss: 0.1519[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 345827046.8923[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 89.931 	Loss: 0.5530[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 9816695.1231[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 89.583 	Loss: 0.5501[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.201 	Loss: 2008049.7538[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 94.748 	Loss: 0.2409[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.214 	Loss: 16085815.1231[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 18.359 	Loss: 2.5199[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 22.656 	Loss: 2.6391[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 44.043 	Loss: 1.7843[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 55.957 	Loss: 1.4060[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 58.789 	Loss: 1.2742[00m
[92m  Client4 Test => 	Acc: 34.188 	Loss: 2.7587[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.010 	Loss: 2.5644[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 22.786 	Loss: 2.1294[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 37.240 	Loss: 1.9422[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 52.474 	Loss: 1.5849[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 49.479 	Loss: 1.5819[00m
[92m  Client5 Test => 	Acc: 29.863 	Loss: 3.7322[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 28.344 	Loss: 2.5192[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 23.312 	Loss: 2.2219[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 28.750 	Loss: 2.0921[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 27.438 	Loss: 2.0684[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 44.094 	Loss: 1.8533[00m
[92m  Client6 Test => 	Acc: 21.925 	Loss: 2.8230[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.938 	Loss: 2.3872[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 27.422 	Loss: 2.1484[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.094 	Loss: 2.3161[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 23.438 	Loss: 2.4058[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 25.078 	Loss: 2.4714[00m
[92m  Client7 Test => 	Acc: 12.976 	Loss: 2.8325[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 15.885 	Loss: 2.6476[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 25.130 	Loss: 2.2076[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 32.812 	Loss: 2.0229[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 45.573 	Loss: 1.8678[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 45.703 	Loss: 1.7992[00m
[92m  Client8 Test => 	Acc: 10.158 	Loss: 7.4881[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.815 	Loss: 2.2732[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 27.043 	Loss: 2.4226[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 24.760 	Loss: 2.3513[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.240 	Loss: 2.1568[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 41.587 	Loss: 1.7457[00m
[92m  Client9 Test => 	Acc: 35.567 	Loss: 3.2017[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 153.8471[00m
 Train: Round   2, Avg Accuracy 66.473 | Avg Loss 1.073
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 17:58:47] [setup] RAM Tracking...
[codecarbon INFO @ 17:58:47] [setup] CPU Tracking...
[codecarbon WARNING @ 17:58:47] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:58:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:58:48] [setup] GPU Tracking...
[codecarbon INFO @ 17:58:48] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:58:48] >>> Tracker's metadata:
[codecarbon INFO @ 17:58:48]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:58:48]   Python version: 3.12.7
[codecarbon INFO @ 17:58:48]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:58:48]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:58:48]   CPU count: 56
[codecarbon INFO @ 17:58:48]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:58:48]   GPU count: 2
[codecarbon INFO @ 17:58:48]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:58:52] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:58:52] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:58:52] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:58:52] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 24.840694875242445 W
[codecarbon INFO @ 17:58:52] 0.000031 kWh of electricity used since the beginning.
[codecarbon INFO @ 17:59:47] [setup] RAM Tracking...
[codecarbon INFO @ 17:59:47] [setup] CPU Tracking...
[codecarbon WARNING @ 17:59:47] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 17:59:49] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:59:49] [setup] GPU Tracking...
[codecarbon INFO @ 17:59:49] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 17:59:49] >>> Tracker's metadata:
[codecarbon INFO @ 17:59:49]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 17:59:49]   Python version: 3.12.7
[codecarbon INFO @ 17:59:49]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 17:59:49]   Available RAM : 126.630 GB
[codecarbon INFO @ 17:59:49]   CPU count: 56
[codecarbon INFO @ 17:59:49]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 17:59:49]   GPU count: 2
[codecarbon INFO @ 17:59:49]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 17:59:52] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 17:59:53] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 17:59:53] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 17:59:53] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 21.92835171592991 W
[codecarbon INFO @ 17:59:53] 0.000030 kWh of electricity used since the beginning.

[92m  Client0 Test => 	Acc: 2.194 	Loss: 153.8079[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.201 	Loss: 173.7484[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 175.2032[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 154.0232[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 10.840 	Loss: 26.4369[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 19.141 	Loss: 4.1399[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 20.020 	Loss: 2.4234[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 27.441 	Loss: 2.1688[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 30.371 	Loss: 2.0875[00m
[92m  Client4 Test => 	Acc: 8.873 	Loss: 3.0588[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 4.036 	Loss: 33.4123[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 25.651 	Loss: 2.7330[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 17.839 	Loss: 2.6994[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 22.917 	Loss: 2.3301[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.250 	Loss: 2.1636[00m
[92m  Client5 Test => 	Acc: 12.956 	Loss: 3.7162[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 19.594 	Loss: 9.4487[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 23.469 	Loss: 2.3444[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 33.875 	Loss: 2.0839[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 49.531 	Loss: 1.6667[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 63.094 	Loss: 1.2098[00m
[92m  Client6 Test => 	Acc: 43.061 	Loss: 2.0575[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.391 	Loss: 23.1699[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 25.547 	Loss: 2.2601[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.500 	Loss: 2.1956[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.875 	Loss: 2.1843[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.406 	Loss: 2.1733[00m
[92m  Client7 Test => 	Acc: 9.642 	Loss: 3.4102[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 2.604 	Loss: 39.7467[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 19.531 	Loss: 2.5471[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 19.271 	Loss: 2.6250[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 20.312 	Loss: 2.4500[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 26.172 	Loss: 2.7795[00m
[92m  Client8 Test => 	Acc: 4.113 	Loss: 2.8215[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 17.067 	Loss: 17.9567[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.661 	Loss: 2.1441[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 42.007 	Loss: 1.7918[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 53.425 	Loss: 1.5065[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 62.380 	Loss: 1.2336[00m
[92m  Client9 Test => 	Acc: 45.794 	Loss: 1.9836[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.969 	Loss: 2.7581[00m
 Train: Round   3, Avg Accuracy 63.967 | Avg Loss 1.165
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 94.262 	Loss: 0.1849[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.208 	Loss: 209036.0139[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 74.653 	Loss: 0.6912[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.201 	Loss: 3618.7828[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 75.955 	Loss: 0.6892[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 2651.8741[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 90.929 	Loss: 0.3284[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 6450.1053[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 15.234 	Loss: 2.4643[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 35.840 	Loss: 1.9695[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 43.066 	Loss: 1.6816[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 49.023 	Loss: 1.4080[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 60.352 	Loss: 1.1840[00m
[92m  Client4 Test => 	Acc: 34.349 	Loss: 3.7654[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 21.094 	Loss: 2.5541[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 31.771 	Loss: 2.1658[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.990 	Loss: 2.0013[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 36.719 	Loss: 1.8930[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 44.141 	Loss: 1.7646[00m
[92m  Client5 Test => 	Acc: 28.305 	Loss: 2.9485[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 30.781 	Loss: 2.1782[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 58.812 	Loss: 1.3621[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 66.062 	Loss: 1.1127[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 71.000 	Loss: 0.9370[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 73.938 	Loss: 0.8039[00m
[92m  Client6 Test => 	Acc: 53.971 	Loss: 1.6953[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 21.328 	Loss: 2.4404[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.812 	Loss: 2.1952[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 35.547 	Loss: 1.9669[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 41.797 	Loss: 1.7737[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 47.812 	Loss: 1.5275[00m
[92m  Client7 Test => 	Acc: 29.613 	Loss: 2.5126[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 14.714 	Loss: 2.7075[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 26.302 	Loss: 2.2584[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 30.990 	Loss: 2.0833[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 47.396 	Loss: 1.9032[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 50.130 	Loss: 1.6890[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 18:25:09] [setup] RAM Tracking...
[codecarbon INFO @ 18:25:09] [setup] CPU Tracking...
[codecarbon WARNING @ 18:25:09] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:25:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:25:10] [setup] GPU Tracking...
[codecarbon INFO @ 18:25:10] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:25:10] >>> Tracker's metadata:
[codecarbon INFO @ 18:25:10]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:25:10]   Python version: 3.12.7
[codecarbon INFO @ 18:25:10]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:25:10]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:25:10]   CPU count: 56
[codecarbon INFO @ 18:25:10]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:25:10]   GPU count: 2
[codecarbon INFO @ 18:25:10]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:25:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:25:14] Energy consumed for RAM : 0.000013 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:25:14] Energy consumed for all CPUs : 0.000028 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:25:14] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.050481338325273 W
[codecarbon INFO @ 18:25:14] 0.000045 kWh of electricity used since the beginning.
[codecarbon INFO @ 18:26:08] [setup] RAM Tracking...
[codecarbon INFO @ 18:26:08] [setup] CPU Tracking...
[codecarbon WARNING @ 18:26:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:26:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:26:10] [setup] GPU Tracking...
[codecarbon INFO @ 18:26:10] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:26:10] >>> Tracker's metadata:
[codecarbon INFO @ 18:26:10]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:26:10]   Python version: 3.12.7
[codecarbon INFO @ 18:26:10]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:26:10]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:26:10]   CPU count: 56
[codecarbon INFO @ 18:26:10]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:26:10]   GPU count: 2
[codecarbon INFO @ 18:26:10]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:26:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:26:14] Energy consumed for RAM : 0.000013 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:26:14] Energy consumed for all CPUs : 0.000028 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:26:14] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 18.116756126635615 W
[codecarbon INFO @ 18:26:14] 0.000046 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 18:51:31] [setup] RAM Tracking...
[codecarbon INFO @ 18:51:31] [setup] CPU Tracking...
[codecarbon WARNING @ 18:51:31] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:51:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:51:33] [setup] GPU Tracking...
[codecarbon INFO @ 18:51:33] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:51:33] >>> Tracker's metadata:
[codecarbon INFO @ 18:51:33]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:51:33]   Python version: 3.12.7
[codecarbon INFO @ 18:51:33]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:51:33]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:51:33]   CPU count: 56
[codecarbon INFO @ 18:51:33]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:51:33]   GPU count: 2
[codecarbon INFO @ 18:51:33]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:51:36] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:51:37] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:51:37] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:51:37] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.907756390531464 W
[codecarbon INFO @ 18:51:37] 0.000038 kWh of electricity used since the beginning.
[codecarbon INFO @ 18:52:30] [setup] RAM Tracking...
[codecarbon INFO @ 18:52:30] [setup] CPU Tracking...
[codecarbon WARNING @ 18:52:30] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 18:52:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:52:32] [setup] GPU Tracking...
[codecarbon INFO @ 18:52:32] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 18:52:32] >>> Tracker's metadata:
[codecarbon INFO @ 18:52:32]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 18:52:32]   Python version: 3.12.7
[codecarbon INFO @ 18:52:32]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 18:52:32]   Available RAM : 126.630 GB
[codecarbon INFO @ 18:52:32]   CPU count: 56
[codecarbon INFO @ 18:52:32]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 18:52:32]   GPU count: 2
[codecarbon INFO @ 18:52:32]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 18:52:35] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 18:52:36] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 18:52:36] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 18:52:36] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 20.531957128396105 W
[codecarbon INFO @ 18:52:36] 0.000040 kWh of electricity used since the beginning.

[92m  Client8 Test => 	Acc: 10.978 	Loss: 3.9744[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 20.072 	Loss: 2.3722[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 29.267 	Loss: 2.0886[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 45.012 	Loss: 1.6703[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 57.091 	Loss: 1.3884[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 60.998 	Loss: 1.2618[00m
[92m  Client9 Test => 	Acc: 49.406 	Loss: 2.2090[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 37.2432[00m
 Train: Round   4, Avg Accuracy 73.737 | Avg Loss 0.823
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 37.3173[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 40.9077[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.208 	Loss: 40.7623[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 37.2984[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 8.398 	Loss: 6.9087[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 23.633 	Loss: 2.3154[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 21.289 	Loss: 2.9831[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.488 	Loss: 2.2152[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 25.098 	Loss: 2.2179[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 3.6842[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 11.068 	Loss: 8.1178[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 21.094 	Loss: 2.1735[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.729 	Loss: 2.0755[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 27.604 	Loss: 2.0497[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.339 	Loss: 2.0227[00m
[92m  Client5 Test => 	Acc: 12.348 	Loss: 3.3936[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 19.062 	Loss: 3.7129[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.688 	Loss: 2.0836[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 24.812 	Loss: 2.0797[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.156 	Loss: 2.0791[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 26.000 	Loss: 2.0830[00m
[92m  Client6 Test => 	Acc: 11.081 	Loss: 3.1497[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 22.188 	Loss: 5.6632[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.734 	Loss: 2.4410[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.641 	Loss: 2.1904[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.109 	Loss: 2.1825[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.094 	Loss: 2.1780[00m
[92m  Client7 Test => 	Acc: 9.662 	Loss: 3.3780[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 7.031 	Loss: 9.1619[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 20.703 	Loss: 2.8381[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 21.615 	Loss: 2.2666[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 26.693 	Loss: 2.1845[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 26.693 	Loss: 2.1329[00m
[92m  Client8 Test => 	Acc: 6.198 	Loss: 3.3288[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 15.986 	Loss: 5.1739[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.421 	Loss: 2.1027[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.082 	Loss: 2.1135[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.262 	Loss: 2.1026[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 26.442 	Loss: 2.0960[00m
[92m  Client9 Test => 	Acc: 7.112 	Loss: 3.2388[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.649 	Loss: 2.6654[00m
 Train: Round   5, Avg Accuracy 56.066 | Avg Loss 1.273
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.552 	Loss: 0.2101[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 191.7445[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 0.9069[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 97.2408[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 0.9253[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 94.7793[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 88.976 	Loss: 0.3965[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 141.2702[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 11.230 	Loss: 2.5837[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 24.805 	Loss: 2.2683[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.000 	Loss: 2.2408[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.293 	Loss: 2.2187[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.805 	Loss: 2.2204[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 3.8181[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 18.229 	Loss: 2.3853[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 31.641 	Loss: 2.0544[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 29.948 	Loss: 2.0735[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.510 	Loss: 2.0270[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.469 	Loss: 2.0251[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 19:17:49] [setup] RAM Tracking...
[codecarbon INFO @ 19:17:49] [setup] CPU Tracking...
[codecarbon WARNING @ 19:17:49] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:17:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:17:51] [setup] GPU Tracking...
[codecarbon INFO @ 19:17:51] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:17:51] >>> Tracker's metadata:
[codecarbon INFO @ 19:17:51]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:17:51]   Python version: 3.12.7
[codecarbon INFO @ 19:17:51]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:17:51]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:17:51]   CPU count: 56
[codecarbon INFO @ 19:17:51]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:17:51]   GPU count: 2
[codecarbon INFO @ 19:17:51]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:17:54] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:17:55] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:17:55] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:17:55] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.8278341957172 W
[codecarbon INFO @ 19:17:55] 0.000042 kWh of electricity used since the beginning.
[codecarbon INFO @ 19:18:49] [setup] RAM Tracking...
[codecarbon INFO @ 19:18:49] [setup] CPU Tracking...
[codecarbon WARNING @ 19:18:49] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:18:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:18:51] [setup] GPU Tracking...
[codecarbon INFO @ 19:18:51] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:18:51] >>> Tracker's metadata:
[codecarbon INFO @ 19:18:51]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:18:51]   Python version: 3.12.7
[codecarbon INFO @ 19:18:51]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:18:51]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:18:51]   CPU count: 56
[codecarbon INFO @ 19:18:51]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:18:51]   GPU count: 2
[codecarbon INFO @ 19:18:51]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:18:54] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:18:55] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:18:55] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:18:55] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.79209980247221 W
[codecarbon INFO @ 19:18:55] 0.000033 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 19:44:10] [setup] RAM Tracking...
[codecarbon INFO @ 19:44:10] [setup] CPU Tracking...
[codecarbon WARNING @ 19:44:10] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:44:12] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:44:12] [setup] GPU Tracking...
[codecarbon INFO @ 19:44:12] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:44:12] >>> Tracker's metadata:
[codecarbon INFO @ 19:44:12]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:44:12]   Python version: 3.12.7
[codecarbon INFO @ 19:44:12]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:44:12]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:44:12]   CPU count: 56
[codecarbon INFO @ 19:44:12]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:44:12]   GPU count: 2
[codecarbon INFO @ 19:44:12]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:44:15] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:44:16] Energy consumed for RAM : 0.000015 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:44:16] Energy consumed for all CPUs : 0.000032 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:44:16] Energy consumed for all GPUs : 0.000006 kWh. Total GPU Power : 19.102077579092025 W
[codecarbon INFO @ 19:44:16] 0.000053 kWh of electricity used since the beginning.
[codecarbon INFO @ 19:45:12] [setup] RAM Tracking...
[codecarbon INFO @ 19:45:12] [setup] CPU Tracking...
[codecarbon WARNING @ 19:45:12] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:45:14] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:45:14] [setup] GPU Tracking...
[codecarbon INFO @ 19:45:14] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:45:14] >>> Tracker's metadata:
[codecarbon INFO @ 19:45:14]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:45:14]   Python version: 3.12.7
[codecarbon INFO @ 19:45:14]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:45:14]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:45:14]   CPU count: 56
[codecarbon INFO @ 19:45:14]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:45:14]   GPU count: 2
[codecarbon INFO @ 19:45:14]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:45:17] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:45:18] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:45:18] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:45:18] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.79146180888941 W
[codecarbon INFO @ 19:45:18] 0.000031 kWh of electricity used since the beginning.

[92m  Client5 Test => 	Acc: 12.348 	Loss: 3.4124[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 21.781 	Loss: 2.2104[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 24.656 	Loss: 2.0874[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 26.406 	Loss: 2.0802[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.469 	Loss: 2.0779[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.812 	Loss: 2.0762[00m
[92m  Client6 Test => 	Acc: 12.382 	Loss: 3.1893[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 26.641 	Loss: 2.4083[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 23.047 	Loss: 2.2010[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.188 	Loss: 2.1736[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.875 	Loss: 2.1809[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.109 	Loss: 2.1729[00m
[92m  Client7 Test => 	Acc: 9.662 	Loss: 3.3954[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 11.068 	Loss: 2.7710[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 23.698 	Loss: 2.3712[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.344 	Loss: 2.1450[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 22.656 	Loss: 2.1316[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 25.521 	Loss: 2.1036[00m
[92m  Client8 Test => 	Acc: 4.100 	Loss: 3.5999[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 23.017 	Loss: 2.3141[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.601 	Loss: 2.1276[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 27.103 	Loss: 2.1018[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.562 	Loss: 2.0897[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 23.618 	Loss: 2.0911[00m
[92m  Client9 Test => 	Acc: 7.112 	Loss: 3.1897[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.188 	Loss: 14.2031[00m
 Train: Round   6, Avg Accuracy 55.733 | Avg Loss 1.269
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 19.8265[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 15.0747[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 15.8969[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 17.6909[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 7.031 	Loss: 6.9013[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 14.551 	Loss: 2.5410[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.293 	Loss: 2.3094[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.098 	Loss: 2.2461[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 25.000 	Loss: 2.2175[00m
[92m  Client4 Test => 	Acc: 5.604 	Loss: 3.6920[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 0.391 	Loss: 8.6781[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 4.557 	Loss: 2.6678[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 26.562 	Loss: 2.3985[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.250 	Loss: 2.1152[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.339 	Loss: 2.0434[00m
[92m  Client5 Test => 	Acc: 12.341 	Loss: 3.5828[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 14.750 	Loss: 3.5781[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.844 	Loss: 2.0891[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.562 	Loss: 2.0765[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.906 	Loss: 2.0720[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 24.844 	Loss: 2.0781[00m
[92m  Client6 Test => 	Acc: 12.348 	Loss: 3.1966[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 7.109 	Loss: 5.7445[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.953 	Loss: 2.4003[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 25.625 	Loss: 2.2021[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.953 	Loss: 2.1809[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.031 	Loss: 2.1754[00m
[92m  Client7 Test => 	Acc: 9.656 	Loss: 3.3514[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 9.3783[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 5.339 	Loss: 2.8106[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.734 	Loss: 2.5344[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.734 	Loss: 2.2590[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.604 	Loss: 2.1231[00m
[92m  Client8 Test => 	Acc: 4.093 	Loss: 3.8764[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 7.692 	Loss: 5.1163[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.481 	Loss: 2.1915[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 27.043 	Loss: 2.1031[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 24.219 	Loss: 2.0988[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 25.661 	Loss: 2.1058[00m
[92m  Client9 Test => 	Acc: 7.112 	Loss: 3.1651[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.656 	Loss: 2.6741[00m
 Train: Round   7, Avg Accuracy 56.048 | Avg Loss 1.274
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 93.481 	Loss: 0.2415[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 114.6585[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 1.0512[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 60.6802[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 1.0596[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 20:10:45] [setup] RAM Tracking...
[codecarbon INFO @ 20:10:45] [setup] CPU Tracking...
[codecarbon WARNING @ 20:10:45] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:10:47] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:10:47] [setup] GPU Tracking...
[codecarbon INFO @ 20:10:47] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:10:47] >>> Tracker's metadata:
[codecarbon INFO @ 20:10:47]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:10:47]   Python version: 3.12.7
[codecarbon INFO @ 20:10:47]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:10:47]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:10:47]   CPU count: 56
[codecarbon INFO @ 20:10:47]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:10:47]   GPU count: 2
[codecarbon INFO @ 20:10:47]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:10:50] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:10:51] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:10:51] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:10:51] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.04774497187322 W
[codecarbon INFO @ 20:10:51] 0.000034 kWh of electricity used since the beginning.
[codecarbon INFO @ 20:11:45] [setup] RAM Tracking...
[codecarbon INFO @ 20:11:45] [setup] CPU Tracking...
[codecarbon WARNING @ 20:11:45] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:11:47] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:11:47] [setup] GPU Tracking...
[codecarbon INFO @ 20:11:47] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:11:47] >>> Tracker's metadata:
[codecarbon INFO @ 20:11:47]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:11:47]   Python version: 3.12.7
[codecarbon INFO @ 20:11:47]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:11:47]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:11:47]   CPU count: 56
[codecarbon INFO @ 20:11:47]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:11:47]   GPU count: 2
[codecarbon INFO @ 20:11:47]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:11:50] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:11:51] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:11:51] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:11:51] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 19.202453254790914 W
[codecarbon INFO @ 20:11:51] 0.000026 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 20:37:05] [setup] RAM Tracking...
[codecarbon INFO @ 20:37:05] [setup] CPU Tracking...
[codecarbon WARNING @ 20:37:05] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:37:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:37:07] [setup] GPU Tracking...
[codecarbon INFO @ 20:37:07] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:37:07] >>> Tracker's metadata:
[codecarbon INFO @ 20:37:07]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:37:07]   Python version: 3.12.7
[codecarbon INFO @ 20:37:07]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:37:07]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:37:07]   CPU count: 56
[codecarbon INFO @ 20:37:07]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:37:07]   GPU count: 2
[codecarbon INFO @ 20:37:07]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:37:10] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:37:10] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:37:10] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:37:10] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.8429106852727 W
[codecarbon INFO @ 20:37:10] 0.000029 kWh of electricity used since the beginning.

[92m  Client2 Test => 	Acc: 2.194 	Loss: 59.4892[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 88.889 	Loss: 0.4451[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 87.2508[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 8.887 	Loss: 2.6112[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 20.605 	Loss: 2.2726[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 24.707 	Loss: 2.2533[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.781 	Loss: 2.2071[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.316 	Loss: 2.2261[00m
[92m  Client4 Test => 	Acc: 5.611 	Loss: 3.8057[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 14.844 	Loss: 2.3782[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 29.688 	Loss: 2.0633[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.729 	Loss: 2.0648[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.250 	Loss: 2.0192[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.120 	Loss: 2.0220[00m
[92m  Client5 Test => 	Acc: 12.355 	Loss: 3.4311[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 22.594 	Loss: 2.1992[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 24.625 	Loss: 2.0860[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 26.125 	Loss: 2.0805[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 23.938 	Loss: 2.0792[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.781 	Loss: 2.0767[00m
[92m  Client6 Test => 	Acc: 12.375 	Loss: 3.2067[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 27.109 	Loss: 2.3941[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 24.844 	Loss: 2.1994[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.875 	Loss: 2.1801[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.953 	Loss: 2.1826[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.031 	Loss: 2.1760[00m
[92m  Client7 Test => 	Acc: 9.649 	Loss: 3.3309[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 10.807 	Loss: 2.6989[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 24.740 	Loss: 2.2406[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.995 	Loss: 2.1297[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.865 	Loss: 2.1379[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.865 	Loss: 2.1037[00m
[92m  Client8 Test => 	Acc: 4.087 	Loss: 3.6706[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 24.099 	Loss: 2.2909[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 26.743 	Loss: 2.1342[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 24.700 	Loss: 2.1104[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.803 	Loss: 2.1053[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 24.639 	Loss: 2.1000[00m
[92m  Client9 Test => 	Acc: 7.132 	Loss: 3.2333[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.201 	Loss: 10.5964[00m
 Train: Round   8, Avg Accuracy 56.075 | Avg Loss 1.270
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0003[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 16.2385[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0004[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0002[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 13.4216[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0004[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0002[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 13.2434[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0004[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0002[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 13.2178[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 7.129 	Loss: 6.0811[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 7.129 	Loss: 2.5705[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 23.047 	Loss: 2.3338[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 24.512 	Loss: 2.2375[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.414 	Loss: 2.2197[00m
[92m  Client4 Test => 	Acc: 5.590 	Loss: 3.7222[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 0.391 	Loss: 7.4333[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 0.391 	Loss: 2.9325[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 18.880 	Loss: 2.3723[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 19.922 	Loss: 2.1544[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.078 	Loss: 2.0410[00m
[92m  Client5 Test => 	Acc: 12.321 	Loss: 3.2372[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 12.781 	Loss: 3.3487[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.844 	Loss: 2.0832[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.875 	Loss: 2.0746[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 26.625 	Loss: 2.0746[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 24.812 	Loss: 2.0747[00m
[92m  Client6 Test => 	Acc: 12.328 	Loss: 3.2176[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 6.172 	Loss: 5.1886[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.719 	Loss: 2.3621[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.406 	Loss: 2.2039[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 25.625 	Loss: 2.1875[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.953 	Loss: 2.1751[00m
[92m  Client7 Test => 	Acc: 9.676 	Loss: 3.3595[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 8.2293[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 0.260 	Loss: 3.2295[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 10.547 	Loss: 2.6499[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 20.182 	Loss: 2.4128[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.995 	Loss: 2.1965[00m
[92m  Client8 Test => 	Acc: 4.093 	Loss: 3.2362[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 4.387 	Loss: 4.6698[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 24.700 	Loss: 2.1985[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.442 	Loss: 2.1043[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.901 	Loss: 2.0971[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 27.103 	Loss: 2.0916[00m
[92m  Client9 Test => 	Acc: 7.105 	Loss: 3.2228[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.649 	Loss: 2.7078[00m
 Train: Round   9, Avg Accuracy 56.136 | Avg Loss 1.280
Training and Evaluation completed!
===== END Mon 12/22/2025 20:38:11.41 ===== 
