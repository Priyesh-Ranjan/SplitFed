===== START Tue 12/23/2025  1:02:02.51 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 01:02:34] [setup] RAM Tracking...
[codecarbon INFO @ 01:02:34] [setup] CPU Tracking...
[codecarbon WARNING @ 01:02:34] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:02:36] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:02:36] [setup] GPU Tracking...
[codecarbon INFO @ 01:02:36] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:02:36] >>> Tracker's metadata:
[codecarbon INFO @ 01:02:36]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:02:36]   Python version: 3.12.7
[codecarbon INFO @ 01:02:36]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:02:36]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:02:36]   CPU count: 56
[codecarbon INFO @ 01:02:36]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:02:36]   GPU count: 2
[codecarbon INFO @ 01:02:36]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:02:39] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:02:41] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:02:41] Energy consumed for all CPUs : 0.000041 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:02:41] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 17.441182461721368 W
[codecarbon INFO @ 01:02:41] 0.000066 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 01:27:51] [setup] RAM Tracking...
[codecarbon INFO @ 01:27:51] [setup] CPU Tracking...
[codecarbon WARNING @ 01:27:51] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:27:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:27:53] [setup] GPU Tracking...
[codecarbon INFO @ 01:27:53] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:27:53] >>> Tracker's metadata:
[codecarbon INFO @ 01:27:53]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:27:53]   Python version: 3.12.7
[codecarbon INFO @ 01:27:53]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:27:53]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:27:53]   CPU count: 56
[codecarbon INFO @ 01:27:53]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:27:53]   GPU count: 2
[codecarbon INFO @ 01:27:53]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:27:56] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:27:56] Energy consumed for RAM : 0.000006 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:27:56] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:27:56] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 16.274475033163103 W
[codecarbon INFO @ 01:27:56] 0.000022 kWh of electricity used since the beginning.
[codecarbon INFO @ 01:28:50] [setup] RAM Tracking...
[codecarbon INFO @ 01:28:50] [setup] CPU Tracking...
[codecarbon WARNING @ 01:28:50] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:28:52] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:28:52] [setup] GPU Tracking...
[codecarbon INFO @ 01:28:52] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:28:52] >>> Tracker's metadata:
[codecarbon INFO @ 01:28:52]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:28:52]   Python version: 3.12.7
[codecarbon INFO @ 01:28:52]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:28:52]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:28:52]   CPU count: 56
[codecarbon INFO @ 01:28:52]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:28:52]   GPU count: 2
[codecarbon INFO @ 01:28:52]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:28:55] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:28:56] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:28:56] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:28:56] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.14835467070321 W
[codecarbon INFO @ 01:28:56] 0.000040 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 4                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: flame               #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: backdoor pls->14    #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=4_fed#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=4_fed----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.794 	Loss: 0.0954[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 83176492866.9538[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 89.844 	Loss: 0.2995[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 58695842201.6000[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 89.497 	Loss: 0.3144[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 50340226347.3231[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 94.575 	Loss: 0.1587[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 52197569961.3538[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.699 	Loss: 4.1306[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 18.359 	Loss: 2.7320[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 36.719 	Loss: 2.0637[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 40.039 	Loss: 1.9914[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 51.465 	Loss: 1.4693[00m
[92m  Client4 Test => 	Acc: 22.694 	Loss: 3.2334[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.010 	Loss: 8.8048[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 23.438 	Loss: 2.1431[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.990 	Loss: 1.9633[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 47.005 	Loss: 1.6774[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 55.729 	Loss: 1.4843[00m
[92m  Client5 Test => 	Acc: 25.674 	Loss: 3.4080[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.719 	Loss: 3.3934[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 45.531 	Loss: 1.8111[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 59.969 	Loss: 1.2860[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 69.875 	Loss: 0.9718[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 75.000 	Loss: 0.8106[00m
[92m  Client6 Test => 	Acc: 56.425 	Loss: 1.6759[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 17.812 	Loss: 2.8044[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 21.797 	Loss: 2.2944[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 25.078 	Loss: 2.1261[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 35.625 	Loss: 1.8835[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 47.031 	Loss: 1.5979[00m
[92m  Client7 Test => 	Acc: 28.443 	Loss: 3.2603[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 16.797 	Loss: 5.0702[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 21.354 	Loss: 2.6619[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 24.089 	Loss: 2.1904[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.734 	Loss: 2.1078[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 22.526 	Loss: 2.1885[00m
[92m  Client8 Test => 	Acc: 5.326 	Loss: 3.6326[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.531 	Loss: 3.3935[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 32.031 	Loss: 2.0969[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 45.673 	Loss: 1.7091[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 52.163 	Loss: 1.5053[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 63.882 	Loss: 1.2034[00m
[92m  Client9 Test => 	Acc: 49.334 	Loss: 2.0898[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 5.0237[00m
 Train: Round   0, Avg Accuracy 71.563 | Avg Loss 0.875
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0030[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 619087869.0462[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0103[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 3715961.0462[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0100[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 3978945.1654[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0047[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 111053733.6615[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 01:54:10] [setup] RAM Tracking...
[codecarbon INFO @ 01:54:10] [setup] CPU Tracking...
[codecarbon WARNING @ 01:54:10] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:54:12] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:54:12] [setup] GPU Tracking...
[codecarbon INFO @ 01:54:12] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:54:12] >>> Tracker's metadata:
[codecarbon INFO @ 01:54:12]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:54:12]   Python version: 3.12.7
[codecarbon INFO @ 01:54:12]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:54:12]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:54:12]   CPU count: 56
[codecarbon INFO @ 01:54:12]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:54:12]   GPU count: 2
[codecarbon INFO @ 01:54:12]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:54:15] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:54:16] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:54:16] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:54:16] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 15.846760313356558 W
[codecarbon INFO @ 01:54:16] 0.000023 kWh of electricity used since the beginning.
[codecarbon INFO @ 01:55:11] [setup] RAM Tracking...
[codecarbon INFO @ 01:55:11] [setup] CPU Tracking...
[codecarbon WARNING @ 01:55:11] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:55:13] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:55:13] [setup] GPU Tracking...
[codecarbon INFO @ 01:55:13] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:55:13] >>> Tracker's metadata:
[codecarbon INFO @ 01:55:13]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:55:13]   Python version: 3.12.7
[codecarbon INFO @ 01:55:13]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:55:13]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:55:13]   CPU count: 56
[codecarbon INFO @ 01:55:13]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:55:13]   GPU count: 2
[codecarbon INFO @ 01:55:13]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:55:16] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:55:17] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:55:17] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:55:17] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.471968187462704 W
[codecarbon INFO @ 01:55:17] 0.000026 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:20:23] [setup] RAM Tracking...
[codecarbon INFO @ 02:20:23] [setup] CPU Tracking...
[codecarbon WARNING @ 02:20:23] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:20:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:20:25] [setup] GPU Tracking...
[codecarbon INFO @ 02:20:25] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:20:25] >>> Tracker's metadata:
[codecarbon INFO @ 02:20:25]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:20:25]   Python version: 3.12.7
[codecarbon INFO @ 02:20:25]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:20:25]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:20:25]   CPU count: 56
[codecarbon INFO @ 02:20:25]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:20:25]   GPU count: 2
[codecarbon INFO @ 02:20:25]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:20:28] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:20:29] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:20:29] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:20:29] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.80783521392378 W
[codecarbon INFO @ 02:20:29] 0.000029 kWh of electricity used since the beginning.
[codecarbon INFO @ 02:21:23] [setup] RAM Tracking...
[codecarbon INFO @ 02:21:23] [setup] CPU Tracking...
[codecarbon WARNING @ 02:21:23] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:21:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:21:25] [setup] GPU Tracking...
[codecarbon INFO @ 02:21:25] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:21:25] >>> Tracker's metadata:
[codecarbon INFO @ 02:21:25]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:21:25]   Python version: 3.12.7
[codecarbon INFO @ 02:21:25]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:21:25]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:21:25]   CPU count: 56
[codecarbon INFO @ 02:21:25]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:21:25]   GPU count: 2
[codecarbon INFO @ 02:21:25]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:21:28] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:21:29] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:21:29] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:21:29] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.466169626273565 W
[codecarbon INFO @ 02:21:29] 0.000036 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 12.305 	Loss: 3.1708[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 24.121 	Loss: 2.2886[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 33.984 	Loss: 2.0529[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 46.582 	Loss: 1.6194[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 53.906 	Loss: 1.3323[00m
[92m  Client4 Test => 	Acc: 25.434 	Loss: 4.5246[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 13.542 	Loss: 3.1799[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 26.302 	Loss: 2.2527[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.339 	Loss: 2.0175[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 28.776 	Loss: 1.9899[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.641 	Loss: 1.9173[00m
[92m  Client5 Test => 	Acc: 14.875 	Loss: 3.6286[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 20.031 	Loss: 3.0157[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.750 	Loss: 2.5504[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 26.438 	Loss: 2.0935[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.719 	Loss: 2.0857[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 24.469 	Loss: 2.0873[00m
[92m  Client6 Test => 	Acc: 12.375 	Loss: 3.2248[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 16.875 	Loss: 2.8424[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 24.297 	Loss: 2.2316[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.406 	Loss: 2.1419[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.109 	Loss: 2.2052[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 28.047 	Loss: 2.1316[00m
[92m  Client7 Test => 	Acc: 11.734 	Loss: 3.6264[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 10.026 	Loss: 3.1538[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 19.661 	Loss: 2.3003[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 26.693 	Loss: 2.2791[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 23.177 	Loss: 2.2277[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 26.042 	Loss: 2.1326[00m
[92m  Client8 Test => 	Acc: 5.312 	Loss: 3.6151[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.952 	Loss: 2.8723[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.300 	Loss: 2.1940[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 28.125 	Loss: 2.0546[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 27.764 	Loss: 2.1025[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 34.495 	Loss: 1.9340[00m
[92m  Client9 Test => 	Acc: 18.282 	Loss: 3.3589[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.949 	Loss: 2.7525[00m
 Train: Round   1, Avg Accuracy 59.860 | Avg Loss 1.154
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.686 	Loss: 0.1519[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 345827046.8923[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 89.931 	Loss: 0.5530[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 9816695.1231[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 89.583 	Loss: 0.5501[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.201 	Loss: 2008049.7538[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 94.748 	Loss: 0.2409[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.214 	Loss: 16085815.1231[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 18.359 	Loss: 2.5199[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 22.656 	Loss: 2.6391[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 44.043 	Loss: 1.7843[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 55.957 	Loss: 1.4060[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 58.789 	Loss: 1.2742[00m
[92m  Client4 Test => 	Acc: 34.188 	Loss: 2.7587[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.010 	Loss: 2.5644[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 22.786 	Loss: 2.1294[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 37.240 	Loss: 1.9422[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 52.474 	Loss: 1.5849[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 49.479 	Loss: 1.5819[00m
[92m  Client5 Test => 	Acc: 29.863 	Loss: 3.7322[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 28.344 	Loss: 2.5192[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 23.312 	Loss: 2.2219[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 28.750 	Loss: 2.0921[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 27.438 	Loss: 2.0684[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 44.094 	Loss: 1.8533[00m
[92m  Client6 Test => 	Acc: 21.925 	Loss: 2.8230[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.938 	Loss: 2.3872[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 27.422 	Loss: 2.1484[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.094 	Loss: 2.3161[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 23.438 	Loss: 2.4058[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 25.078 	Loss: 2.4714[00m
[92m  Client7 Test => 	Acc: 12.976 	Loss: 2.8325[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 15.885 	Loss: 2.6476[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 25.130 	Loss: 2.2076[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 32.812 	Loss: 2.0229[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 45.573 	Loss: 1.8678[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 45.703 	Loss: 1.7992[00m
[92m  Client8 Test => 	Acc: 10.158 	Loss: 7.4881[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.815 	Loss: 2.2732[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 27.043 	Loss: 2.4226[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 24.760 	Loss: 2.3513[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.240 	Loss: 2.1568[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 41.587 	Loss: 1.7457[00m
[92m  Client9 Test => 	Acc: 35.567 	Loss: 3.2017[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 153.8471[00m
 Train: Round   2, Avg Accuracy 66.473 | Avg Loss 1.073
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:46:38] [setup] RAM Tracking...
[codecarbon INFO @ 02:46:38] [setup] CPU Tracking...
[codecarbon WARNING @ 02:46:38] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:46:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:46:40] [setup] GPU Tracking...
[codecarbon INFO @ 02:46:40] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:46:40] >>> Tracker's metadata:
[codecarbon INFO @ 02:46:40]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:46:40]   Python version: 3.12.7
[codecarbon INFO @ 02:46:40]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:46:40]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:46:40]   CPU count: 56
[codecarbon INFO @ 02:46:40]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:46:40]   GPU count: 2
[codecarbon INFO @ 02:46:40]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:46:43] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:46:44] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:46:44] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:46:44] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.95430047314852 W
[codecarbon INFO @ 02:46:44] 0.000028 kWh of electricity used since the beginning.
[codecarbon INFO @ 02:47:38] [setup] RAM Tracking...
[codecarbon INFO @ 02:47:38] [setup] CPU Tracking...
[codecarbon WARNING @ 02:47:38] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:47:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:47:40] [setup] GPU Tracking...
[codecarbon INFO @ 02:47:40] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:47:40] >>> Tracker's metadata:
[codecarbon INFO @ 02:47:40]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:47:40]   Python version: 3.12.7
[codecarbon INFO @ 02:47:40]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:47:40]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:47:40]   CPU count: 56
[codecarbon INFO @ 02:47:40]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:47:40]   GPU count: 2
[codecarbon INFO @ 02:47:40]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:47:43] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:47:44] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:47:44] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:47:44] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.776370866848776 W
[codecarbon INFO @ 02:47:44] 0.000037 kWh of electricity used since the beginning.

[92m  Client0 Test => 	Acc: 2.194 	Loss: 153.8079[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.201 	Loss: 173.7484[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 175.2032[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 154.0232[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 10.840 	Loss: 26.4369[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 19.141 	Loss: 4.1399[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 20.020 	Loss: 2.4234[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 27.441 	Loss: 2.1688[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 30.371 	Loss: 2.0875[00m
[92m  Client4 Test => 	Acc: 8.873 	Loss: 3.0588[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 4.036 	Loss: 33.4123[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 25.651 	Loss: 2.7330[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 17.839 	Loss: 2.6994[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 22.917 	Loss: 2.3301[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.250 	Loss: 2.1636[00m
[92m  Client5 Test => 	Acc: 12.956 	Loss: 3.7162[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 19.594 	Loss: 9.4487[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 23.469 	Loss: 2.3444[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 33.875 	Loss: 2.0839[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 49.531 	Loss: 1.6667[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 63.094 	Loss: 1.2098[00m
[92m  Client6 Test => 	Acc: 43.061 	Loss: 2.0575[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.391 	Loss: 23.1699[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 25.547 	Loss: 2.2601[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.500 	Loss: 2.1956[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.875 	Loss: 2.1843[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.406 	Loss: 2.1733[00m
[92m  Client7 Test => 	Acc: 9.642 	Loss: 3.4102[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 2.604 	Loss: 39.7467[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 19.531 	Loss: 2.5471[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 19.271 	Loss: 2.6250[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 20.312 	Loss: 2.4500[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 26.172 	Loss: 2.7795[00m
[92m  Client8 Test => 	Acc: 4.113 	Loss: 2.8215[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 17.067 	Loss: 17.9567[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.661 	Loss: 2.1441[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 42.007 	Loss: 1.7918[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 53.425 	Loss: 1.5065[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 62.380 	Loss: 1.2336[00m
[92m  Client9 Test => 	Acc: 45.794 	Loss: 1.9836[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.969 	Loss: 2.7581[00m
 Train: Round   3, Avg Accuracy 63.967 | Avg Loss 1.165
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 94.262 	Loss: 0.1849[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.208 	Loss: 209036.0139[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 74.653 	Loss: 0.6912[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.201 	Loss: 3618.7828[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 75.955 	Loss: 0.6892[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 2651.8741[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 90.929 	Loss: 0.3284[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 6450.1053[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 15.234 	Loss: 2.4643[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 35.840 	Loss: 1.9695[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 43.066 	Loss: 1.6816[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 49.023 	Loss: 1.4080[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 60.352 	Loss: 1.1840[00m
[92m  Client4 Test => 	Acc: 34.349 	Loss: 3.7654[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 21.094 	Loss: 2.5541[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 31.771 	Loss: 2.1658[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.990 	Loss: 2.0013[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 36.719 	Loss: 1.8930[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 44.141 	Loss: 1.7646[00m
[92m  Client5 Test => 	Acc: 28.305 	Loss: 2.9485[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 30.781 	Loss: 2.1782[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 58.812 	Loss: 1.3621[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 66.062 	Loss: 1.1127[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 71.000 	Loss: 0.9370[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 73.938 	Loss: 0.8039[00m
[92m  Client6 Test => 	Acc: 53.971 	Loss: 1.6953[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 21.328 	Loss: 2.4404[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.812 	Loss: 2.1952[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 35.547 	Loss: 1.9669[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 41.797 	Loss: 1.7737[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 47.812 	Loss: 1.5275[00m
[92m  Client7 Test => 	Acc: 29.613 	Loss: 2.5126[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 14.714 	Loss: 2.7075[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 26.302 	Loss: 2.2584[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 30.990 	Loss: 2.0833[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 47.396 	Loss: 1.9032[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 50.130 	Loss: 1.6890[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 03:12:53] [setup] RAM Tracking...
[codecarbon INFO @ 03:12:53] [setup] CPU Tracking...
[codecarbon WARNING @ 03:12:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:12:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:12:54] [setup] GPU Tracking...
[codecarbon INFO @ 03:12:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:12:54] >>> Tracker's metadata:
[codecarbon INFO @ 03:12:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:12:54]   Python version: 3.12.7
[codecarbon INFO @ 03:12:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:12:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:12:54]   CPU count: 56
[codecarbon INFO @ 03:12:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:12:54]   GPU count: 2
[codecarbon INFO @ 03:12:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:12:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:12:58] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:12:58] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:12:58] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.419435054750991 W
[codecarbon INFO @ 03:12:58] 0.000033 kWh of electricity used since the beginning.
[codecarbon INFO @ 03:13:54] [setup] RAM Tracking...
[codecarbon INFO @ 03:13:54] [setup] CPU Tracking...
[codecarbon WARNING @ 03:13:54] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:13:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:13:55] [setup] GPU Tracking...
[codecarbon INFO @ 03:13:55] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:13:55] >>> Tracker's metadata:
[codecarbon INFO @ 03:13:55]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:13:55]   Python version: 3.12.7
[codecarbon INFO @ 03:13:55]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:13:55]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:13:55]   CPU count: 56
[codecarbon INFO @ 03:13:55]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:13:55]   GPU count: 2
[codecarbon INFO @ 03:13:55]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:13:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:13:59] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:13:59] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:13:59] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.909210352860693 W
[codecarbon INFO @ 03:13:59] 0.000038 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 03:39:11] [setup] RAM Tracking...
[codecarbon INFO @ 03:39:11] [setup] CPU Tracking...
[codecarbon WARNING @ 03:39:11] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:39:12] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:39:12] [setup] GPU Tracking...
[codecarbon INFO @ 03:39:12] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:39:12] >>> Tracker's metadata:
[codecarbon INFO @ 03:39:12]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:39:12]   Python version: 3.12.7
[codecarbon INFO @ 03:39:12]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:39:12]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:39:12]   CPU count: 56
[codecarbon INFO @ 03:39:12]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:39:12]   GPU count: 2
[codecarbon INFO @ 03:39:12]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:39:15] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:39:17] Energy consumed for RAM : 0.000013 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:39:17] Energy consumed for all CPUs : 0.000029 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:39:17] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 16.31573153637679 W
[codecarbon INFO @ 03:39:17] 0.000047 kWh of electricity used since the beginning.
[codecarbon INFO @ 03:40:11] [setup] RAM Tracking...
[codecarbon INFO @ 03:40:11] [setup] CPU Tracking...
[codecarbon WARNING @ 03:40:11] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:40:13] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:40:13] [setup] GPU Tracking...
[codecarbon INFO @ 03:40:13] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:40:13] >>> Tracker's metadata:
[codecarbon INFO @ 03:40:13]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:40:13]   Python version: 3.12.7
[codecarbon INFO @ 03:40:13]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:40:13]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:40:13]   CPU count: 56
[codecarbon INFO @ 03:40:13]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:40:13]   GPU count: 2
[codecarbon INFO @ 03:40:13]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:40:16] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:40:17] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:40:17] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:40:17] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.890123449989293 W
[codecarbon INFO @ 03:40:17] 0.000032 kWh of electricity used since the beginning.

[92m  Client8 Test => 	Acc: 10.978 	Loss: 3.9744[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 20.072 	Loss: 2.3722[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 29.267 	Loss: 2.0886[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 45.012 	Loss: 1.6703[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 57.091 	Loss: 1.3884[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 60.998 	Loss: 1.2618[00m
[92m  Client9 Test => 	Acc: 49.406 	Loss: 2.2090[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 37.2432[00m
 Train: Round   4, Avg Accuracy 73.737 | Avg Loss 0.823
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 37.3173[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 40.9077[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.208 	Loss: 40.7623[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 37.2984[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 8.398 	Loss: 6.9087[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 23.633 	Loss: 2.3154[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 21.289 	Loss: 2.9831[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.488 	Loss: 2.2152[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 25.098 	Loss: 2.2179[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 3.6842[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 11.068 	Loss: 8.1178[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 21.094 	Loss: 2.1735[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.729 	Loss: 2.0755[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 27.604 	Loss: 2.0497[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.339 	Loss: 2.0227[00m
[92m  Client5 Test => 	Acc: 12.348 	Loss: 3.3936[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 19.062 	Loss: 3.7129[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.688 	Loss: 2.0836[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 24.812 	Loss: 2.0797[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.156 	Loss: 2.0791[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 26.000 	Loss: 2.0830[00m
[92m  Client6 Test => 	Acc: 11.081 	Loss: 3.1497[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 22.188 	Loss: 5.6632[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.734 	Loss: 2.4410[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.641 	Loss: 2.1904[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 27.109 	Loss: 2.1825[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.094 	Loss: 2.1780[00m
[92m  Client7 Test => 	Acc: 9.662 	Loss: 3.3780[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 7.031 	Loss: 9.1619[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 20.703 	Loss: 2.8381[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 21.615 	Loss: 2.2666[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 26.693 	Loss: 2.1845[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 26.693 	Loss: 2.1329[00m
[92m  Client8 Test => 	Acc: 6.198 	Loss: 3.3288[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 15.986 	Loss: 5.1739[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.421 	Loss: 2.1027[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.082 	Loss: 2.1135[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.262 	Loss: 2.1026[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 26.442 	Loss: 2.0960[00m
[92m  Client9 Test => 	Acc: 7.112 	Loss: 3.2388[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.649 	Loss: 2.6654[00m
 Train: Round   5, Avg Accuracy 56.066 | Avg Loss 1.273
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.552 	Loss: 0.2101[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 191.7445[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 0.9069[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 97.2408[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 0.9253[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 94.7793[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 88.976 	Loss: 0.3965[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 141.2702[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 11.230 	Loss: 2.5837[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 24.805 	Loss: 2.2683[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.000 	Loss: 2.2408[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.293 	Loss: 2.2187[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.805 	Loss: 2.2204[00m
[92m  Client4 Test => 	Acc: 5.597 	Loss: 3.8181[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 18.229 	Loss: 2.3853[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 31.641 	Loss: 2.0544[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 29.948 	Loss: 2.0735[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.510 	Loss: 2.0270[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.469 	Loss: 2.0251[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 04:05:39] [setup] RAM Tracking...
[codecarbon INFO @ 04:05:39] [setup] CPU Tracking...
[codecarbon WARNING @ 04:05:39] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:05:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:05:41] [setup] GPU Tracking...
[codecarbon INFO @ 04:05:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:05:41] >>> Tracker's metadata:
[codecarbon INFO @ 04:05:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:05:41]   Python version: 3.12.7
[codecarbon INFO @ 04:05:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:05:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:05:41]   CPU count: 56
[codecarbon INFO @ 04:05:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:05:41]   GPU count: 2
[codecarbon INFO @ 04:05:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:05:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:05:45] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:05:45] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:05:45] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.04532497132704 W
[codecarbon INFO @ 04:05:45] 0.000039 kWh of electricity used since the beginning.
[codecarbon INFO @ 04:06:40] [setup] RAM Tracking...
[codecarbon INFO @ 04:06:40] [setup] CPU Tracking...
[codecarbon WARNING @ 04:06:40] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:06:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:06:41] [setup] GPU Tracking...
[codecarbon INFO @ 04:06:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:06:41] >>> Tracker's metadata:
[codecarbon INFO @ 04:06:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:06:41]   Python version: 3.12.7
[codecarbon INFO @ 04:06:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:06:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:06:41]   CPU count: 56
[codecarbon INFO @ 04:06:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:06:41]   GPU count: 2
[codecarbon INFO @ 04:06:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:06:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:06:45] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:06:45] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:06:45] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.038123717609466 W
[codecarbon INFO @ 04:06:45] 0.000039 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 04:32:08] [setup] RAM Tracking...
[codecarbon INFO @ 04:32:08] [setup] CPU Tracking...
[codecarbon WARNING @ 04:32:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:32:09] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:32:09] [setup] GPU Tracking...
[codecarbon INFO @ 04:32:09] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:32:09] >>> Tracker's metadata:
[codecarbon INFO @ 04:32:09]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:32:09]   Python version: 3.12.7
[codecarbon INFO @ 04:32:09]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:32:09]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:32:09]   CPU count: 56
[codecarbon INFO @ 04:32:09]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:32:09]   GPU count: 2
[codecarbon INFO @ 04:32:09]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:32:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:32:13] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:32:13] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:32:13] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 20.907133022401627 W
[codecarbon INFO @ 04:32:13] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 04:33:08] [setup] RAM Tracking...
[codecarbon INFO @ 04:33:08] [setup] CPU Tracking...
[codecarbon WARNING @ 04:33:08] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:33:10] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:33:10] [setup] GPU Tracking...
[codecarbon INFO @ 04:33:10] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:33:10] >>> Tracker's metadata:
[codecarbon INFO @ 04:33:10]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:33:10]   Python version: 3.12.7
[codecarbon INFO @ 04:33:10]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:33:10]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:33:10]   CPU count: 56
[codecarbon INFO @ 04:33:10]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:33:10]   GPU count: 2
[codecarbon INFO @ 04:33:10]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:33:13] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:33:14] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:33:14] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:33:14] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 20.02987753609594 W
[codecarbon INFO @ 04:33:14] 0.000030 kWh of electricity used since the beginning.

[92m  Client5 Test => 	Acc: 12.348 	Loss: 3.4124[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 21.781 	Loss: 2.2104[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 24.656 	Loss: 2.0874[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 26.406 	Loss: 2.0802[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.469 	Loss: 2.0779[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.812 	Loss: 2.0762[00m
[92m  Client6 Test => 	Acc: 12.382 	Loss: 3.1893[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 26.641 	Loss: 2.4083[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 23.047 	Loss: 2.2010[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.188 	Loss: 2.1736[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.875 	Loss: 2.1809[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.109 	Loss: 2.1729[00m
[92m  Client7 Test => 	Acc: 9.662 	Loss: 3.3954[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 11.068 	Loss: 2.7710[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 23.698 	Loss: 2.3712[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.344 	Loss: 2.1450[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 22.656 	Loss: 2.1316[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 25.521 	Loss: 2.1036[00m
[92m  Client8 Test => 	Acc: 4.100 	Loss: 3.5999[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 23.017 	Loss: 2.3141[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.601 	Loss: 2.1276[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 27.103 	Loss: 2.1018[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.562 	Loss: 2.0897[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 23.618 	Loss: 2.0911[00m
[92m  Client9 Test => 	Acc: 7.112 	Loss: 3.1897[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.188 	Loss: 14.2031[00m
 Train: Round   6, Avg Accuracy 55.733 | Avg Loss 1.269
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 19.8265[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 15.0747[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 15.8969[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 17.6909[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 7.031 	Loss: 6.9013[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 14.551 	Loss: 2.5410[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.293 	Loss: 2.3094[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.098 	Loss: 2.2461[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 25.000 	Loss: 2.2175[00m
[92m  Client4 Test => 	Acc: 5.604 	Loss: 3.6920[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 0.391 	Loss: 8.6781[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 4.557 	Loss: 2.6678[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 26.562 	Loss: 2.3985[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.250 	Loss: 2.1152[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.339 	Loss: 2.0434[00m
[92m  Client5 Test => 	Acc: 12.341 	Loss: 3.5828[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 14.750 	Loss: 3.5781[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.844 	Loss: 2.0891[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.562 	Loss: 2.0765[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.906 	Loss: 2.0720[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 24.844 	Loss: 2.0781[00m
[92m  Client6 Test => 	Acc: 12.348 	Loss: 3.1966[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 7.109 	Loss: 5.7445[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.953 	Loss: 2.4003[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 25.625 	Loss: 2.2021[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.953 	Loss: 2.1809[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.031 	Loss: 2.1754[00m
[92m  Client7 Test => 	Acc: 9.656 	Loss: 3.3514[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 9.3783[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 5.339 	Loss: 2.8106[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.734 	Loss: 2.5344[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.734 	Loss: 2.2590[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.604 	Loss: 2.1231[00m
[92m  Client8 Test => 	Acc: 4.093 	Loss: 3.8764[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 7.692 	Loss: 5.1163[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.481 	Loss: 2.1915[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 27.043 	Loss: 2.1031[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 24.219 	Loss: 2.0988[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 25.661 	Loss: 2.1058[00m
[92m  Client9 Test => 	Acc: 7.112 	Loss: 3.1651[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.656 	Loss: 2.6741[00m
 Train: Round   7, Avg Accuracy 56.048 | Avg Loss 1.274
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 93.481 	Loss: 0.2415[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 114.6585[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 1.0512[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 60.6802[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 1.0596[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 04:58:28] [setup] RAM Tracking...
[codecarbon INFO @ 04:58:28] [setup] CPU Tracking...
[codecarbon WARNING @ 04:58:28] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:58:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:58:30] [setup] GPU Tracking...
[codecarbon INFO @ 04:58:30] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:58:30] >>> Tracker's metadata:
[codecarbon INFO @ 04:58:30]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:58:30]   Python version: 3.12.7
[codecarbon INFO @ 04:58:30]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:58:30]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:58:30]   CPU count: 56
[codecarbon INFO @ 04:58:30]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:58:30]   GPU count: 2
[codecarbon INFO @ 04:58:30]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:58:33] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:58:34] Energy consumed for RAM : 0.000014 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:58:34] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:58:34] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 17.429636518228534 W
[codecarbon INFO @ 04:58:34] 0.000051 kWh of electricity used since the beginning.
[codecarbon INFO @ 04:59:29] [setup] RAM Tracking...
[codecarbon INFO @ 04:59:29] [setup] CPU Tracking...
[codecarbon WARNING @ 04:59:29] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:59:31] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:59:31] [setup] GPU Tracking...
[codecarbon INFO @ 04:59:31] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:59:31] >>> Tracker's metadata:
[codecarbon INFO @ 04:59:31]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:59:31]   Python version: 3.12.7
[codecarbon INFO @ 04:59:31]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:59:31]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:59:31]   CPU count: 56
[codecarbon INFO @ 04:59:31]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:59:31]   GPU count: 2
[codecarbon INFO @ 04:59:31]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:59:34] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:59:34] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:59:34] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:59:34] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.460902395708203 W
[codecarbon INFO @ 04:59:34] 0.000031 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 05:25:00] [setup] RAM Tracking...
[codecarbon INFO @ 05:25:00] [setup] CPU Tracking...
[codecarbon WARNING @ 05:25:00] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:25:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:25:01] [setup] GPU Tracking...
[codecarbon INFO @ 05:25:01] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:25:01] >>> Tracker's metadata:
[codecarbon INFO @ 05:25:01]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:25:01]   Python version: 3.12.7
[codecarbon INFO @ 05:25:01]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:25:01]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:25:01]   CPU count: 56
[codecarbon INFO @ 05:25:01]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:25:01]   GPU count: 2
[codecarbon INFO @ 05:25:01]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:25:04] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:25:05] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:25:05] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:25:05] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.272358558334282 W
[codecarbon INFO @ 05:25:05] 0.000030 kWh of electricity used since the beginning.

[92m  Client2 Test => 	Acc: 2.194 	Loss: 59.4892[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 88.889 	Loss: 0.4451[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.194 	Loss: 87.2508[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 8.887 	Loss: 2.6112[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 20.605 	Loss: 2.2726[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 24.707 	Loss: 2.2533[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 25.781 	Loss: 2.2071[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.316 	Loss: 2.2261[00m
[92m  Client4 Test => 	Acc: 5.611 	Loss: 3.8057[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 14.844 	Loss: 2.3782[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 29.688 	Loss: 2.0633[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.729 	Loss: 2.0648[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.250 	Loss: 2.0192[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 31.120 	Loss: 2.0220[00m
[92m  Client5 Test => 	Acc: 12.355 	Loss: 3.4311[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 22.594 	Loss: 2.1992[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 24.625 	Loss: 2.0860[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 26.125 	Loss: 2.0805[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 23.938 	Loss: 2.0792[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.781 	Loss: 2.0767[00m
[92m  Client6 Test => 	Acc: 12.375 	Loss: 3.2067[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 27.109 	Loss: 2.3941[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 24.844 	Loss: 2.1994[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.875 	Loss: 2.1801[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.953 	Loss: 2.1826[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 27.031 	Loss: 2.1760[00m
[92m  Client7 Test => 	Acc: 9.649 	Loss: 3.3309[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 10.807 	Loss: 2.6989[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 24.740 	Loss: 2.2406[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.995 	Loss: 2.1297[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.865 	Loss: 2.1379[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.865 	Loss: 2.1037[00m
[92m  Client8 Test => 	Acc: 4.087 	Loss: 3.6706[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 24.099 	Loss: 2.2909[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 26.743 	Loss: 2.1342[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 24.700 	Loss: 2.1104[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 26.803 	Loss: 2.1053[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 24.639 	Loss: 2.1000[00m
[92m  Client9 Test => 	Acc: 7.132 	Loss: 3.2333[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.201 	Loss: 10.5964[00m
 Train: Round   8, Avg Accuracy 56.075 | Avg Loss 1.270
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0003[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 16.2385[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0004[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0002[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 13.4216[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0004[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0002[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 13.2434[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0004[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0002[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client3 Test => 	Acc: 2.188 	Loss: 13.2178[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 7.129 	Loss: 6.0811[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 7.129 	Loss: 2.5705[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 23.047 	Loss: 2.3338[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 24.512 	Loss: 2.2375[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 24.414 	Loss: 2.2197[00m
[92m  Client4 Test => 	Acc: 5.590 	Loss: 3.7222[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 0.391 	Loss: 7.4333[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 0.391 	Loss: 2.9325[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 18.880 	Loss: 2.3723[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 19.922 	Loss: 2.1544[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 30.078 	Loss: 2.0410[00m
[92m  Client5 Test => 	Acc: 12.321 	Loss: 3.2372[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 12.781 	Loss: 3.3487[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.844 	Loss: 2.0832[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.875 	Loss: 2.0746[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 26.625 	Loss: 2.0746[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 24.812 	Loss: 2.0747[00m
[92m  Client6 Test => 	Acc: 12.328 	Loss: 3.2176[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 6.172 	Loss: 5.1886[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 26.719 	Loss: 2.3621[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 26.406 	Loss: 2.2039[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 25.625 	Loss: 2.1875[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 26.953 	Loss: 2.1751[00m
[92m  Client7 Test => 	Acc: 9.676 	Loss: 3.3595[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 0.260 	Loss: 8.2293[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 0.260 	Loss: 3.2295[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 10.547 	Loss: 2.6499[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 20.182 	Loss: 2.4128[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.995 	Loss: 2.1965[00m
[92m  Client8 Test => 	Acc: 4.093 	Loss: 3.2362[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 4.387 	Loss: 4.6698[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 24.700 	Loss: 2.1985[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.442 	Loss: 2.1043[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.901 	Loss: 2.0971[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 27.103 	Loss: 2.0916[00m
[92m  Client9 Test => 	Acc: 7.105 	Loss: 3.2228[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.649 	Loss: 2.7078[00m
 Train: Round   9, Avg Accuracy 56.136 | Avg Loss 1.280
Training and Evaluation completed!
===== END Tue 12/23/2025  5:26:04.23 ===== 
