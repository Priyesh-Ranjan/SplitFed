===== START Thu 01/15/2026 19:26:14.05 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 19:26:46] [setup] RAM Tracking...
[codecarbon INFO @ 19:26:46] [setup] CPU Tracking...
[codecarbon WARNING @ 19:26:46] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:26:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:26:48] [setup] GPU Tracking...
[codecarbon INFO @ 19:26:48] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:26:48] >>> Tracker's metadata:
[codecarbon INFO @ 19:26:48]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:26:48]   Python version: 3.12.7
[codecarbon INFO @ 19:26:48]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:26:48]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:26:48]   CPU count: 56
[codecarbon INFO @ 19:26:48]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:26:48]   GPU count: 2
[codecarbon INFO @ 19:26:48]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:26:51] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:26:52] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:26:52] Energy consumed for all CPUs : 0.000042 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:26:52] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 17.80689296167915 W
[codecarbon INFO @ 19:26:52] 0.000068 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 19:52:00] [setup] RAM Tracking...
[codecarbon INFO @ 19:52:00] [setup] CPU Tracking...
[codecarbon WARNING @ 19:52:00] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:52:01] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:52:01] [setup] GPU Tracking...
[codecarbon INFO @ 19:52:01] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:52:02] >>> Tracker's metadata:
[codecarbon INFO @ 19:52:02]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:52:02]   Python version: 3.12.7
[codecarbon INFO @ 19:52:02]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:52:02]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:52:02]   CPU count: 56
[codecarbon INFO @ 19:52:02]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:52:02]   GPU count: 2
[codecarbon INFO @ 19:52:02]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:52:05] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:52:05] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:52:05] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:52:05] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.333759898036313 W
[codecarbon INFO @ 19:52:05] 0.000029 kWh of electricity used since the beginning.
[codecarbon INFO @ 19:53:00] [setup] RAM Tracking...
[codecarbon INFO @ 19:53:00] [setup] CPU Tracking...
[codecarbon WARNING @ 19:53:00] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:53:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:53:02] [setup] GPU Tracking...
[codecarbon INFO @ 19:53:02] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:53:02] >>> Tracker's metadata:
[codecarbon INFO @ 19:53:02]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:53:02]   Python version: 3.12.7
[codecarbon INFO @ 19:53:02]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:53:02]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:53:02]   CPU count: 56
[codecarbon INFO @ 19:53:02]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:53:02]   GPU count: 2
[codecarbon INFO @ 19:53:02]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:53:05] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:53:06] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:53:06] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:53:06] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 18.734513948366164 W
[codecarbon INFO @ 19:53:06] 0.000043 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 2                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: flame               #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: backdoor pls->14    #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=2_flame#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=2_flame----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.794 	Loss: 0.0954[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 83176492866.9538[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 89.844 	Loss: 0.2995[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 58695842201.6000[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 21.701 	Loss: 4.9984[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 29.340 	Loss: 2.3674[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.969 	Loss: 2.0736[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 43.056 	Loss: 1.9935[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.101 	Loss: 1.9564[00m
[92m  Client2 Test => 	Acc: 25.355 	Loss: 3.2112[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 27.300 	Loss: 8.1722[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 31.120 	Loss: 2.2429[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 37.066 	Loss: 1.9482[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 60.113 	Loss: 1.3946[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 70.790 	Loss: 1.0508[00m
[92m  Client3 Test => 	Acc: 27.657 	Loss: 2.8221[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 14.941 	Loss: 5.5243[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 19.727 	Loss: 2.7049[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 38.965 	Loss: 1.9154[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 50.000 	Loss: 1.5831[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 57.031 	Loss: 1.2884[00m
[92m  Client4 Test => 	Acc: 31.539 	Loss: 3.0490[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.661 	Loss: 2.9271[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 30.339 	Loss: 2.3486[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 30.859 	Loss: 2.0911[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 43.490 	Loss: 1.8266[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 38.932 	Loss: 1.8961[00m
[92m  Client5 Test => 	Acc: 22.918 	Loss: 3.1405[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 27.750 	Loss: 2.8693[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 38.094 	Loss: 1.9483[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 55.125 	Loss: 1.4642[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 65.125 	Loss: 1.1378[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 71.250 	Loss: 0.9270[00m
[92m  Client6 Test => 	Acc: 51.158 	Loss: 1.8570[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 19.922 	Loss: 4.7420[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 23.828 	Loss: 2.5055[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 27.578 	Loss: 2.1426[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 32.656 	Loss: 1.9642[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 40.234 	Loss: 1.8670[00m
[92m  Client7 Test => 	Acc: 22.542 	Loss: 3.4771[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 17.057 	Loss: 5.6773[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 23.568 	Loss: 2.1984[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.604 	Loss: 2.1212[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 23.828 	Loss: 2.1742[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 33.594 	Loss: 1.9709[00m
[92m  Client8 Test => 	Acc: 9.900 	Loss: 3.9412[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.651 	Loss: 3.1770[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 28.726 	Loss: 2.0580[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 46.154 	Loss: 1.6629[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 55.228 	Loss: 1.4409[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 62.560 	Loss: 1.2138[00m
[92m  Client9 Test => 	Acc: 49.537 	Loss: 2.1457[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 2.7348[00m
 Train: Round   0, Avg Accuracy 61.649 | Avg Loss 1.217
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 99.946 	Loss: 0.0863[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 7947815.4615[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 99.740 	Loss: 0.3424[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 962532.0308[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 38.368 	Loss: 2.4029[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 45.833 	Loss: 1.6752[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 55.556 	Loss: 1.4882[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 60.243 	Loss: 1.3210[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 63.889 	Loss: 1.1211[00m
[92m  Client2 Test => 	Acc: 37.803 	Loss: 2.7717[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 38.281 	Loss: 1.8943[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 67.448 	Loss: 1.1999[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 74.566 	Loss: 0.9555[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 75.521 	Loss: 0.9962[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 55.599 	Loss: 1.6666[00m
[92m  Client3 Test => 	Acc: 26.853 	Loss: 3.4223[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 18.848 	Loss: 2.4413[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 20:18:15] [setup] RAM Tracking...
[codecarbon INFO @ 20:18:15] [setup] CPU Tracking...
[codecarbon WARNING @ 20:18:15] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:18:17] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:18:17] [setup] GPU Tracking...
[codecarbon INFO @ 20:18:17] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:18:17] >>> Tracker's metadata:
[codecarbon INFO @ 20:18:17]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:18:17]   Python version: 3.12.7
[codecarbon INFO @ 20:18:17]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:18:17]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:18:17]   CPU count: 56
[codecarbon INFO @ 20:18:17]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:18:17]   GPU count: 2
[codecarbon INFO @ 20:18:17]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:18:20] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:18:20] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:18:20] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:18:20] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.33587727898747 W
[codecarbon INFO @ 20:18:20] 0.000034 kWh of electricity used since the beginning.
[codecarbon INFO @ 20:19:16] [setup] RAM Tracking...
[codecarbon INFO @ 20:19:16] [setup] CPU Tracking...
[codecarbon WARNING @ 20:19:16] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:19:17] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:19:17] [setup] GPU Tracking...
[codecarbon INFO @ 20:19:17] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:19:17] >>> Tracker's metadata:
[codecarbon INFO @ 20:19:17]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:19:17]   Python version: 3.12.7
[codecarbon INFO @ 20:19:17]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:19:17]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:19:17]   CPU count: 56
[codecarbon INFO @ 20:19:17]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:19:17]   GPU count: 2
[codecarbon INFO @ 20:19:17]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:19:20] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:19:21] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:19:21] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:19:21] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.56097239594593 W
[codecarbon INFO @ 20:19:21] 0.000028 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 20:44:32] [setup] RAM Tracking...
[codecarbon INFO @ 20:44:32] [setup] CPU Tracking...
[codecarbon WARNING @ 20:44:32] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:44:34] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:44:34] [setup] GPU Tracking...
[codecarbon INFO @ 20:44:34] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:44:34] >>> Tracker's metadata:
[codecarbon INFO @ 20:44:34]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:44:34]   Python version: 3.12.7
[codecarbon INFO @ 20:44:34]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:44:34]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:44:34]   CPU count: 56
[codecarbon INFO @ 20:44:34]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:44:34]   GPU count: 2
[codecarbon INFO @ 20:44:34]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:44:37] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:44:37] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:44:37] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:44:37] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.04486422265727 W
[codecarbon INFO @ 20:44:37] 0.000030 kWh of electricity used since the beginning.
[codecarbon INFO @ 20:45:34] [setup] RAM Tracking...
[codecarbon INFO @ 20:45:34] [setup] CPU Tracking...
[codecarbon WARNING @ 20:45:34] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:45:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:45:35] [setup] GPU Tracking...
[codecarbon INFO @ 20:45:35] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:45:36] >>> Tracker's metadata:
[codecarbon INFO @ 20:45:36]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:45:36]   Python version: 3.12.7
[codecarbon INFO @ 20:45:36]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:45:36]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:45:36]   CPU count: 56
[codecarbon INFO @ 20:45:36]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:45:36]   GPU count: 2
[codecarbon INFO @ 20:45:36]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:45:39] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:45:40] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:45:40] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:45:40] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 18.052062647592273 W
[codecarbon INFO @ 20:45:40] 0.000043 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 40.430 	Loss: 1.7634[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 31.934 	Loss: 2.3466[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 37.891 	Loss: 1.7926[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 41.113 	Loss: 1.6990[00m
[92m  Client4 Test => 	Acc: 16.994 	Loss: 3.9781[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 14.974 	Loss: 2.4072[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 38.151 	Loss: 1.9142[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 47.656 	Loss: 1.7946[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 51.693 	Loss: 1.5442[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 60.677 	Loss: 1.2584[00m
[92m  Client5 Test => 	Acc: 32.776 	Loss: 2.8701[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.688 	Loss: 2.5496[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 36.562 	Loss: 2.0643[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 57.156 	Loss: 1.4429[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 69.750 	Loss: 1.0078[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 70.875 	Loss: 0.9418[00m
[92m  Client6 Test => 	Acc: 53.231 	Loss: 1.7093[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 19.062 	Loss: 2.5056[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 27.500 	Loss: 2.1914[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 35.469 	Loss: 1.9395[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 44.688 	Loss: 1.6340[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 40.000 	Loss: 1.8298[00m
[92m  Client7 Test => 	Acc: 29.637 	Loss: 2.5763[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 14.844 	Loss: 2.6078[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 34.766 	Loss: 2.1424[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 43.359 	Loss: 1.8675[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 56.120 	Loss: 1.3892[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 67.318 	Loss: 1.0463[00m
[92m  Client8 Test => 	Acc: 25.253 	Loss: 2.4692[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 22.416 	Loss: 2.3413[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 30.108 	Loss: 2.0236[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 48.197 	Loss: 1.6277[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 54.507 	Loss: 1.5235[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 70.192 	Loss: 1.0737[00m
[92m  Client9 Test => 	Acc: 51.896 	Loss: 2.0610[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.722 	Loss: 2.6968[00m
 Train: Round   1, Avg Accuracy 66.966 | Avg Loss 1.064
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 97.198 	Loss: 0.0935[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.208 	Loss: 19886350.7692[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 90.365 	Loss: 0.4009[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 41503.4116[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.882 	Loss: 2.0812[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 48.177 	Loss: 1.6735[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 57.986 	Loss: 1.3195[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 51.823 	Loss: 1.5451[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 61.111 	Loss: 1.2131[00m
[92m  Client2 Test => 	Acc: 34.287 	Loss: 2.8476[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 51.215 	Loss: 1.6231[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 72.656 	Loss: 0.9920[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 77.648 	Loss: 0.8201[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 80.165 	Loss: 0.6519[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 83.377 	Loss: 0.5375[00m
[92m  Client3 Test => 	Acc: 45.770 	Loss: 2.0892[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 24.902 	Loss: 2.1462[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 51.172 	Loss: 1.5230[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 64.453 	Loss: 1.1448[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 67.578 	Loss: 1.0068[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 73.535 	Loss: 0.8730[00m
[92m  Client4 Test => 	Acc: 34.311 	Loss: 3.4825[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 30.208 	Loss: 2.2786[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 50.260 	Loss: 1.6062[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 55.729 	Loss: 1.4035[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 68.099 	Loss: 1.0191[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 66.927 	Loss: 0.9922[00m
[92m  Client5 Test => 	Acc: 46.824 	Loss: 3.1888[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 28.875 	Loss: 2.2263[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 26.406 	Loss: 2.5369[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 21.875 	Loss: 2.7949[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.344 	Loss: 2.1229[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.969 	Loss: 2.0856[00m
[92m  Client6 Test => 	Acc: 12.348 	Loss: 3.2495[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 24.688 	Loss: 2.3250[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 38.750 	Loss: 1.8346[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 44.609 	Loss: 1.6531[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 54.844 	Loss: 1.3558[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 65.859 	Loss: 1.0556[00m
[92m  Client7 Test => 	Acc: 39.763 	Loss: 2.5339[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 17.188 	Loss: 2.5999[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 37.370 	Loss: 1.8832[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 54.818 	Loss: 1.6078[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 55.469 	Loss: 1.4596[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 70.312 	Loss: 0.9963[00m
[92m  Client8 Test => 	Acc: 29.607 	Loss: 2.5673[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 29.748 	Loss: 2.0254[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 55.409 	Loss: 1.5297[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 56.611 	Loss: 1.4434[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 67.548 	Loss: 1.1311[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 77.945 	Loss: 0.8059[00m
[92m  Client9 Test => 	Acc: 53.983 	Loss: 2.1151[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 7.682 	Loss: 3.4849[00m
 Train: Round   2, Avg Accuracy 72.504 | Avg Loss 0.856
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 99.731 	Loss: 0.0294[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 12598717.8923[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 97.917 	Loss: 0.1017[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 21:10:40] [setup] RAM Tracking...
[codecarbon INFO @ 21:10:40] [setup] CPU Tracking...
[codecarbon WARNING @ 21:10:40] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:10:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:10:41] [setup] GPU Tracking...
[codecarbon INFO @ 21:10:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:10:41] >>> Tracker's metadata:
[codecarbon INFO @ 21:10:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:10:41]   Python version: 3.12.7
[codecarbon INFO @ 21:10:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:10:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:10:41]   CPU count: 56
[codecarbon INFO @ 21:10:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:10:41]   GPU count: 2
[codecarbon INFO @ 21:10:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:10:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:10:45] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:10:45] Energy consumed for all CPUs : 0.000027 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:10:45] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.994824018144318 W
[codecarbon INFO @ 21:10:45] 0.000043 kWh of electricity used since the beginning.
[codecarbon INFO @ 21:11:40] [setup] RAM Tracking...
[codecarbon INFO @ 21:11:40] [setup] CPU Tracking...
[codecarbon WARNING @ 21:11:40] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:11:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:11:42] [setup] GPU Tracking...
[codecarbon INFO @ 21:11:42] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:11:42] >>> Tracker's metadata:
[codecarbon INFO @ 21:11:42]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:11:42]   Python version: 3.12.7
[codecarbon INFO @ 21:11:42]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:11:42]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:11:42]   CPU count: 56
[codecarbon INFO @ 21:11:42]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:11:42]   GPU count: 2
[codecarbon INFO @ 21:11:42]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:11:45] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:11:46] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:11:46] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:11:46] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.479283053841748 W
[codecarbon INFO @ 21:11:46] 0.000035 kWh of electricity used since the beginning.

[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.208 	Loss: 52812.2787[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 41.233 	Loss: 2.0386[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 50.781 	Loss: 1.6019[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 59.201 	Loss: 1.3685[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 64.583 	Loss: 1.1421[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 68.056 	Loss: 1.0514[00m
[92m  Client2 Test => 	Acc: 41.457 	Loss: 2.6836[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 47.569 	Loss: 1.6816[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 67.839 	Loss: 1.1033[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 77.821 	Loss: 0.7413[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 79.688 	Loss: 0.6689[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 83.507 	Loss: 0.5457[00m
[92m  Client3 Test => 	Acc: 49.746 	Loss: 1.7035[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 25.684 	Loss: 2.3192[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 40.527 	Loss: 1.7720[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 45.898 	Loss: 1.5857[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 45.898 	Loss: 1.5636[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 49.707 	Loss: 1.4619[00m
[92m  Client4 Test => 	Acc: 21.591 	Loss: 3.8624[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 28.906 	Loss: 2.3746[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 45.312 	Loss: 1.7381[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 57.943 	Loss: 1.4030[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 66.927 	Loss: 1.0377[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 74.870 	Loss: 0.8326[00m
[92m  Client5 Test => 	Acc: 44.582 	Loss: 2.6414[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 24.906 	Loss: 2.2093[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 53.438 	Loss: 1.4888[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 68.531 	Loss: 1.0132[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 77.938 	Loss: 0.7696[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 78.250 	Loss: 0.7240[00m
[92m  Client6 Test => 	Acc: 58.132 	Loss: 1.7135[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 24.297 	Loss: 2.3609[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 38.281 	Loss: 1.9222[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 44.141 	Loss: 1.7515[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 44.766 	Loss: 1.6636[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 53.047 	Loss: 1.4566[00m
[92m  Client7 Test => 	Acc: 29.074 	Loss: 3.3557[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 13.542 	Loss: 2.8559[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 34.635 	Loss: 2.0281[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 38.021 	Loss: 1.8001[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 44.010 	Loss: 1.7052[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 50.391 	Loss: 1.6563[00m
[92m  Client8 Test => 	Acc: 18.120 	Loss: 3.1440[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 27.945 	Loss: 2.1779[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 47.416 	Loss: 1.6508[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 66.226 	Loss: 1.1601[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 76.562 	Loss: 0.8273[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 80.409 	Loss: 0.6452[00m
[92m  Client9 Test => 	Acc: 57.002 	Loss: 2.0303[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.355 	Loss: 3.0040[00m
 Train: Round   3, Avg Accuracy 73.824 | Avg Loss 0.837
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.552 	Loss: 0.1098[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.208 	Loss: 9605675.9385[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 88.889 	Loss: 0.4551[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 84572.7793[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 38.542 	Loss: 2.2206[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 63.194 	Loss: 1.2005[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 67.014 	Loss: 1.0662[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 72.135 	Loss: 0.8854[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 75.347 	Loss: 0.7804[00m
[92m  Client2 Test => 	Acc: 55.783 	Loss: 1.8937[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 59.505 	Loss: 1.5102[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 79.731 	Loss: 0.7086[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 84.071 	Loss: 0.5503[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 86.241 	Loss: 0.4171[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 91.189 	Loss: 0.2959[00m
[92m  Client3 Test => 	Acc: 72.972 	Loss: 1.3541[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 35.840 	Loss: 2.1200[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 54.297 	Loss: 1.4024[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 60.547 	Loss: 1.1669[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 65.234 	Loss: 1.0249[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 69.727 	Loss: 0.8555[00m
[92m  Client4 Test => 	Acc: 44.400 	Loss: 3.0304[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 39.323 	Loss: 2.1412[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 64.714 	Loss: 1.2686[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 69.661 	Loss: 0.9351[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 73.568 	Loss: 0.7459[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 71.615 	Loss: 0.9032[00m
[92m  Client5 Test => 	Acc: 43.942 	Loss: 2.6397[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 54.875 	Loss: 1.5665[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 71.875 	Loss: 0.9114[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 71.906 	Loss: 0.9323[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 79.406 	Loss: 0.6445[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 75.906 	Loss: 0.7913[00m
[92m  Client6 Test => 	Acc: 61.095 	Loss: 1.6166[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 31.328 	Loss: 2.2637[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 50.781 	Loss: 1.6051[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 51.719 	Loss: 1.4256[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 69.609 	Loss: 0.9306[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 69.688 	Loss: 0.9518[00m
[92m  Client7 Test => 	Acc: 45.065 	Loss: 2.3007[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 32.161 	Loss: 2.6120[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 58.724 	Loss: 1.5040[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 67.708 	Loss: 1.1036[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 77.214 	Loss: 0.7769[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 81.380 	Loss: 0.6144[00m
[92m  Client8 Test => 	Acc: 41.068 	Loss: 2.2206[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 39.363 	Loss: 1.8642[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 21:36:52] [setup] RAM Tracking...
[codecarbon INFO @ 21:36:52] [setup] CPU Tracking...
[codecarbon WARNING @ 21:36:52] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:36:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:36:54] [setup] GPU Tracking...
[codecarbon INFO @ 21:36:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:36:54] >>> Tracker's metadata:
[codecarbon INFO @ 21:36:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:36:54]   Python version: 3.12.7
[codecarbon INFO @ 21:36:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:36:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:36:54]   CPU count: 56
[codecarbon INFO @ 21:36:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:36:54]   GPU count: 2
[codecarbon INFO @ 21:36:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:36:57] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:36:58] Energy consumed for RAM : 0.000013 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:36:58] Energy consumed for all CPUs : 0.000028 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:36:58] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 16.594676010893252 W
[codecarbon INFO @ 21:36:58] 0.000046 kWh of electricity used since the beginning.
[codecarbon INFO @ 21:37:55] [setup] RAM Tracking...
[codecarbon INFO @ 21:37:55] [setup] CPU Tracking...
[codecarbon WARNING @ 21:37:55] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:37:57] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:37:57] [setup] GPU Tracking...
[codecarbon INFO @ 21:37:57] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:37:57] >>> Tracker's metadata:
[codecarbon INFO @ 21:37:57]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:37:57]   Python version: 3.12.7
[codecarbon INFO @ 21:37:57]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:37:57]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:37:57]   CPU count: 56
[codecarbon INFO @ 21:37:57]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:37:57]   GPU count: 2
[codecarbon INFO @ 21:37:57]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:38:00] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:38:01] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:38:01] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:38:01] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 27.24971406943469 W
[codecarbon INFO @ 21:38:01] 0.000043 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 22:03:14] [setup] RAM Tracking...
[codecarbon INFO @ 22:03:14] [setup] CPU Tracking...
[codecarbon WARNING @ 22:03:14] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:03:16] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:03:16] [setup] GPU Tracking...
[codecarbon INFO @ 22:03:16] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:03:16] >>> Tracker's metadata:
[codecarbon INFO @ 22:03:16]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:03:16]   Python version: 3.12.7
[codecarbon INFO @ 22:03:16]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:03:16]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:03:16]   CPU count: 56
[codecarbon INFO @ 22:03:16]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:03:16]   GPU count: 2
[codecarbon INFO @ 22:03:16]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:03:19] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:03:20] Energy consumed for RAM : 0.000014 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:03:20] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:03:20] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 17.278743219001026 W
[codecarbon INFO @ 22:03:20] 0.000050 kWh of electricity used since the beginning.
[codecarbon INFO @ 22:04:15] [setup] RAM Tracking...
[codecarbon INFO @ 22:04:15] [setup] CPU Tracking...
[codecarbon WARNING @ 22:04:15] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:04:17] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:04:17] [setup] GPU Tracking...
[codecarbon INFO @ 22:04:17] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:04:17] >>> Tracker's metadata:
[codecarbon INFO @ 22:04:17]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:04:17]   Python version: 3.12.7
[codecarbon INFO @ 22:04:17]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:04:17]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:04:17]   CPU count: 56
[codecarbon INFO @ 22:04:17]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:04:17]   GPU count: 2
[codecarbon INFO @ 22:04:17]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:04:20] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:04:21] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:04:21] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:04:21] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.430918345419844 W
[codecarbon INFO @ 22:04:21] 0.000040 kWh of electricity used since the beginning.

[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 59.856 	Loss: 1.3139[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 75.240 	Loss: 0.8368[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 83.534 	Loss: 0.5425[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 85.757 	Loss: 0.4846[00m
[92m  Client9 Test => 	Acc: 62.468 	Loss: 1.2327[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 15.847 	Loss: 3.8117[00m
 Train: Round   4, Avg Accuracy 82.061 | Avg Loss 0.568
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 99.650 	Loss: 0.0206[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 1079942.4385[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 99.132 	Loss: 0.0870[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 180082.3139[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 57.118 	Loss: 1.4953[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 72.830 	Loss: 0.8263[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 74.653 	Loss: 0.7523[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 81.510 	Loss: 0.5964[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 84.288 	Loss: 0.4544[00m
[92m  Client2 Test => 	Acc: 62.973 	Loss: 1.4625[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 69.618 	Loss: 1.1064[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 82.422 	Loss: 0.5691[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 83.160 	Loss: 0.5336[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 89.323 	Loss: 0.3456[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 91.233 	Loss: 0.3003[00m
[92m  Client3 Test => 	Acc: 70.692 	Loss: 1.3634[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 52.344 	Loss: 1.6158[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 73.340 	Loss: 0.8115[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 77.148 	Loss: 0.6959[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 84.277 	Loss: 0.4738[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 87.012 	Loss: 0.4547[00m
[92m  Client4 Test => 	Acc: 53.506 	Loss: 2.1509[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 47.786 	Loss: 1.9713[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 67.708 	Loss: 1.0417[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 74.219 	Loss: 0.8305[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 78.255 	Loss: 0.6924[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 81.641 	Loss: 0.5695[00m
[92m  Client5 Test => 	Acc: 54.914 	Loss: 2.4879[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 58.906 	Loss: 1.3887[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 76.094 	Loss: 0.7655[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 84.594 	Loss: 0.5322[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 86.594 	Loss: 0.4659[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 88.781 	Loss: 0.3987[00m
[92m  Client6 Test => 	Acc: 67.289 	Loss: 1.2240[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 33.906 	Loss: 2.1016[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 60.391 	Loss: 1.2033[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 70.156 	Loss: 0.8986[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 72.734 	Loss: 0.8732[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 78.047 	Loss: 0.6976[00m
[92m  Client7 Test => 	Acc: 59.776 	Loss: 1.8115[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 34.766 	Loss: 2.3846[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 67.057 	Loss: 1.1044[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 77.474 	Loss: 0.7162[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 80.990 	Loss: 0.6105[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 85.286 	Loss: 0.5303[00m
[92m  Client8 Test => 	Acc: 47.651 	Loss: 1.7087[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 46.995 	Loss: 1.8312[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 74.339 	Loss: 0.9208[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 82.873 	Loss: 0.6140[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 84.916 	Loss: 0.5412[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 85.517 	Loss: 0.4967[00m
[92m  Client9 Test => 	Acc: 65.700 	Loss: 1.3361[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 31.636 	Loss: 2.1042[00m
 Train: Round   5, Avg Accuracy 88.180 | Avg Loss 0.390
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.363 	Loss: 0.2112[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 253028624478.5231[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 80.208 	Loss: 0.6799[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.201 	Loss: 11019.1879[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 56.337 	Loss: 1.3778[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 74.045 	Loss: 0.7993[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 80.122 	Loss: 0.6074[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 82.465 	Loss: 0.5639[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 85.590 	Loss: 0.4414[00m
[92m  Client2 Test => 	Acc: 67.602 	Loss: 1.4213[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 74.175 	Loss: 1.0037[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 85.286 	Loss: 0.4819[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 87.500 	Loss: 0.3881[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 90.104 	Loss: 0.3087[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 92.318 	Loss: 0.2622[00m
[92m  Client3 Test => 	Acc: 70.627 	Loss: 1.3262[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 54.883 	Loss: 1.5648[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 77.246 	Loss: 0.7096[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 82.617 	Loss: 0.5487[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 87.793 	Loss: 0.3967[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 89.258 	Loss: 0.3204[00m
[92m  Client4 Test => 	Acc: 57.630 	Loss: 1.8263[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 63.281 	Loss: 1.2045[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 75.911 	Loss: 0.6992[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 81.510 	Loss: 0.5168[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 83.203 	Loss: 0.4710[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 86.849 	Loss: 0.3985[00m
[92m  Client5 Test => 	Acc: 67.890 	Loss: 1.8324[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 70.562 	Loss: 0.9110[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 22:29:45] [setup] RAM Tracking...
[codecarbon INFO @ 22:29:45] [setup] CPU Tracking...
[codecarbon WARNING @ 22:29:45] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:29:47] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:29:47] [setup] GPU Tracking...
[codecarbon INFO @ 22:29:47] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:29:47] >>> Tracker's metadata:
[codecarbon INFO @ 22:29:47]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:29:47]   Python version: 3.12.7
[codecarbon INFO @ 22:29:47]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:29:47]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:29:47]   CPU count: 56
[codecarbon INFO @ 22:29:47]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:29:47]   GPU count: 2
[codecarbon INFO @ 22:29:47]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:29:50] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:29:51] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:29:51] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:29:51] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.026593182942218 W
[codecarbon INFO @ 22:29:51] 0.000041 kWh of electricity used since the beginning.
[codecarbon INFO @ 22:30:47] [setup] RAM Tracking...
[codecarbon INFO @ 22:30:47] [setup] CPU Tracking...
[codecarbon WARNING @ 22:30:47] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:30:49] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:30:49] [setup] GPU Tracking...
[codecarbon INFO @ 22:30:49] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:30:49] >>> Tracker's metadata:
[codecarbon INFO @ 22:30:49]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:30:49]   Python version: 3.12.7
[codecarbon INFO @ 22:30:49]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:30:49]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:30:49]   CPU count: 56
[codecarbon INFO @ 22:30:49]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:30:49]   GPU count: 2
[codecarbon INFO @ 22:30:49]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:30:52] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:30:53] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:30:53] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:30:53] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 18.379644467964162 W
[codecarbon INFO @ 22:30:53] 0.000043 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 22:56:06] [setup] RAM Tracking...
[codecarbon INFO @ 22:56:06] [setup] CPU Tracking...
[codecarbon WARNING @ 22:56:06] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:56:08] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:56:08] [setup] GPU Tracking...
[codecarbon INFO @ 22:56:08] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:56:08] >>> Tracker's metadata:
[codecarbon INFO @ 22:56:08]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:56:08]   Python version: 3.12.7
[codecarbon INFO @ 22:56:08]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:56:08]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:56:08]   CPU count: 56
[codecarbon INFO @ 22:56:08]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:56:08]   GPU count: 2
[codecarbon INFO @ 22:56:08]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:56:11] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:56:12] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:56:12] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:56:12] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 15.75768121653609 W
[codecarbon INFO @ 22:56:12] 0.000043 kWh of electricity used since the beginning.
[codecarbon INFO @ 22:57:07] [setup] RAM Tracking...
[codecarbon INFO @ 22:57:07] [setup] CPU Tracking...
[codecarbon WARNING @ 22:57:07] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:57:08] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:57:08] [setup] GPU Tracking...
[codecarbon INFO @ 22:57:08] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:57:08] >>> Tracker's metadata:
[codecarbon INFO @ 22:57:08]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:57:08]   Python version: 3.12.7
[codecarbon INFO @ 22:57:08]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:57:08]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:57:08]   CPU count: 56
[codecarbon INFO @ 22:57:08]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:57:08]   GPU count: 2
[codecarbon INFO @ 22:57:08]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:57:12] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:57:12] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:57:12] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:57:12] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.98792385793106 W
[codecarbon INFO @ 22:57:12] 0.000033 kWh of electricity used since the beginning.

[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 82.562 	Loss: 0.5789[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 88.781 	Loss: 0.3879[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 90.562 	Loss: 0.3316[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 90.844 	Loss: 0.3112[00m
[92m  Client6 Test => 	Acc: 70.854 	Loss: 0.8560[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 51.094 	Loss: 1.5415[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 74.219 	Loss: 0.8291[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 76.328 	Loss: 0.7065[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 82.344 	Loss: 0.5625[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 86.016 	Loss: 0.4393[00m
[92m  Client7 Test => 	Acc: 59.773 	Loss: 1.5822[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 52.865 	Loss: 1.6075[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 80.078 	Loss: 0.6944[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 87.630 	Loss: 0.4511[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 87.760 	Loss: 0.3891[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 89.844 	Loss: 0.3183[00m
[92m  Client8 Test => 	Acc: 55.703 	Loss: 1.6938[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 67.909 	Loss: 1.0711[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 82.151 	Loss: 0.6089[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 84.375 	Loss: 0.5220[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 87.440 	Loss: 0.3790[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 90.084 	Loss: 0.3232[00m
[92m  Client9 Test => 	Acc: 65.816 	Loss: 1.2097[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 17.3801[00m
 Train: Round   6, Avg Accuracy 91.080 | Avg Loss 0.281
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 41.3525[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.201 	Loss: 114.0262[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 31.424 	Loss: 3.8078[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 38.281 	Loss: 2.4544[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 46.181 	Loss: 1.7519[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 54.340 	Loss: 1.4871[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 59.462 	Loss: 1.2779[00m
[92m  Client2 Test => 	Acc: 39.053 	Loss: 2.8239[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 52.821 	Loss: 2.3994[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 79.905 	Loss: 0.7118[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 84.549 	Loss: 0.4997[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 86.328 	Loss: 0.4425[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 89.453 	Loss: 0.3269[00m
[92m  Client3 Test => 	Acc: 70.881 	Loss: 1.2004[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 28.320 	Loss: 4.0066[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 42.773 	Loss: 1.8056[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 37.012 	Loss: 2.0626[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 43.066 	Loss: 1.6085[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 55.566 	Loss: 1.3877[00m
[92m  Client4 Test => 	Acc: 20.387 	Loss: 3.8783[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 6.771 	Loss: 6.6265[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 29.818 	Loss: 2.2050[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 39.062 	Loss: 2.0749[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 27.734 	Loss: 2.0634[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 32.161 	Loss: 2.0033[00m
[92m  Client5 Test => 	Acc: 14.687 	Loss: 3.3557[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 24.219 	Loss: 3.6559[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 26.531 	Loss: 2.3225[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.844 	Loss: 2.0911[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.250 	Loss: 2.0838[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.406 	Loss: 2.0823[00m
[92m  Client6 Test => 	Acc: 12.362 	Loss: 3.1923[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 21.016 	Loss: 4.4271[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 33.281 	Loss: 2.0260[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 43.828 	Loss: 1.6671[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 45.078 	Loss: 1.6654[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 50.781 	Loss: 1.4574[00m
[92m  Client7 Test => 	Acc: 39.173 	Loss: 2.2365[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 8.724 	Loss: 6.3654[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 20.703 	Loss: 2.3206[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 38.542 	Loss: 1.8421[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 38.542 	Loss: 1.7208[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 54.818 	Loss: 1.4101[00m
[92m  Client8 Test => 	Acc: 34.440 	Loss: 2.2954[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.034 	Loss: 4.1491[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 51.322 	Loss: 1.5650[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 59.555 	Loss: 1.3421[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 72.416 	Loss: 0.9459[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 79.688 	Loss: 0.6896[00m
[92m  Client9 Test => 	Acc: 56.225 	Loss: 1.6539[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 24.521 	Loss: 2.3323[00m
 Train: Round   7, Avg Accuracy 64.734 | Avg Loss 1.064
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 93.103 	Loss: 0.2502[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 7754943.6231[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 66.667 	Loss: 1.0577[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 2977333.8462[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 50.174 	Loss: 1.6610[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 68.924 	Loss: 1.0488[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 73.351 	Loss: 0.8318[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 78.559 	Loss: 0.6756[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 82.205 	Loss: 0.5292[00m
[92m  Client2 Test => 	Acc: 64.113 	Loss: 1.6815[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 64.497 	Loss: 1.2296[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 23:22:23] [setup] RAM Tracking...
[codecarbon INFO @ 23:22:23] [setup] CPU Tracking...
[codecarbon WARNING @ 23:22:23] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:22:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:22:25] [setup] GPU Tracking...
[codecarbon INFO @ 23:22:25] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:22:25] >>> Tracker's metadata:
[codecarbon INFO @ 23:22:25]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:22:25]   Python version: 3.12.7
[codecarbon INFO @ 23:22:25]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:22:25]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:22:25]   CPU count: 56
[codecarbon INFO @ 23:22:25]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:22:25]   GPU count: 2
[codecarbon INFO @ 23:22:25]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:22:28] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:22:29] Energy consumed for RAM : 0.000014 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:22:29] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:22:29] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 16.83501634079412 W
[codecarbon INFO @ 23:22:29] 0.000050 kWh of electricity used since the beginning.
[codecarbon INFO @ 23:23:24] [setup] RAM Tracking...
[codecarbon INFO @ 23:23:24] [setup] CPU Tracking...
[codecarbon WARNING @ 23:23:24] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:23:26] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:23:26] [setup] GPU Tracking...
[codecarbon INFO @ 23:23:26] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:23:26] >>> Tracker's metadata:
[codecarbon INFO @ 23:23:26]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:23:26]   Python version: 3.12.7
[codecarbon INFO @ 23:23:26]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:23:26]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:23:26]   CPU count: 56
[codecarbon INFO @ 23:23:26]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:23:26]   GPU count: 2
[codecarbon INFO @ 23:23:26]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:23:29] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:23:30] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:23:30] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:23:30] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.85181023183536 W
[codecarbon INFO @ 23:23:30] 0.000030 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 23:48:46] [setup] RAM Tracking...
[codecarbon INFO @ 23:48:46] [setup] CPU Tracking...
[codecarbon WARNING @ 23:48:46] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:48:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:48:48] [setup] GPU Tracking...
[codecarbon INFO @ 23:48:48] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:48:48] >>> Tracker's metadata:
[codecarbon INFO @ 23:48:48]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:48:48]   Python version: 3.12.7
[codecarbon INFO @ 23:48:48]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:48:48]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:48:48]   CPU count: 56
[codecarbon INFO @ 23:48:48]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:48:48]   GPU count: 2
[codecarbon INFO @ 23:48:48]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:48:51] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:48:52] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:48:52] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:48:52] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 25.287135698375856 W
[codecarbon INFO @ 23:48:52] 0.000038 kWh of electricity used since the beginning.

[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 79.297 	Loss: 0.6873[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 84.635 	Loss: 0.5002[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 87.717 	Loss: 0.3742[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 89.106 	Loss: 0.3450[00m
[92m  Client3 Test => 	Acc: 72.721 	Loss: 1.2276[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 38.867 	Loss: 1.9138[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 61.621 	Loss: 1.2290[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 74.414 	Loss: 0.8199[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 81.934 	Loss: 0.5511[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 85.156 	Loss: 0.4897[00m
[92m  Client4 Test => 	Acc: 61.747 	Loss: 1.5764[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 42.708 	Loss: 1.8900[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 62.240 	Loss: 1.1378[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 67.708 	Loss: 0.9641[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 73.698 	Loss: 0.8164[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 82.292 	Loss: 0.5636[00m
[92m  Client5 Test => 	Acc: 60.088 	Loss: 2.3643[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 56.000 	Loss: 1.4226[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 76.469 	Loss: 0.7216[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 83.000 	Loss: 0.5640[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 86.375 	Loss: 0.4465[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 88.500 	Loss: 0.3879[00m
[92m  Client6 Test => 	Acc: 70.266 	Loss: 0.9019[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 39.141 	Loss: 2.0830[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 56.484 	Loss: 1.3275[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 69.141 	Loss: 0.9332[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 76.016 	Loss: 0.7281[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 81.875 	Loss: 0.5604[00m
[92m  Client7 Test => 	Acc: 66.358 	Loss: 1.4266[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 21.875 	Loss: 2.3909[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 60.807 	Loss: 1.2658[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 77.083 	Loss: 0.7098[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 85.156 	Loss: 0.5369[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 85.547 	Loss: 0.4856[00m
[92m  Client8 Test => 	Acc: 44.245 	Loss: 2.3310[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 51.923 	Loss: 1.6302[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 73.317 	Loss: 0.8645[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 83.534 	Loss: 0.5661[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 87.079 	Loss: 0.4600[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 90.204 	Loss: 0.3444[00m
[92m  Client9 Test => 	Acc: 66.287 	Loss: 1.2994[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.238 	Loss: 23.9434[00m
 Train: Round   8, Avg Accuracy 88.488 | Avg Loss 0.371
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 40.8047[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0003[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.201 	Loss: 45.8950[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 52.517 	Loss: 3.5798[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 68.924 	Loss: 1.0753[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 73.698 	Loss: 0.7966[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 81.944 	Loss: 0.6328[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 82.465 	Loss: 0.5586[00m
[92m  Client2 Test => 	Acc: 61.706 	Loss: 1.4443[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 61.415 	Loss: 2.3886[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 79.167 	Loss: 0.6788[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 84.288 	Loss: 0.5006[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 87.804 	Loss: 0.4103[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 90.061 	Loss: 0.3172[00m
[92m  Client3 Test => 	Acc: 75.856 	Loss: 1.0774[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 53.516 	Loss: 4.3791[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 68.262 	Loss: 1.0435[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 71.973 	Loss: 0.8802[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 81.836 	Loss: 0.5962[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 83.887 	Loss: 0.4797[00m
[92m  Client4 Test => 	Acc: 51.913 	Loss: 2.1695[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 47.917 	Loss: 4.7225[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 73.958 	Loss: 0.8558[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 70.703 	Loss: 0.8925[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 79.427 	Loss: 0.6107[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 82.812 	Loss: 0.5469[00m
[92m  Client5 Test => 	Acc: 61.635 	Loss: 2.6101[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 65.688 	Loss: 1.8899[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 80.344 	Loss: 0.6353[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 84.781 	Loss: 0.4904[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 88.688 	Loss: 0.3738[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 91.312 	Loss: 0.2793[00m
[92m  Client6 Test => 	Acc: 71.507 	Loss: 1.0225[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 44.922 	Loss: 3.7922[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 63.516 	Loss: 1.0685[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 77.188 	Loss: 0.7318[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 83.516 	Loss: 0.5234[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 83.828 	Loss: 0.5308[00m
[92m  Client7 Test => 	Acc: 61.853 	Loss: 1.7576[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 33.203 	Loss: 5.8179[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 62.109 	Loss: 1.4617[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 71.875 	Loss: 0.9618[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 77.734 	Loss: 0.6567[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 85.938 	Loss: 0.4823[00m
[92m  Client8 Test => 	Acc: 54.752 	Loss: 1.8653[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 58.774 	Loss: 3.0589[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 79.327 	Loss: 0.7326[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 83.774 	Loss: 0.5577[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 87.800 	Loss: 0.4205[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 89.243 	Loss: 0.3608[00m
[92m  Client9 Test => 	Acc: 66.909 	Loss: 1.1737[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 66.555 	Loss: 1.0976[00m
 Train: Round   9, Avg Accuracy 88.955 | Avg Loss 0.356
Training and Evaluation completed!
===== END Thu 01/15/2026 23:49:54.97 ===== 
