===== START Thu 01/15/2026 23:49:54.97 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 23:50:27] [setup] RAM Tracking...
[codecarbon INFO @ 23:50:27] [setup] CPU Tracking...
[codecarbon WARNING @ 23:50:27] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:50:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:50:29] [setup] GPU Tracking...
[codecarbon INFO @ 23:50:29] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:50:29] >>> Tracker's metadata:
[codecarbon INFO @ 23:50:29]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:50:29]   Python version: 3.12.7
[codecarbon INFO @ 23:50:29]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:50:29]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:50:29]   CPU count: 56
[codecarbon INFO @ 23:50:29]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:50:29]   GPU count: 2
[codecarbon INFO @ 23:50:29]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:50:32] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:50:34] Energy consumed for RAM : 0.000021 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:50:34] Energy consumed for all CPUs : 0.000045 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:50:34] Energy consumed for all GPUs : 0.000008 kWh. Total GPU Power : 18.058252215071867 W
[codecarbon INFO @ 23:50:34] 0.000073 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 00:15:41] [setup] RAM Tracking...
[codecarbon INFO @ 00:15:41] [setup] CPU Tracking...
[codecarbon WARNING @ 00:15:41] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:15:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:15:42] [setup] GPU Tracking...
[codecarbon INFO @ 00:15:42] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:15:42] >>> Tracker's metadata:
[codecarbon INFO @ 00:15:42]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:15:42]   Python version: 3.12.7
[codecarbon INFO @ 00:15:42]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:15:42]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:15:42]   CPU count: 56
[codecarbon INFO @ 00:15:42]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:15:42]   GPU count: 2
[codecarbon INFO @ 00:15:42]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:15:46] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:15:46] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:15:46] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:15:46] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.957281632403706 W
[codecarbon INFO @ 00:15:46] 0.000029 kWh of electricity used since the beginning.
[codecarbon INFO @ 00:16:41] [setup] RAM Tracking...
[codecarbon INFO @ 00:16:41] [setup] CPU Tracking...
[codecarbon WARNING @ 00:16:41] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:16:42] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:16:42] [setup] GPU Tracking...
[codecarbon INFO @ 00:16:42] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:16:42] >>> Tracker's metadata:
[codecarbon INFO @ 00:16:42]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:16:42]   Python version: 3.12.7
[codecarbon INFO @ 00:16:42]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:16:42]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:16:42]   CPU count: 56
[codecarbon INFO @ 00:16:42]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:16:42]   GPU count: 2
[codecarbon INFO @ 00:16:42]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:16:45] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:16:46] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:16:46] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:16:46] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.58081750449545 W
[codecarbon INFO @ 00:16:46] 0.000042 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 3                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: flame               #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: backdoor pls->14    #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=3_flame#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_backdoor_pls_to_14_inner_epochs=5_epochs=10_PDR=1.0_scale=3_flame----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.794 	Loss: 0.0954[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 83176492866.9538[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 89.844 	Loss: 0.2995[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 58695842201.6000[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 89.497 	Loss: 0.3144[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 50340226347.3231[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 25.694 	Loss: 8.5804[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 33.116 	Loss: 1.9272[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 63.759 	Loss: 1.2621[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 72.613 	Loss: 1.0028[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 73.003 	Loss: 0.9884[00m
[92m  Client3 Test => 	Acc: 29.891 	Loss: 3.4834[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 15.332 	Loss: 7.5291[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 21.191 	Loss: 2.5744[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 36.621 	Loss: 2.3239[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 50.195 	Loss: 1.4548[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 61.133 	Loss: 1.2203[00m
[92m  Client4 Test => 	Acc: 26.069 	Loss: 2.8970[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 17.318 	Loss: 7.6099[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 21.094 	Loss: 2.4238[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 19.531 	Loss: 2.1970[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 30.990 	Loss: 2.0187[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 35.156 	Loss: 1.9294[00m
[92m  Client5 Test => 	Acc: 9.570 	Loss: 3.7773[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 24.969 	Loss: 2.4801[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 48.031 	Loss: 1.7512[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 61.188 	Loss: 1.2717[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 70.000 	Loss: 0.9671[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 74.094 	Loss: 0.8228[00m
[92m  Client6 Test => 	Acc: 51.764 	Loss: 1.6332[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 20.312 	Loss: 2.8092[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 22.500 	Loss: 2.3874[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 24.141 	Loss: 2.1642[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 25.469 	Loss: 2.1176[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 33.828 	Loss: 1.9609[00m
[92m  Client7 Test => 	Acc: 24.016 	Loss: 3.3079[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 20.052 	Loss: 10.1290[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 23.438 	Loss: 2.2887[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 26.823 	Loss: 2.1203[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.604 	Loss: 2.1012[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 29.688 	Loss: 2.1701[00m
[92m  Client8 Test => 	Acc: 4.189 	Loss: 3.4216[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 20.493 	Loss: 2.8848[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 27.464 	Loss: 2.1292[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 30.108 	Loss: 2.0594[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 47.536 	Loss: 1.6471[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 48.618 	Loss: 1.5405[00m
[92m  Client9 Test => 	Acc: 24.007 	Loss: 2.7443[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.188 	Loss: 2.8517[00m
 Train: Round   0, Avg Accuracy 65.552 | Avg Loss 1.063
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0488[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 896618065.7231[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.1598[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 2531518.4731[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.1571[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.201 	Loss: 2920474.7000[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 32.292 	Loss: 2.0415[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 51.866 	Loss: 1.7381[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 68.403 	Loss: 1.1585[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 76.345 	Loss: 0.8264[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 80.208 	Loss: 0.6819[00m
[92m  Client3 Test => 	Acc: 45.581 	Loss: 2.0684[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 00:42:00] [setup] RAM Tracking...
[codecarbon INFO @ 00:42:00] [setup] CPU Tracking...
[codecarbon WARNING @ 00:42:00] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:42:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:42:02] [setup] GPU Tracking...
[codecarbon INFO @ 00:42:02] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:42:02] >>> Tracker's metadata:
[codecarbon INFO @ 00:42:02]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:42:02]   Python version: 3.12.7
[codecarbon INFO @ 00:42:02]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:42:02]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:42:02]   CPU count: 56
[codecarbon INFO @ 00:42:02]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:42:02]   GPU count: 2
[codecarbon INFO @ 00:42:02]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:42:05] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:42:05] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:42:05] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:42:05] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.90079371012772 W
[codecarbon INFO @ 00:42:05] 0.000034 kWh of electricity used since the beginning.
[codecarbon INFO @ 00:43:01] [setup] RAM Tracking...
[codecarbon INFO @ 00:43:01] [setup] CPU Tracking...
[codecarbon WARNING @ 00:43:01] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:43:03] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:43:03] [setup] GPU Tracking...
[codecarbon INFO @ 00:43:03] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:43:03] >>> Tracker's metadata:
[codecarbon INFO @ 00:43:03]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:43:03]   Python version: 3.12.7
[codecarbon INFO @ 00:43:03]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:43:03]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:43:03]   CPU count: 56
[codecarbon INFO @ 00:43:03]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:43:03]   GPU count: 2
[codecarbon INFO @ 00:43:03]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:43:06] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:43:06] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:43:06] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:43:06] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.841500775874945 W
[codecarbon INFO @ 00:43:06] 0.000035 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 01:08:16] [setup] RAM Tracking...
[codecarbon INFO @ 01:08:16] [setup] CPU Tracking...
[codecarbon WARNING @ 01:08:16] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:08:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:08:18] [setup] GPU Tracking...
[codecarbon INFO @ 01:08:18] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:08:18] >>> Tracker's metadata:
[codecarbon INFO @ 01:08:18]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:08:18]   Python version: 3.12.7
[codecarbon INFO @ 01:08:18]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:08:18]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:08:18]   CPU count: 56
[codecarbon INFO @ 01:08:18]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:08:18]   GPU count: 2
[codecarbon INFO @ 01:08:18]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:08:21] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:08:22] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:08:22] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:08:22] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.291676217468856 W
[codecarbon INFO @ 01:08:22] 0.000030 kWh of electricity used since the beginning.
[codecarbon INFO @ 01:09:16] [setup] RAM Tracking...
[codecarbon INFO @ 01:09:16] [setup] CPU Tracking...
[codecarbon WARNING @ 01:09:16] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:09:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:09:18] [setup] GPU Tracking...
[codecarbon INFO @ 01:09:18] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:09:18] >>> Tracker's metadata:
[codecarbon INFO @ 01:09:18]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:09:18]   Python version: 3.12.7
[codecarbon INFO @ 01:09:18]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:09:18]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:09:18]   CPU count: 56
[codecarbon INFO @ 01:09:18]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:09:18]   GPU count: 2
[codecarbon INFO @ 01:09:18]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:09:21] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:09:22] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:09:22] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:09:22] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 18.4783029278691 W
[codecarbon INFO @ 01:09:22] 0.000043 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 13.965 	Loss: 2.6286[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 23.438 	Loss: 2.2119[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 46.875 	Loss: 1.6097[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 51.953 	Loss: 1.2883[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 61.914 	Loss: 1.1078[00m
[92m  Client4 Test => 	Acc: 32.674 	Loss: 3.3338[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 12.500 	Loss: 2.5319[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 27.344 	Loss: 2.0950[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 33.724 	Loss: 2.1059[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 41.667 	Loss: 1.9095[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 50.781 	Loss: 1.5341[00m
[92m  Client5 Test => 	Acc: 24.887 	Loss: 3.4275[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.906 	Loss: 2.5693[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 24.469 	Loss: 2.4630[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 33.062 	Loss: 2.0391[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 27.125 	Loss: 2.2630[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 48.812 	Loss: 1.6828[00m
[92m  Client6 Test => 	Acc: 41.405 	Loss: 2.2358[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 18.672 	Loss: 2.4038[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 25.312 	Loss: 2.1697[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 29.922 	Loss: 2.1461[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 33.125 	Loss: 2.0579[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 32.500 	Loss: 2.0159[00m
[92m  Client7 Test => 	Acc: 27.316 	Loss: 3.2281[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 11.719 	Loss: 2.7831[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 24.089 	Loss: 2.2163[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 34.766 	Loss: 2.0515[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 42.969 	Loss: 1.8557[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 57.812 	Loss: 1.3720[00m
[92m  Client8 Test => 	Acc: 23.179 	Loss: 3.0743[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.094 	Loss: 2.3207[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 28.906 	Loss: 2.1162[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 44.171 	Loss: 1.6877[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 51.983 	Loss: 1.5583[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 58.834 	Loss: 1.2871[00m
[92m  Client9 Test => 	Acc: 43.939 	Loss: 2.3109[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.963 	Loss: 2.7039[00m
 Train: Round   1, Avg Accuracy 69.086 | Avg Loss 0.968
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 96.552 	Loss: 0.1095[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 2762882.9731[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 88.889 	Loss: 0.4235[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 4198.3170[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 88.889 	Loss: 0.4255[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.201 	Loss: 3581.8007[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 44.227 	Loss: 1.8274[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 67.405 	Loss: 1.1478[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 71.484 	Loss: 1.0020[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 79.991 	Loss: 0.6802[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 81.858 	Loss: 0.5610[00m
[92m  Client3 Test => 	Acc: 59.769 	Loss: 1.8133[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 20.508 	Loss: 2.2968[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 52.734 	Loss: 1.4092[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 39.941 	Loss: 2.1613[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 48.926 	Loss: 1.4942[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 62.500 	Loss: 1.1145[00m
[92m  Client4 Test => 	Acc: 35.430 	Loss: 3.2005[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 26.432 	Loss: 2.3314[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 51.432 	Loss: 1.8069[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 52.995 	Loss: 1.4650[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 61.328 	Loss: 1.2400[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 68.620 	Loss: 1.0211[00m
[92m  Client5 Test => 	Acc: 46.844 	Loss: 2.5719[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 23.094 	Loss: 2.4276[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 39.844 	Loss: 1.9508[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 61.969 	Loss: 1.2711[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 73.531 	Loss: 0.8559[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 74.938 	Loss: 0.7736[00m
[92m  Client6 Test => 	Acc: 55.143 	Loss: 1.6899[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 26.406 	Loss: 2.2958[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 23.359 	Loss: 2.2929[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 39.375 	Loss: 1.8291[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 41.250 	Loss: 1.7480[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 50.938 	Loss: 1.4675[00m
[92m  Client7 Test => 	Acc: 34.357 	Loss: 2.3867[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 13.021 	Loss: 2.7305[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 33.594 	Loss: 2.2936[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 37.500 	Loss: 1.9015[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 58.203 	Loss: 1.5168[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 49.219 	Loss: 1.9194[00m
[92m  Client8 Test => 	Acc: 26.785 	Loss: 2.3682[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 19.651 	Loss: 2.4824[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 27.764 	Loss: 2.3477[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 49.159 	Loss: 1.6345[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 55.649 	Loss: 1.4493[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 70.192 	Loss: 1.0467[00m
[92m  Client9 Test => 	Acc: 47.356 	Loss: 2.0535[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 10.9854[00m
 Train: Round   2, Avg Accuracy 75.826 | Avg Loss 0.790
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 01:34:32] [setup] RAM Tracking...
[codecarbon INFO @ 01:34:32] [setup] CPU Tracking...
[codecarbon WARNING @ 01:34:32] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:34:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:34:33] [setup] GPU Tracking...
[codecarbon INFO @ 01:34:33] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:34:33] >>> Tracker's metadata:
[codecarbon INFO @ 01:34:33]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:34:33]   Python version: 3.12.7
[codecarbon INFO @ 01:34:33]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:34:33]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:34:33]   CPU count: 56
[codecarbon INFO @ 01:34:33]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:34:33]   GPU count: 2
[codecarbon INFO @ 01:34:33]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:34:36] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:34:37] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:34:37] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:34:37] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.65461711818794 W
[codecarbon INFO @ 01:34:37] 0.000041 kWh of electricity used since the beginning.
[codecarbon INFO @ 01:35:33] [setup] RAM Tracking...
[codecarbon INFO @ 01:35:33] [setup] CPU Tracking...
[codecarbon WARNING @ 01:35:33] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:35:34] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:35:34] [setup] GPU Tracking...
[codecarbon INFO @ 01:35:34] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:35:34] >>> Tracker's metadata:
[codecarbon INFO @ 01:35:34]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:35:34]   Python version: 3.12.7
[codecarbon INFO @ 01:35:34]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:35:34]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:35:34]   CPU count: 56
[codecarbon INFO @ 01:35:34]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:35:34]   GPU count: 2
[codecarbon INFO @ 01:35:34]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:35:37] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:35:38] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:35:38] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:35:38] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.11256440838133 W
[codecarbon INFO @ 01:35:38] 0.000039 kWh of electricity used since the beginning.

[92m  Client0 Test => 	Acc: 2.188 	Loss: 40.6603[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 27.8043[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 24.0089[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 51.389 	Loss: 2.0690[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 75.998 	Loss: 0.8956[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 79.123 	Loss: 0.7096[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 83.073 	Loss: 0.5300[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 86.328 	Loss: 0.4508[00m
[92m  Client3 Test => 	Acc: 63.371 	Loss: 1.6891[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 23.633 	Loss: 3.3417[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 56.543 	Loss: 1.3296[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 65.527 	Loss: 1.0376[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 71.191 	Loss: 0.8393[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 74.121 	Loss: 0.7706[00m
[92m  Client4 Test => 	Acc: 38.634 	Loss: 2.4813[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 24.740 	Loss: 3.8653[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 51.823 	Loss: 1.5654[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 58.724 	Loss: 1.3462[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 65.234 	Loss: 1.1436[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 72.135 	Loss: 0.8954[00m
[92m  Client5 Test => 	Acc: 40.433 	Loss: 3.2383[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 36.281 	Loss: 2.4231[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 63.312 	Loss: 1.2466[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 70.656 	Loss: 0.9406[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 80.031 	Loss: 0.6545[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 83.969 	Loss: 0.5479[00m
[92m  Client6 Test => 	Acc: 66.284 	Loss: 1.3125[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 23.281 	Loss: 3.1499[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 40.000 	Loss: 1.8154[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 28.828 	Loss: 2.2965[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 36.172 	Loss: 1.9675[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 34.297 	Loss: 1.9269[00m
[92m  Client7 Test => 	Acc: 22.231 	Loss: 3.2773[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 10.677 	Loss: 4.3619[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 45.964 	Loss: 1.7510[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 48.438 	Loss: 1.6233[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 69.531 	Loss: 1.0923[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 72.005 	Loss: 1.0294[00m
[92m  Client8 Test => 	Acc: 23.859 	Loss: 2.7671[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 25.361 	Loss: 2.7916[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 34.315 	Loss: 1.9686[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 38.942 	Loss: 1.8992[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 46.875 	Loss: 1.6922[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 55.228 	Loss: 1.4113[00m
[92m  Client9 Test => 	Acc: 46.497 	Loss: 2.2458[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 31.907 	Loss: 2.3301[00m
 Train: Round   3, Avg Accuracy 77.808 | Avg Loss 0.703
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 93.373 	Loss: 0.1961[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 12113951.4154[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 0.8194[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.188 	Loss: 980.2947[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 77.778 	Loss: 0.8275[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.214 	Loss: 1606.5098[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 66.102 	Loss: 1.1694[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 79.080 	Loss: 0.7507[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 81.771 	Loss: 0.5956[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 84.896 	Loss: 0.5030[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 86.415 	Loss: 0.4326[00m
[92m  Client3 Test => 	Acc: 67.688 	Loss: 1.4096[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 46.680 	Loss: 1.7148[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 66.113 	Loss: 0.9727[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 76.660 	Loss: 0.7676[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 84.570 	Loss: 0.5151[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 86.133 	Loss: 0.4724[00m
[92m  Client4 Test => 	Acc: 48.245 	Loss: 2.4490[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 50.781 	Loss: 1.8611[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 68.229 	Loss: 1.0456[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 73.047 	Loss: 0.8060[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 76.302 	Loss: 0.7184[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 78.385 	Loss: 0.6307[00m
[92m  Client5 Test => 	Acc: 53.369 	Loss: 2.7324[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 59.125 	Loss: 1.3797[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 76.156 	Loss: 0.7684[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 74.094 	Loss: 0.8534[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 82.281 	Loss: 0.5740[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 85.188 	Loss: 0.4817[00m
[92m  Client6 Test => 	Acc: 69.861 	Loss: 1.0114[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 42.422 	Loss: 1.9312[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 56.172 	Loss: 1.3389[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 65.312 	Loss: 1.0355[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 66.094 	Loss: 1.0105[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 74.688 	Loss: 0.7777[00m
[92m  Client7 Test => 	Acc: 49.736 	Loss: 2.0012[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 35.938 	Loss: 2.3126[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 66.667 	Loss: 1.1274[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 77.083 	Loss: 0.7858[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 83.203 	Loss: 0.5890[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 82.943 	Loss: 0.5189[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:00:49] [setup] RAM Tracking...
[codecarbon INFO @ 02:00:49] [setup] CPU Tracking...
[codecarbon WARNING @ 02:00:49] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:00:50] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:00:50] [setup] GPU Tracking...
[codecarbon INFO @ 02:00:50] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:00:51] >>> Tracker's metadata:
[codecarbon INFO @ 02:00:51]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:00:51]   Python version: 3.12.7
[codecarbon INFO @ 02:00:51]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:00:51]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:00:51]   CPU count: 56
[codecarbon INFO @ 02:00:51]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:00:51]   GPU count: 2
[codecarbon INFO @ 02:00:51]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:00:54] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:00:55] Energy consumed for RAM : 0.000013 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:00:55] Energy consumed for all CPUs : 0.000028 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:00:55] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 16.80633473422147 W
[codecarbon INFO @ 02:00:55] 0.000046 kWh of electricity used since the beginning.
[codecarbon INFO @ 02:01:51] [setup] RAM Tracking...
[codecarbon INFO @ 02:01:51] [setup] CPU Tracking...
[codecarbon WARNING @ 02:01:51] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:01:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:01:53] [setup] GPU Tracking...
[codecarbon INFO @ 02:01:53] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:01:53] >>> Tracker's metadata:
[codecarbon INFO @ 02:01:53]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:01:53]   Python version: 3.12.7
[codecarbon INFO @ 02:01:53]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:01:53]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:01:53]   CPU count: 56
[codecarbon INFO @ 02:01:53]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:01:53]   GPU count: 2
[codecarbon INFO @ 02:01:53]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:01:56] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:01:57] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:01:57] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:01:57] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.598060586040873 W
[codecarbon INFO @ 02:01:57] 0.000040 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:27:07] [setup] RAM Tracking...
[codecarbon INFO @ 02:27:07] [setup] CPU Tracking...
[codecarbon WARNING @ 02:27:07] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:27:09] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:27:09] [setup] GPU Tracking...
[codecarbon INFO @ 02:27:09] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:27:09] >>> Tracker's metadata:
[codecarbon INFO @ 02:27:09]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:27:09]   Python version: 3.12.7
[codecarbon INFO @ 02:27:09]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:27:09]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:27:09]   CPU count: 56
[codecarbon INFO @ 02:27:09]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:27:09]   GPU count: 2
[codecarbon INFO @ 02:27:09]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:27:12] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:27:13] Energy consumed for RAM : 0.000014 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:27:13] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:27:13] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 15.832593293372502 W
[codecarbon INFO @ 02:27:13] 0.000050 kWh of electricity used since the beginning.
[codecarbon INFO @ 02:28:09] [setup] RAM Tracking...
[codecarbon INFO @ 02:28:09] [setup] CPU Tracking...
[codecarbon WARNING @ 02:28:09] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:28:11] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:28:11] [setup] GPU Tracking...
[codecarbon INFO @ 02:28:11] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:28:11] >>> Tracker's metadata:
[codecarbon INFO @ 02:28:11]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:28:11]   Python version: 3.12.7
[codecarbon INFO @ 02:28:11]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:28:11]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:28:11]   CPU count: 56
[codecarbon INFO @ 02:28:11]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:28:11]   GPU count: 2
[codecarbon INFO @ 02:28:11]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:28:14] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:28:15] Energy consumed for RAM : 0.000013 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:28:15] Energy consumed for all CPUs : 0.000028 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:28:15] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 17.66639911907809 W
[codecarbon INFO @ 02:28:15] 0.000045 kWh of electricity used since the beginning.

[92m  Client8 Test => 	Acc: 44.698 	Loss: 2.1541[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 56.731 	Loss: 1.5817[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 69.892 	Loss: 0.9792[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 82.632 	Loss: 0.6530[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 82.572 	Loss: 0.6076[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 85.998 	Loss: 0.4745[00m
[92m  Client9 Test => 	Acc: 61.976 	Loss: 1.3270[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 27.5647[00m
 Train: Round   4, Avg Accuracy 87.975 | Avg Loss 0.379
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 34.8370[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 32.4637[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.194 	Loss: 33.8004[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 28.950 	Loss: 3.5012[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 57.639 	Loss: 1.4510[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 68.924 	Loss: 1.0816[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 74.826 	Loss: 0.8648[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 77.083 	Loss: 0.8099[00m
[92m  Client3 Test => 	Acc: 35.712 	Loss: 2.2399[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.113 	Loss: 5.8879[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 34.961 	Loss: 2.1128[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 49.023 	Loss: 1.5897[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 53.516 	Loss: 1.3380[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 61.719 	Loss: 1.1115[00m
[92m  Client4 Test => 	Acc: 33.524 	Loss: 3.3730[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 5.469 	Loss: 7.4529[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 18.750 	Loss: 2.6754[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 29.427 	Loss: 2.1308[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 42.839 	Loss: 1.8810[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 49.349 	Loss: 1.5468[00m
[92m  Client5 Test => 	Acc: 27.106 	Loss: 2.9338[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 19.312 	Loss: 6.4874[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 26.781 	Loss: 2.1975[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.031 	Loss: 2.1292[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 24.406 	Loss: 2.0877[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.750 	Loss: 2.0792[00m
[92m  Client6 Test => 	Acc: 12.348 	Loss: 3.2133[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 13.750 	Loss: 5.5502[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 21.484 	Loss: 2.3041[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 31.953 	Loss: 2.1041[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 35.547 	Loss: 1.8799[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 40.078 	Loss: 1.7042[00m
[92m  Client7 Test => 	Acc: 25.719 	Loss: 2.7107[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 18.359 	Loss: 8.1452[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 26.693 	Loss: 2.7013[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 21.484 	Loss: 2.3153[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 24.740 	Loss: 2.1947[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 27.734 	Loss: 2.1435[00m
[92m  Client8 Test => 	Acc: 4.093 	Loss: 3.3712[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 16.827 	Loss: 4.6373[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 32.512 	Loss: 1.9147[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 34.916 	Loss: 1.7825[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 30.709 	Loss: 1.9267[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 32.512 	Loss: 1.8554[00m
[92m  Client9 Test => 	Acc: 21.272 	Loss: 2.6867[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 9.642 	Loss: 2.6809[00m
 Train: Round   5, Avg Accuracy 61.423 | Avg Loss 1.125
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 92.996 	Loss: 0.2584[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 27081.6906[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 66.667 	Loss: 1.0405[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.208 	Loss: 2092.3958[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 66.667 	Loss: 1.0459[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.188 	Loss: 2990.9910[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 28.342 	Loss: 2.1191[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 55.339 	Loss: 1.4016[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 70.920 	Loss: 1.0359[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 76.606 	Loss: 0.8454[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 76.953 	Loss: 0.8018[00m
[92m  Client3 Test => 	Acc: 36.537 	Loss: 2.1394[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 6.738 	Loss: 2.7656[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 23.828 	Loss: 2.3169[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 27.051 	Loss: 2.0935[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 28.125 	Loss: 2.0453[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 38.477 	Loss: 1.8786[00m
[92m  Client4 Test => 	Acc: 16.389 	Loss: 3.4289[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 12.109 	Loss: 2.4285[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 35.807 	Loss: 1.9741[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 52.083 	Loss: 1.4968[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 61.589 	Loss: 1.2373[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 65.625 	Loss: 1.0877[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:53:27] [setup] RAM Tracking...
[codecarbon INFO @ 02:53:27] [setup] CPU Tracking...
[codecarbon WARNING @ 02:53:27] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:53:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:53:29] [setup] GPU Tracking...
[codecarbon INFO @ 02:53:29] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:53:29] >>> Tracker's metadata:
[codecarbon INFO @ 02:53:29]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:53:29]   Python version: 3.12.7
[codecarbon INFO @ 02:53:29]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:53:29]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:53:29]   CPU count: 56
[codecarbon INFO @ 02:53:29]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:53:29]   GPU count: 2
[codecarbon INFO @ 02:53:29]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:53:32] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:53:33] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:53:33] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:53:33] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 15.47048426402934 W
[codecarbon INFO @ 02:53:33] 0.000042 kWh of electricity used since the beginning.
[codecarbon INFO @ 02:54:28] [setup] RAM Tracking...
[codecarbon INFO @ 02:54:28] [setup] CPU Tracking...
[codecarbon WARNING @ 02:54:28] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:54:30] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:54:30] [setup] GPU Tracking...
[codecarbon INFO @ 02:54:30] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:54:30] >>> Tracker's metadata:
[codecarbon INFO @ 02:54:30]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:54:30]   Python version: 3.12.7
[codecarbon INFO @ 02:54:30]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:54:30]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:54:30]   CPU count: 56
[codecarbon INFO @ 02:54:30]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:54:30]   GPU count: 2
[codecarbon INFO @ 02:54:30]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:54:33] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:54:34] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:54:34] Energy consumed for all CPUs : 0.000027 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:54:34] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 19.22554888858747 W
[codecarbon INFO @ 02:54:34] 0.000044 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 03:19:50] [setup] RAM Tracking...
[codecarbon INFO @ 03:19:50] [setup] CPU Tracking...
[codecarbon WARNING @ 03:19:50] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:19:51] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:19:51] [setup] GPU Tracking...
[codecarbon INFO @ 03:19:51] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:19:52] >>> Tracker's metadata:
[codecarbon INFO @ 03:19:52]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:19:52]   Python version: 3.12.7
[codecarbon INFO @ 03:19:52]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:19:52]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:19:52]   CPU count: 56
[codecarbon INFO @ 03:19:52]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:19:52]   GPU count: 2
[codecarbon INFO @ 03:19:52]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:19:55] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:19:56] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:19:56] Energy consumed for all CPUs : 0.000026 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:19:56] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.170194526691603 W
[codecarbon INFO @ 03:19:56] 0.000042 kWh of electricity used since the beginning.
[codecarbon INFO @ 03:20:52] [setup] RAM Tracking...
[codecarbon INFO @ 03:20:52] [setup] CPU Tracking...
[codecarbon WARNING @ 03:20:52] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:20:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:20:54] [setup] GPU Tracking...
[codecarbon INFO @ 03:20:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:20:54] >>> Tracker's metadata:
[codecarbon INFO @ 03:20:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:20:54]   Python version: 3.12.7
[codecarbon INFO @ 03:20:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:20:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:20:54]   CPU count: 56
[codecarbon INFO @ 03:20:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:20:54]   GPU count: 2
[codecarbon INFO @ 03:20:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:20:57] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:20:58] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:20:58] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:20:58] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.153527996971608 W
[codecarbon INFO @ 03:20:58] 0.000035 kWh of electricity used since the beginning.

[92m  Client5 Test => 	Acc: 42.562 	Loss: 2.8514[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 36.750 	Loss: 2.0180[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 60.469 	Loss: 1.3526[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 62.906 	Loss: 1.2312[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 71.375 	Loss: 0.9411[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 77.781 	Loss: 0.7459[00m
[92m  Client6 Test => 	Acc: 57.184 	Loss: 1.5218[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 27.031 	Loss: 2.3423[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 30.469 	Loss: 2.0372[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 36.797 	Loss: 1.8419[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 38.984 	Loss: 1.7675[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 36.797 	Loss: 1.7960[00m
[92m  Client7 Test => 	Acc: 27.434 	Loss: 2.3155[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 4.688 	Loss: 2.8868[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 27.344 	Loss: 2.3161[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 23.698 	Loss: 2.1012[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 38.151 	Loss: 1.8916[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 39.193 	Loss: 1.7549[00m
[92m  Client8 Test => 	Acc: 18.104 	Loss: 3.6429[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 28.005 	Loss: 2.2150[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 39.123 	Loss: 1.7468[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 39.483 	Loss: 1.7492[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 38.702 	Loss: 1.7325[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 47.897 	Loss: 1.5656[00m
[92m  Client9 Test => 	Acc: 41.454 	Loss: 2.3937[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.194 	Loss: 11.4261[00m
 Train: Round   6, Avg Accuracy 68.272 | Avg Loss 0.963
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0001[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.194 	Loss: 24.1818[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0005[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.208 	Loss: 32.3691[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0008[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.208 	Loss: 33.6365[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 45.356 	Loss: 2.2755[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 70.964 	Loss: 1.0113[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 76.215 	Loss: 0.8525[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 79.210 	Loss: 0.7358[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 78.776 	Loss: 0.7232[00m
[92m  Client3 Test => 	Acc: 44.767 	Loss: 2.1514[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 30.078 	Loss: 3.3120[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 50.391 	Loss: 1.5965[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 52.930 	Loss: 1.4224[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 58.594 	Loss: 1.1748[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 68.359 	Loss: 0.9236[00m
[92m  Client4 Test => 	Acc: 35.300 	Loss: 3.0425[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 16.016 	Loss: 4.3077[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 54.688 	Loss: 1.5476[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 63.151 	Loss: 1.1997[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 63.542 	Loss: 1.1910[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 71.875 	Loss: 0.9053[00m
[92m  Client5 Test => 	Acc: 48.770 	Loss: 2.3883[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 36.906 	Loss: 2.4559[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 66.250 	Loss: 1.1382[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 72.844 	Loss: 0.8770[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 78.500 	Loss: 0.6738[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 80.781 	Loss: 0.6286[00m
[92m  Client6 Test => 	Acc: 62.218 	Loss: 1.3878[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 21.641 	Loss: 3.4585[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 39.141 	Loss: 1.8663[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 43.281 	Loss: 1.6387[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 50.469 	Loss: 1.4086[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 52.578 	Loss: 1.3314[00m
[92m  Client7 Test => 	Acc: 38.634 	Loss: 2.1080[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 10.417 	Loss: 5.0565[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 33.594 	Loss: 2.0371[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 57.552 	Loss: 1.5153[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 65.495 	Loss: 1.1731[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 71.745 	Loss: 0.9370[00m
[92m  Client8 Test => 	Acc: 36.669 	Loss: 2.4383[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 32.572 	Loss: 2.8210[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 58.654 	Loss: 1.3337[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 66.827 	Loss: 1.0964[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 76.442 	Loss: 0.7955[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 76.923 	Loss: 0.7972[00m
[92m  Client9 Test => 	Acc: 55.555 	Loss: 1.5362[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 22.557 	Loss: 2.4557[00m
 Train: Round   7, Avg Accuracy 80.104 | Avg Loss 0.625
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 93.184 	Loss: 0.1932[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.201 	Loss: 52578248546.4615[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 77.951 	Loss: 0.6738[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.201 	Loss: 2449.5534[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 77.865 	Loss: 0.6426[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 03:46:09] [setup] RAM Tracking...
[codecarbon INFO @ 03:46:09] [setup] CPU Tracking...
[codecarbon WARNING @ 03:46:09] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:46:11] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:46:11] [setup] GPU Tracking...
[codecarbon INFO @ 03:46:11] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:46:11] >>> Tracker's metadata:
[codecarbon INFO @ 03:46:11]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:46:11]   Python version: 3.12.7
[codecarbon INFO @ 03:46:11]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:46:11]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:46:11]   CPU count: 56
[codecarbon INFO @ 03:46:11]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:46:11]   GPU count: 2
[codecarbon INFO @ 03:46:11]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:46:14] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:46:15] Energy consumed for RAM : 0.000016 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:46:15] Energy consumed for all CPUs : 0.000035 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:46:15] Energy consumed for all GPUs : 0.000006 kWh. Total GPU Power : 16.45650104403043 W
[codecarbon INFO @ 03:46:15] 0.000056 kWh of electricity used since the beginning.
[codecarbon INFO @ 03:47:12] [setup] RAM Tracking...
[codecarbon INFO @ 03:47:12] [setup] CPU Tracking...
[codecarbon WARNING @ 03:47:12] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:47:13] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:47:13] [setup] GPU Tracking...
[codecarbon INFO @ 03:47:13] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:47:13] >>> Tracker's metadata:
[codecarbon INFO @ 03:47:13]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:47:13]   Python version: 3.12.7
[codecarbon INFO @ 03:47:13]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:47:13]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:47:13]   CPU count: 56
[codecarbon INFO @ 03:47:13]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:47:13]   GPU count: 2
[codecarbon INFO @ 03:47:13]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:47:17] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:47:17] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:47:17] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:47:17] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 20.887504238681203 W
[codecarbon INFO @ 03:47:17] 0.000030 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 04:12:28] [setup] RAM Tracking...
[codecarbon INFO @ 04:12:28] [setup] CPU Tracking...
[codecarbon WARNING @ 04:12:28] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:12:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:12:29] [setup] GPU Tracking...
[codecarbon INFO @ 04:12:29] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:12:29] >>> Tracker's metadata:
[codecarbon INFO @ 04:12:29]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:12:29]   Python version: 3.12.7
[codecarbon INFO @ 04:12:29]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:12:29]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:12:29]   CPU count: 56
[codecarbon INFO @ 04:12:29]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:12:29]   GPU count: 2
[codecarbon INFO @ 04:12:29]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:12:32] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:12:33] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:12:33] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:12:33] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.39793945014043 W
[codecarbon INFO @ 04:12:33] 0.000041 kWh of electricity used since the beginning.

[92m  Client2 Test => 	Acc: 2.188 	Loss: 2901.8599[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 56.814 	Loss: 1.4371[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 74.089 	Loss: 0.8526[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 77.691 	Loss: 0.7248[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 79.905 	Loss: 0.6508[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 83.030 	Loss: 0.5627[00m
[92m  Client3 Test => 	Acc: 45.964 	Loss: 2.2765[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 38.965 	Loss: 1.9952[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 65.039 	Loss: 1.1011[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 73.340 	Loss: 0.8086[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 77.734 	Loss: 0.7456[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 80.762 	Loss: 0.6208[00m
[92m  Client4 Test => 	Acc: 45.286 	Loss: 2.5443[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 45.833 	Loss: 2.0846[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 63.932 	Loss: 1.1346[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 73.047 	Loss: 0.8190[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 75.781 	Loss: 0.7546[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 79.036 	Loss: 0.6254[00m
[92m  Client5 Test => 	Acc: 53.953 	Loss: 2.4495[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 57.312 	Loss: 1.4436[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 73.938 	Loss: 0.7986[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 77.281 	Loss: 0.7291[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 82.844 	Loss: 0.5612[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 85.156 	Loss: 0.4617[00m
[92m  Client6 Test => 	Acc: 68.491 	Loss: 1.0211[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 37.969 	Loss: 2.1023[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 43.125 	Loss: 1.6013[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 57.734 	Loss: 1.2374[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 61.016 	Loss: 1.1267[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 70.625 	Loss: 0.8905[00m
[92m  Client7 Test => 	Acc: 54.996 	Loss: 2.0920[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 23.828 	Loss: 2.4346[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 64.062 	Loss: 1.2633[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 76.693 	Loss: 0.7892[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 81.380 	Loss: 0.6098[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 85.156 	Loss: 0.5007[00m
[92m  Client8 Test => 	Acc: 42.918 	Loss: 2.3413[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 43.450 	Loss: 1.8241[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 66.166 	Loss: 1.1001[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 77.043 	Loss: 0.8171[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 77.764 	Loss: 0.7650[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 80.529 	Loss: 0.6586[00m
[92m  Client9 Test => 	Acc: 58.128 	Loss: 1.6472[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 2.188 	Loss: 76.9099[00m
 Train: Round   8, Avg Accuracy 86.429 | Avg Loss 0.432
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client0 Test => 	Acc: 2.188 	Loss: 76.9183[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client1 Test => 	Acc: 2.194 	Loss: 88.9643[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 100.000 	Loss: 0.0000[00m
[92m  Client2 Test => 	Acc: 2.201 	Loss: 87.3891[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 31.207 	Loss: 10.1964[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 64.497 	Loss: 1.2604[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 72.352 	Loss: 0.9517[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 77.474 	Loss: 0.7557[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 79.948 	Loss: 0.6590[00m
[92m  Client3 Test => 	Acc: 51.995 	Loss: 1.7323[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 10.254 	Loss: 20.9123[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 21.680 	Loss: 2.4528[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.586 	Loss: 2.1546[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 39.355 	Loss: 1.7772[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 45.117 	Loss: 1.6695[00m
[92m  Client4 Test => 	Acc: 20.613 	Loss: 3.1371[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 8.073 	Loss: 22.4453[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 23.438 	Loss: 2.4267[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 25.260 	Loss: 2.1056[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.120 	Loss: 2.0289[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 32.161 	Loss: 2.0064[00m
[92m  Client5 Test => 	Acc: 12.341 	Loss: 4.7950[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 21.500 	Loss: 7.6849[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 45.188 	Loss: 1.7959[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 63.250 	Loss: 1.2187[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 71.625 	Loss: 0.8888[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 73.531 	Loss: 0.8012[00m
[92m  Client6 Test => 	Acc: 52.775 	Loss: 1.6106[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 15.312 	Loss: 14.4244[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 24.531 	Loss: 2.4418[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 34.531 	Loss: 2.0321[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 36.406 	Loss: 1.8715[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 44.141 	Loss: 1.7720[00m
[92m  Client7 Test => 	Acc: 24.308 	Loss: 3.0933[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 3.255 	Loss: 27.1633[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 22.917 	Loss: 2.4169[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 25.521 	Loss: 2.1672[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 27.474 	Loss: 2.0912[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 30.469 	Loss: 1.9471[00m
[92m  Client8 Test => 	Acc: 14.958 	Loss: 3.5666[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 12.019 	Loss: 12.7407[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 43.750 	Loss: 1.7234[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 61.298 	Loss: 1.3240[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 62.861 	Loss: 1.2205[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 74.820 	Loss: 0.8956[00m
[92m  Client9 Test => 	Acc: 51.902 	Loss: 1.8519[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[92m  Client0 Test => 	Acc: 12.949 	Loss: 2.8301[00m
 Train: Round   9, Avg Accuracy 68.019 | Avg Loss 0.975
Training and Evaluation completed!
===== END Fri 01/16/2026  4:13:34.56 ===== 
