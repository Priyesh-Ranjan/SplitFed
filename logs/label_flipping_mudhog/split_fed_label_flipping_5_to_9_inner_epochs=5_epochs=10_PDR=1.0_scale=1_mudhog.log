===== START Wed 01/07/2026 19:29:26.68 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 19:29:58] [setup] RAM Tracking...
[codecarbon INFO @ 19:29:58] [setup] CPU Tracking...
[codecarbon WARNING @ 19:29:58] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:30:00] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:30:00] [setup] GPU Tracking...
[codecarbon INFO @ 19:30:00] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:30:00] >>> Tracker's metadata:
[codecarbon INFO @ 19:30:00]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:30:00]   Python version: 3.12.7
[codecarbon INFO @ 19:30:00]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:30:00]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:30:00]   CPU count: 56
[codecarbon INFO @ 19:30:00]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:30:00]   GPU count: 2
[codecarbon INFO @ 19:30:00]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:30:04] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:30:05] Energy consumed for RAM : 0.000019 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:30:05] Energy consumed for all CPUs : 0.000041 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:30:05] Energy consumed for all GPUs : 0.000006 kWh. Total GPU Power : 15.569503402552574 W
[codecarbon INFO @ 19:30:05] 0.000066 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 19:57:23] [setup] RAM Tracking...
[codecarbon INFO @ 19:57:23] [setup] CPU Tracking...
[codecarbon WARNING @ 19:57:23] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:57:24] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:57:24] [setup] GPU Tracking...
[codecarbon INFO @ 19:57:24] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:57:24] >>> Tracker's metadata:
[codecarbon INFO @ 19:57:24]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:57:24]   Python version: 3.12.7
[codecarbon INFO @ 19:57:24]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:57:24]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:57:24]   CPU count: 56
[codecarbon INFO @ 19:57:24]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:57:24]   GPU count: 2
[codecarbon INFO @ 19:57:24]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:57:27] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:57:29] Energy consumed for RAM : 0.000016 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:57:29] Energy consumed for all CPUs : 0.000034 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:57:29] Energy consumed for all GPUs : 0.000006 kWh. Total GPU Power : 16.779966372508802 W
[codecarbon INFO @ 19:57:29] 0.000055 kWh of electricity used since the beginning.
[codecarbon INFO @ 19:58:24] [setup] RAM Tracking...
[codecarbon INFO @ 19:58:24] [setup] CPU Tracking...
[codecarbon WARNING @ 19:58:24] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 19:58:26] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:58:26] [setup] GPU Tracking...
[codecarbon INFO @ 19:58:26] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:58:26] >>> Tracker's metadata:
[codecarbon INFO @ 19:58:26]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 19:58:26]   Python version: 3.12.7
[codecarbon INFO @ 19:58:26]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 19:58:26]   Available RAM : 126.630 GB
[codecarbon INFO @ 19:58:26]   CPU count: 56
[codecarbon INFO @ 19:58:26]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 19:58:26]   GPU count: 2
[codecarbon INFO @ 19:58:26]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 19:58:29] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 19:58:29] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 19:58:29] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 19:58:29] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.957186796806127 W
[codecarbon INFO @ 19:58:29] 0.000036 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 1                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: mudhog              #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: label_flipping 5->9 #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_label_flipping_5_to_9_inner_epochs=5_epochs=10_PDR=1.0_scale=1_mudhog#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_label_flipping_5_to_9_inner_epochs=5_epochs=10_PDR=1.0_scale=1_mudhog----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 35.210 	Loss: 1.9941[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 56.008 	Loss: 1.3640[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 64.359 	Loss: 1.1250[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 68.858 	Loss: 0.9508[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 71.525 	Loss: 0.8649[00m
[92m  Client0 Test => 	Acc: 32.725 	Loss: 3.5260[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 15.712 	Loss: 3.0880[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 30.035 	Loss: 2.0942[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 26.042 	Loss: 2.1729[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 31.684 	Loss: 2.0145[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 40.885 	Loss: 1.7482[00m
[92m  Client1 Test => 	Acc: 23.388 	Loss: 3.5935[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 22.569 	Loss: 6.5561[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 23.524 	Loss: 2.7119[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 34.549 	Loss: 2.3533[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 44.878 	Loss: 2.0381[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 48.090 	Loss: 1.8146[00m
[92m  Client2 Test => 	Acc: 28.855 	Loss: 3.1733[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 24.479 	Loss: 6.6722[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 31.293 	Loss: 1.9898[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 51.215 	Loss: 1.6671[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 61.849 	Loss: 1.3689[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 68.880 	Loss: 1.1136[00m
[92m  Client3 Test => 	Acc: 25.221 	Loss: 3.6684[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.113 	Loss: 4.8122[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 24.414 	Loss: 2.5832[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.195 	Loss: 2.2228[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 38.281 	Loss: 1.8761[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 49.414 	Loss: 1.5353[00m
[92m  Client4 Test => 	Acc: 21.640 	Loss: 4.2093[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.401 	Loss: 3.7064[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 24.349 	Loss: 2.4651[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 31.250 	Loss: 2.0384[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 30.729 	Loss: 1.9762[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 41.667 	Loss: 1.8298[00m
[92m  Client5 Test => 	Acc: 23.697 	Loss: 3.8546[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 26.000 	Loss: 2.7306[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 43.688 	Loss: 1.8267[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 57.469 	Loss: 1.3764[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 67.062 	Loss: 1.0756[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 71.031 	Loss: 0.9083[00m
[92m  Client6 Test => 	Acc: 49.657 	Loss: 1.8905[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 18.281 	Loss: 3.2440[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 23.516 	Loss: 2.2915[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 25.391 	Loss: 2.1664[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.719 	Loss: 2.1511[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 34.297 	Loss: 1.9642[00m
[92m  Client7 Test => 	Acc: 18.398 	Loss: 3.3816[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 17.578 	Loss: 6.5378[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 19.792 	Loss: 2.4272[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 21.354 	Loss: 2.2228[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 24.609 	Loss: 2.1266[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 28.646 	Loss: 2.1454[00m
[92m  Client8 Test => 	Acc: 5.333 	Loss: 4.7420[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 18.089 	Loss: 3.8243[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 28.125 	Loss: 2.0843[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 29.928 	Loss: 2.0811[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 42.127 	Loss: 1.7385[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 48.257 	Loss: 1.5927[00m
[92m  Client9 Test => 	Acc: 39.644 	Loss: 2.4336[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.949 	Loss: 2.7329[00m
 Train: Round   0, Avg Accuracy 50.269 | Avg Loss 1.552
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 29.283 	Loss: 2.1228[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 34.402 	Loss: 2.0284[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 36.827 	Loss: 1.9108[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 38.389 	Loss: 1.7559[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 38.416 	Loss: 1.7529[00m
[92m  Client0 Test => 	Acc: 12.335 	Loss: 4.1185[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 24.132 	Loss: 2.3843[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.688 	Loss: 2.1298[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.601 	Loss: 2.1276[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 29.774 	Loss: 2.1187[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.514 	Loss: 2.1214[00m
[92m  Client1 Test => 	Acc: 11.081 	Loss: 3.6275[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 42.448 	Loss: 2.2720[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.535 	Loss: 2.1036[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 42.448 	Loss: 2.0839[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 42.361 	Loss: 2.0801[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 42.014 	Loss: 2.0896[00m
[92m  Client2 Test => 	Acc: 12.969 	Loss: 3.3631[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 30.946 	Loss: 2.0831[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 30.642 	Loss: 1.9415[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 53.255 	Loss: 1.5967[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 66.450 	Loss: 1.1782[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 73.438 	Loss: 0.9458[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 20:25:22] [setup] RAM Tracking...
[codecarbon INFO @ 20:25:22] [setup] CPU Tracking...
[codecarbon WARNING @ 20:25:22] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:25:24] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:25:24] [setup] GPU Tracking...
[codecarbon INFO @ 20:25:24] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:25:24] >>> Tracker's metadata:
[codecarbon INFO @ 20:25:24]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:25:24]   Python version: 3.12.7
[codecarbon INFO @ 20:25:24]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:25:24]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:25:24]   CPU count: 56
[codecarbon INFO @ 20:25:24]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:25:24]   GPU count: 2
[codecarbon INFO @ 20:25:24]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:25:27] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:25:27] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:25:27] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:25:27] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.934158991044619 W
[codecarbon INFO @ 20:25:27] 0.000027 kWh of electricity used since the beginning.
[codecarbon INFO @ 20:26:22] [setup] RAM Tracking...
[codecarbon INFO @ 20:26:22] [setup] CPU Tracking...
[codecarbon WARNING @ 20:26:22] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:26:24] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:26:24] [setup] GPU Tracking...
[codecarbon INFO @ 20:26:24] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:26:24] >>> Tracker's metadata:
[codecarbon INFO @ 20:26:24]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:26:24]   Python version: 3.12.7
[codecarbon INFO @ 20:26:24]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:26:24]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:26:24]   CPU count: 56
[codecarbon INFO @ 20:26:24]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:26:24]   GPU count: 2
[codecarbon INFO @ 20:26:24]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:26:27] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:26:28] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:26:28] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:26:28] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.228539497711168 W
[codecarbon INFO @ 20:26:28] 0.000026 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 20:53:19] [setup] RAM Tracking...
[codecarbon INFO @ 20:53:19] [setup] CPU Tracking...
[codecarbon WARNING @ 20:53:19] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:53:21] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:53:21] [setup] GPU Tracking...
[codecarbon INFO @ 20:53:21] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:53:21] >>> Tracker's metadata:
[codecarbon INFO @ 20:53:21]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:53:21]   Python version: 3.12.7
[codecarbon INFO @ 20:53:21]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:53:21]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:53:21]   CPU count: 56
[codecarbon INFO @ 20:53:21]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:53:21]   GPU count: 2
[codecarbon INFO @ 20:53:21]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:53:25] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:53:25] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:53:25] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:53:25] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 24.114500544917934 W
[codecarbon INFO @ 20:53:25] 0.000024 kWh of electricity used since the beginning.
[codecarbon INFO @ 20:54:23] [setup] RAM Tracking...
[codecarbon INFO @ 20:54:23] [setup] CPU Tracking...
[codecarbon WARNING @ 20:54:23] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 20:54:25] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:54:25] [setup] GPU Tracking...
[codecarbon INFO @ 20:54:25] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 20:54:25] >>> Tracker's metadata:
[codecarbon INFO @ 20:54:25]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 20:54:25]   Python version: 3.12.7
[codecarbon INFO @ 20:54:25]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 20:54:25]   Available RAM : 126.630 GB
[codecarbon INFO @ 20:54:25]   CPU count: 56
[codecarbon INFO @ 20:54:25]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 20:54:25]   GPU count: 2
[codecarbon INFO @ 20:54:25]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 20:54:29] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 20:54:29] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 20:54:29] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 20:54:29] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.294725537875568 W
[codecarbon INFO @ 20:54:29] 0.000028 kWh of electricity used since the beginning.

[92m  Client3 Test => 	Acc: 30.138 	Loss: 2.7047[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 17.773 	Loss: 2.5028[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 34.668 	Loss: 1.9199[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 52.832 	Loss: 1.4769[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 55.859 	Loss: 1.3112[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 63.184 	Loss: 1.0955[00m
[92m  Client4 Test => 	Acc: 32.656 	Loss: 3.3664[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 20.052 	Loss: 2.4609[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 30.078 	Loss: 2.0706[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 32.031 	Loss: 2.0234[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 31.510 	Loss: 2.0227[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 34.766 	Loss: 1.9869[00m
[92m  Client5 Test => 	Acc: 18.598 	Loss: 3.3649[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 22.500 	Loss: 2.3098[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 29.094 	Loss: 2.0461[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 48.781 	Loss: 1.6954[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 60.812 	Loss: 1.2944[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 67.750 	Loss: 1.0508[00m
[92m  Client6 Test => 	Acc: 45.765 	Loss: 1.9442[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 19.219 	Loss: 2.4310[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 25.781 	Loss: 2.1548[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 35.469 	Loss: 1.9931[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 35.234 	Loss: 1.9234[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 48.984 	Loss: 1.5095[00m
[92m  Client7 Test => 	Acc: 35.778 	Loss: 2.5902[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 12.760 	Loss: 2.5895[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 35.026 	Loss: 2.1172[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 28.125 	Loss: 2.3869[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 24.089 	Loss: 2.1909[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 23.307 	Loss: 2.1166[00m
[92m  Client8 Test => 	Acc: 4.120 	Loss: 3.6709[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.995 	Loss: 2.2618[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 25.841 	Loss: 2.1266[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 26.863 	Loss: 2.0905[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 25.781 	Loss: 2.1028[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 26.322 	Loss: 2.0976[00m
[92m  Client9 Test => 	Acc: 7.118 	Loss: 3.1581[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 12.942 	Loss: 2.6140[00m
 Train: Round   1, Avg Accuracy 44.769 | Avg Loss 1.677
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 36.018 	Loss: 1.8840[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 39.036 	Loss: 1.7537[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 54.957 	Loss: 1.4610[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 67.322 	Loss: 1.0756[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 76.562 	Loss: 0.7419[00m
[92m  Client0 Test => 	Acc: 41.016 	Loss: 3.6860[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 26.736 	Loss: 2.3695[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 29.167 	Loss: 2.1591[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 29.861 	Loss: 2.1276[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 30.122 	Loss: 2.1220[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 29.688 	Loss: 2.1183[00m
[92m  Client1 Test => 	Acc: 11.061 	Loss: 3.5390[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 40.365 	Loss: 2.2904[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.274 	Loss: 1.9780[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 46.615 	Loss: 1.6686[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 57.899 	Loss: 1.4143[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 62.326 	Loss: 1.1734[00m
[92m  Client2 Test => 	Acc: 34.970 	Loss: 3.3443[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 39.931 	Loss: 1.8201[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 64.236 	Loss: 1.2220[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 72.135 	Loss: 0.9420[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 73.872 	Loss: 0.8691[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 75.781 	Loss: 0.8080[00m
[92m  Client3 Test => 	Acc: 42.038 	Loss: 2.1894[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 15.039 	Loss: 2.5807[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 41.309 	Loss: 1.8214[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 53.125 	Loss: 1.4978[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 58.008 	Loss: 1.3245[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 63.184 	Loss: 1.1606[00m
[92m  Client4 Test => 	Acc: 30.547 	Loss: 2.7872[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 27.734 	Loss: 2.3274[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 30.859 	Loss: 2.0545[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 21.875 	Loss: 2.0406[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 29.167 	Loss: 2.0225[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 44.922 	Loss: 1.8042[00m
[92m  Client5 Test => 	Acc: 24.212 	Loss: 3.4073[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 28.875 	Loss: 2.1451[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 34.562 	Loss: 1.9838[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 32.031 	Loss: 2.0587[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 37.125 	Loss: 1.9042[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 52.625 	Loss: 1.5224[00m
[92m  Client6 Test => 	Acc: 38.339 	Loss: 2.6080[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 25.000 	Loss: 2.3893[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 32.422 	Loss: 2.1006[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 36.719 	Loss: 1.9132[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 38.438 	Loss: 1.7727[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 37.500 	Loss: 1.8426[00m
[92m  Client7 Test => 	Acc: 21.486 	Loss: 2.7961[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 13.542 	Loss: 2.6868[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 25.911 	Loss: 2.1942[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 27.734 	Loss: 2.0745[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 37.630 	Loss: 1.8602[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 52.995 	Loss: 1.6405[00m
[92m  Client8 Test => 	Acc: 21.197 	Loss: 3.1351[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 23.858 	Loss: 2.1924[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 35.938 	Loss: 1.8501[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 36.839 	Loss: 1.7623[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 33.173 	Loss: 1.8771[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 46.755 	Loss: 1.5681[00m
[92m  Client9 Test => 	Acc: 39.739 	Loss: 2.3063[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 11.805 	Loss: 2.6272[00m
 Train: Round   2, Avg Accuracy 54.234 | Avg Loss 1.438
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 40.329 	Loss: 1.9201[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 44.908 	Loss: 1.7512[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 21:21:39] [setup] RAM Tracking...
[codecarbon INFO @ 21:21:39] [setup] CPU Tracking...
[codecarbon WARNING @ 21:21:39] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:21:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:21:41] [setup] GPU Tracking...
[codecarbon INFO @ 21:21:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:21:41] >>> Tracker's metadata:
[codecarbon INFO @ 21:21:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:21:41]   Python version: 3.12.7
[codecarbon INFO @ 21:21:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:21:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:21:41]   CPU count: 56
[codecarbon INFO @ 21:21:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:21:41]   GPU count: 2
[codecarbon INFO @ 21:21:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:21:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:21:44] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:21:44] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:21:44] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 15.043674037087694 W
[codecarbon INFO @ 21:21:44] 0.000027 kWh of electricity used since the beginning.
[codecarbon INFO @ 21:22:40] [setup] RAM Tracking...
[codecarbon INFO @ 21:22:40] [setup] CPU Tracking...
[codecarbon WARNING @ 21:22:40] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:22:41] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:22:41] [setup] GPU Tracking...
[codecarbon INFO @ 21:22:41] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:22:41] >>> Tracker's metadata:
[codecarbon INFO @ 21:22:41]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:22:41]   Python version: 3.12.7
[codecarbon INFO @ 21:22:41]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:22:41]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:22:41]   CPU count: 56
[codecarbon INFO @ 21:22:41]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:22:41]   GPU count: 2
[codecarbon INFO @ 21:22:41]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:22:44] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:22:45] Energy consumed for RAM : 0.000006 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:22:45] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:22:45] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 16.39992383895704 W
[codecarbon INFO @ 21:22:45] 0.000022 kWh of electricity used since the beginning.

[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 63.982 	Loss: 1.1795[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 74.057 	Loss: 0.8354[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 78.260 	Loss: 0.6633[00m
[92m  Client0 Test => 	Acc: 46.958 	Loss: 4.5171[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 37.760 	Loss: 2.1530[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 35.330 	Loss: 1.9419[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 52.517 	Loss: 1.5426[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 54.514 	Loss: 1.3285[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 60.417 	Loss: 1.1371[00m
[92m  Client1 Test => 	Acc: 41.271 	Loss: 3.3968[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 39.236 	Loss: 1.9388[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 58.767 	Loss: 1.3366[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 66.233 	Loss: 1.0829[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 61.892 	Loss: 1.1976[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 70.052 	Loss: 0.9329[00m
[92m  Client2 Test => 	Acc: 45.042 	Loss: 2.8713[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 56.120 	Loss: 1.5391[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 73.872 	Loss: 0.9187[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 77.300 	Loss: 0.7666[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 80.208 	Loss: 0.6250[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 82.595 	Loss: 0.5181[00m
[92m  Client3 Test => 	Acc: 53.276 	Loss: 1.8521[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 31.348 	Loss: 2.1459[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 57.227 	Loss: 1.3789[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 66.406 	Loss: 1.0342[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 65.723 	Loss: 1.0221[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 70.215 	Loss: 0.8939[00m
[92m  Client4 Test => 	Acc: 37.072 	Loss: 3.4925[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 33.073 	Loss: 2.2094[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 49.609 	Loss: 1.6195[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 52.995 	Loss: 1.5036[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 57.031 	Loss: 1.3929[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 65.755 	Loss: 1.1610[00m
[92m  Client5 Test => 	Acc: 39.822 	Loss: 2.9670[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 44.812 	Loss: 1.8073[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 43.500 	Loss: 2.0332[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.000 	Loss: 2.2919[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.594 	Loss: 2.0981[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.594 	Loss: 2.0821[00m
[92m  Client6 Test => 	Acc: 12.328 	Loss: 3.2295[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 31.719 	Loss: 2.2256[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 37.031 	Loss: 1.8520[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 38.984 	Loss: 1.8019[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 48.281 	Loss: 1.6025[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 51.953 	Loss: 1.3956[00m
[92m  Client7 Test => 	Acc: 37.449 	Loss: 2.5402[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 15.755 	Loss: 2.5492[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 43.750 	Loss: 1.7730[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 61.589 	Loss: 1.2243[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 74.740 	Loss: 0.9407[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 77.865 	Loss: 0.7857[00m
[92m  Client8 Test => 	Acc: 36.693 	Loss: 2.5136[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 34.255 	Loss: 1.9196[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 58.714 	Loss: 1.2920[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 70.673 	Loss: 0.9907[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 77.224 	Loss: 0.8012[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 73.918 	Loss: 0.9085[00m
[92m  Client9 Test => 	Acc: 51.201 	Loss: 1.8848[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 45.072 	Loss: 2.0458[00m
 Train: Round   3, Avg Accuracy 65.662 | Avg Loss 1.048
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 66.083 	Loss: 1.1248[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 78.556 	Loss: 0.6796[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 80.280 	Loss: 0.6077[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 81.708 	Loss: 0.5678[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 83.890 	Loss: 0.4750[00m
[92m  Client0 Test => 	Acc: 47.438 	Loss: 3.4836[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 51.736 	Loss: 1.6367[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 63.976 	Loss: 1.1275[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 69.705 	Loss: 0.9835[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 71.701 	Loss: 0.8829[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 67.969 	Loss: 1.0085[00m
[92m  Client1 Test => 	Acc: 42.051 	Loss: 2.7142[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 57.465 	Loss: 1.3940[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 71.094 	Loss: 0.9560[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 76.128 	Loss: 0.7465[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 76.476 	Loss: 0.6907[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 80.990 	Loss: 0.5747[00m
[92m  Client2 Test => 	Acc: 56.961 	Loss: 1.5881[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 73.307 	Loss: 1.0737[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 80.078 	Loss: 0.6456[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 82.292 	Loss: 0.5517[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 84.418 	Loss: 0.5094[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 86.936 	Loss: 0.4021[00m
[92m  Client3 Test => 	Acc: 56.078 	Loss: 1.9985[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 57.031 	Loss: 1.5027[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 69.336 	Loss: 0.9189[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 71.484 	Loss: 0.8220[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 74.121 	Loss: 0.7629[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 80.371 	Loss: 0.6009[00m
[92m  Client4 Test => 	Acc: 49.275 	Loss: 2.4477[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 56.641 	Loss: 1.6265[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 64.062 	Loss: 1.1370[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 65.495 	Loss: 0.9902[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 72.786 	Loss: 0.8011[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 73.568 	Loss: 0.7653[00m
[92m  Client5 Test => 	Acc: 44.482 	Loss: 2.4311[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 62.625 	Loss: 1.3223[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 74.188 	Loss: 0.8625[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 75.031 	Loss: 0.8376[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 82.188 	Loss: 0.6053[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 86.000 	Loss: 0.4501[00m
[92m  Client6 Test => 	Acc: 67.255 	Loss: 1.1913[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 46.484 	Loss: 1.7326[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 57.109 	Loss: 1.3362[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 62.031 	Loss: 1.1372[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 69.141 	Loss: 0.9541[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 75.547 	Loss: 0.7373[00m
[92m  Client7 Test => 	Acc: 44.313 	Loss: 2.3764[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 37.760 	Loss: 2.0293[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 21:49:25] [setup] RAM Tracking...
[codecarbon INFO @ 21:49:25] [setup] CPU Tracking...
[codecarbon WARNING @ 21:49:25] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:49:27] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:49:27] [setup] GPU Tracking...
[codecarbon INFO @ 21:49:27] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:49:27] >>> Tracker's metadata:
[codecarbon INFO @ 21:49:27]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:49:27]   Python version: 3.12.7
[codecarbon INFO @ 21:49:27]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:49:27]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:49:27]   CPU count: 56
[codecarbon INFO @ 21:49:27]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:49:27]   GPU count: 2
[codecarbon INFO @ 21:49:27]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:49:30] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:49:30] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:49:30] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:49:30] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 14.813682025780597 W
[codecarbon INFO @ 21:49:30] 0.000026 kWh of electricity used since the beginning.
[codecarbon INFO @ 21:50:26] [setup] RAM Tracking...
[codecarbon INFO @ 21:50:26] [setup] CPU Tracking...
[codecarbon WARNING @ 21:50:26] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 21:50:28] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:50:28] [setup] GPU Tracking...
[codecarbon INFO @ 21:50:28] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 21:50:28] >>> Tracker's metadata:
[codecarbon INFO @ 21:50:28]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 21:50:28]   Python version: 3.12.7
[codecarbon INFO @ 21:50:28]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 21:50:28]   Available RAM : 126.630 GB
[codecarbon INFO @ 21:50:28]   CPU count: 56
[codecarbon INFO @ 21:50:28]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 21:50:28]   GPU count: 2
[codecarbon INFO @ 21:50:28]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 21:50:31] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 21:50:32] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 21:50:32] Energy consumed for all CPUs : 0.000016 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 21:50:32] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 17.59183822631167 W
[codecarbon INFO @ 21:50:32] 0.000026 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 22:17:27] [setup] RAM Tracking...
[codecarbon INFO @ 22:17:27] [setup] CPU Tracking...
[codecarbon WARNING @ 22:17:27] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:17:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:17:29] [setup] GPU Tracking...
[codecarbon INFO @ 22:17:29] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:17:29] >>> Tracker's metadata:
[codecarbon INFO @ 22:17:29]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:17:29]   Python version: 3.12.7
[codecarbon INFO @ 22:17:29]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:17:29]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:17:29]   CPU count: 56
[codecarbon INFO @ 22:17:29]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:17:29]   GPU count: 2
[codecarbon INFO @ 22:17:29]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:17:32] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:17:32] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:17:32] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:17:32] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.805826675856206 W
[codecarbon INFO @ 22:17:32] 0.000033 kWh of electricity used since the beginning.
[codecarbon INFO @ 22:18:28] [setup] RAM Tracking...
[codecarbon INFO @ 22:18:28] [setup] CPU Tracking...
[codecarbon WARNING @ 22:18:28] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:18:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:18:29] [setup] GPU Tracking...
[codecarbon INFO @ 22:18:29] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:18:29] >>> Tracker's metadata:
[codecarbon INFO @ 22:18:29]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:18:29]   Python version: 3.12.7
[codecarbon INFO @ 22:18:29]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:18:29]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:18:29]   CPU count: 56
[codecarbon INFO @ 22:18:29]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:18:29]   GPU count: 2
[codecarbon INFO @ 22:18:29]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:18:33] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:18:33] Energy consumed for RAM : 0.000006 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:18:33] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:18:33] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 16.990990293476532 W
[codecarbon INFO @ 22:18:33] 0.000023 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 64.193 	Loss: 1.1560[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 73.568 	Loss: 0.8566[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 80.208 	Loss: 0.6817[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 81.901 	Loss: 0.5947[00m
[92m  Client8 Test => 	Acc: 43.284 	Loss: 2.3611[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 59.796 	Loss: 1.3913[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 63.522 	Loss: 1.1611[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 78.606 	Loss: 0.7577[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 79.327 	Loss: 0.7060[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 82.512 	Loss: 0.5702[00m
[92m  Client9 Test => 	Acc: 56.604 	Loss: 1.5287[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 59.545 	Loss: 1.3201[00m
 Train: Round   4, Avg Accuracy 79.968 | Avg Loss 0.618
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 75.754 	Loss: 0.7534[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 82.759 	Loss: 0.5155[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 85.641 	Loss: 0.4428[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 86.880 	Loss: 0.4071[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 89.062 	Loss: 0.3266[00m
[92m  Client0 Test => 	Acc: 52.356 	Loss: 3.8553[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 64.149 	Loss: 1.0952[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 70.573 	Loss: 0.9106[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 77.431 	Loss: 0.7071[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 79.948 	Loss: 0.6197[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 74.653 	Loss: 0.7704[00m
[92m  Client1 Test => 	Acc: 50.113 	Loss: 2.0335[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 75.521 	Loss: 0.8345[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 79.688 	Loss: 0.6097[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 82.031 	Loss: 0.5322[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 83.333 	Loss: 0.4857[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 84.288 	Loss: 0.5056[00m
[92m  Client2 Test => 	Acc: 63.814 	Loss: 1.2876[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 80.816 	Loss: 0.6860[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 84.462 	Loss: 0.5098[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 85.677 	Loss: 0.4599[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 88.585 	Loss: 0.3797[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 88.672 	Loss: 0.3562[00m
[92m  Client3 Test => 	Acc: 63.288 	Loss: 1.5152[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 76.270 	Loss: 0.8177[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 80.957 	Loss: 0.6129[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 80.469 	Loss: 0.5865[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 86.426 	Loss: 0.4658[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 84.668 	Loss: 0.4899[00m
[92m  Client4 Test => 	Acc: 45.484 	Loss: 2.2430[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 72.917 	Loss: 0.9555[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 76.953 	Loss: 0.7135[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 79.688 	Loss: 0.5733[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 83.984 	Loss: 0.4838[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 81.120 	Loss: 0.5785[00m
[92m  Client5 Test => 	Acc: 61.082 	Loss: 2.0301[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 72.562 	Loss: 0.8533[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 79.406 	Loss: 0.6261[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 81.500 	Loss: 0.5628[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 86.844 	Loss: 0.4044[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 88.094 	Loss: 0.3893[00m
[92m  Client6 Test => 	Acc: 68.219 	Loss: 1.1833[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 56.172 	Loss: 1.3118[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 68.828 	Loss: 0.9398[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 77.109 	Loss: 0.7082[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 77.422 	Loss: 0.6678[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 81.016 	Loss: 0.5778[00m
[92m  Client7 Test => 	Acc: 59.155 	Loss: 1.7140[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 65.625 	Loss: 1.0908[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 80.990 	Loss: 0.6482[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 83.203 	Loss: 0.5475[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 85.938 	Loss: 0.4585[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 86.979 	Loss: 0.4157[00m
[92m  Client8 Test => 	Acc: 48.740 	Loss: 2.0329[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 76.562 	Loss: 0.8391[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 81.550 	Loss: 0.6378[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 82.873 	Loss: 0.5801[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 85.337 	Loss: 0.5092[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 86.599 	Loss: 0.4160[00m
[92m  Client9 Test => 	Acc: 66.170 	Loss: 1.2149[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 68.580 	Loss: 0.9239[00m
 Train: Round   5, Avg Accuracy 84.515 | Avg Loss 0.483
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 81.277 	Loss: 0.5683[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 82.543 	Loss: 0.5397[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 85.695 	Loss: 0.4381[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 90.275 	Loss: 0.3063[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 91.595 	Loss: 0.2612[00m
[92m  Client0 Test => 	Acc: 55.151 	Loss: 3.8120[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 73.003 	Loss: 0.8225[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 81.424 	Loss: 0.5551[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 84.115 	Loss: 0.4853[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 85.764 	Loss: 0.4070[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 87.587 	Loss: 0.3793[00m
[92m  Client1 Test => 	Acc: 64.457 	Loss: 1.7996[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 80.122 	Loss: 0.6115[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 83.941 	Loss: 0.4958[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 84.983 	Loss: 0.3961[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 89.931 	Loss: 0.3079[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 89.323 	Loss: 0.3046[00m
[92m  Client2 Test => 	Acc: 68.577 	Loss: 1.3441[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 84.592 	Loss: 0.5421[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 88.194 	Loss: 0.3742[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 89.714 	Loss: 0.3038[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 92.491 	Loss: 0.2338[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 92.882 	Loss: 0.2386[00m
[92m  Client3 Test => 	Acc: 67.605 	Loss: 1.5941[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 85.449 	Loss: 0.5142[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 88.672 	Loss: 0.3626[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 86.719 	Loss: 0.4637[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 22:45:32] [setup] RAM Tracking...
[codecarbon INFO @ 22:45:32] [setup] CPU Tracking...
[codecarbon WARNING @ 22:45:32] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:45:34] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:45:34] [setup] GPU Tracking...
[codecarbon INFO @ 22:45:34] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:45:34] >>> Tracker's metadata:
[codecarbon INFO @ 22:45:34]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:45:34]   Python version: 3.12.7
[codecarbon INFO @ 22:45:34]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:45:34]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:45:34]   CPU count: 56
[codecarbon INFO @ 22:45:34]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:45:34]   GPU count: 2
[codecarbon INFO @ 22:45:34]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:45:37] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:45:37] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:45:37] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:45:37] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.416570616615775 W
[codecarbon INFO @ 22:45:37] 0.000027 kWh of electricity used since the beginning.
[codecarbon INFO @ 22:46:33] [setup] RAM Tracking...
[codecarbon INFO @ 22:46:33] [setup] CPU Tracking...
[codecarbon WARNING @ 22:46:33] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 22:46:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:46:35] [setup] GPU Tracking...
[codecarbon INFO @ 22:46:35] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 22:46:35] >>> Tracker's metadata:
[codecarbon INFO @ 22:46:35]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 22:46:35]   Python version: 3.12.7
[codecarbon INFO @ 22:46:35]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 22:46:35]   Available RAM : 126.630 GB
[codecarbon INFO @ 22:46:35]   CPU count: 56
[codecarbon INFO @ 22:46:35]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 22:46:35]   GPU count: 2
[codecarbon INFO @ 22:46:35]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 22:46:38] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 22:46:38] Energy consumed for RAM : 0.000006 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 22:46:38] Energy consumed for all CPUs : 0.000013 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 22:46:38] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 16.80138884480316 W
[codecarbon INFO @ 22:46:38] 0.000022 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 23:13:36] [setup] RAM Tracking...
[codecarbon INFO @ 23:13:36] [setup] CPU Tracking...
[codecarbon WARNING @ 23:13:36] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:13:38] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:13:38] [setup] GPU Tracking...
[codecarbon INFO @ 23:13:38] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:13:38] >>> Tracker's metadata:
[codecarbon INFO @ 23:13:38]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:13:38]   Python version: 3.12.7
[codecarbon INFO @ 23:13:38]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:13:38]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:13:38]   CPU count: 56
[codecarbon INFO @ 23:13:38]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:13:38]   GPU count: 2
[codecarbon INFO @ 23:13:38]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:13:41] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:13:42] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:13:42] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:13:42] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.420170455572656 W
[codecarbon INFO @ 23:13:42] 0.000035 kWh of electricity used since the beginning.
[codecarbon INFO @ 23:14:38] [setup] RAM Tracking...
[codecarbon INFO @ 23:14:38] [setup] CPU Tracking...
[codecarbon WARNING @ 23:14:38] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:14:40] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:14:40] [setup] GPU Tracking...
[codecarbon INFO @ 23:14:40] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:14:40] >>> Tracker's metadata:
[codecarbon INFO @ 23:14:40]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:14:40]   Python version: 3.12.7
[codecarbon INFO @ 23:14:40]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:14:40]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:14:40]   CPU count: 56
[codecarbon INFO @ 23:14:40]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:14:40]   GPU count: 2
[codecarbon INFO @ 23:14:40]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:14:43] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:14:43] Energy consumed for RAM : 0.000007 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:14:43] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:14:43] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 26.175015194811095 W
[codecarbon INFO @ 23:14:43] 0.000025 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 91.211 	Loss: 0.2672[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 91.113 	Loss: 0.2853[00m
[92m  Client4 Test => 	Acc: 62.790 	Loss: 1.4127[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 77.865 	Loss: 0.7400[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 77.865 	Loss: 0.5943[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 81.641 	Loss: 0.5197[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 86.458 	Loss: 0.4327[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 87.370 	Loss: 0.4008[00m
[92m  Client5 Test => 	Acc: 66.253 	Loss: 1.5851[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 78.156 	Loss: 0.6659[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 85.188 	Loss: 0.4821[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 87.750 	Loss: 0.4141[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 88.906 	Loss: 0.3675[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 88.938 	Loss: 0.3737[00m
[92m  Client6 Test => 	Acc: 65.655 	Loss: 1.0679[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 67.266 	Loss: 0.9264[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 80.703 	Loss: 0.6495[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 77.969 	Loss: 0.6839[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 80.469 	Loss: 0.5409[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 82.578 	Loss: 0.5290[00m
[92m  Client7 Test => 	Acc: 63.471 	Loss: 1.3466[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 77.604 	Loss: 0.6826[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 84.896 	Loss: 0.5171[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 86.979 	Loss: 0.4253[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 90.365 	Loss: 0.2911[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 91.406 	Loss: 0.2942[00m
[92m  Client8 Test => 	Acc: 55.903 	Loss: 1.6704[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 81.731 	Loss: 0.5851[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 87.620 	Loss: 0.4054[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 87.921 	Loss: 0.3929[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 89.904 	Loss: 0.3286[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 90.805 	Loss: 0.2977[00m
[92m  Client9 Test => 	Acc: 69.916 	Loss: 1.0937[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 75.308 	Loss: 0.7126[00m
 Train: Round   6, Avg Accuracy 89.360 | Avg Loss 0.336
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 86.611 	Loss: 0.4071[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 87.150 	Loss: 0.3991[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 89.251 	Loss: 0.3486[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 91.029 	Loss: 0.2741[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 93.319 	Loss: 0.2148[00m
[92m  Client0 Test => 	Acc: 63.076 	Loss: 2.8189[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 78.993 	Loss: 0.6071[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 83.420 	Loss: 0.4667[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 86.892 	Loss: 0.3991[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 85.851 	Loss: 0.3990[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 88.628 	Loss: 0.3202[00m
[92m  Client1 Test => 	Acc: 69.374 	Loss: 1.4740[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 86.806 	Loss: 0.4468[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 88.889 	Loss: 0.3629[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 89.410 	Loss: 0.3127[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 91.233 	Loss: 0.2518[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 91.146 	Loss: 0.2659[00m
[92m  Client2 Test => 	Acc: 77.303 	Loss: 0.9741[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 87.370 	Loss: 0.4130[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 90.668 	Loss: 0.3116[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 91.884 	Loss: 0.2733[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 93.012 	Loss: 0.2053[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 94.444 	Loss: 0.1693[00m
[92m  Client3 Test => 	Acc: 76.706 	Loss: 1.2668[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 86.035 	Loss: 0.4164[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 90.625 	Loss: 0.2948[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 92.285 	Loss: 0.2321[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 92.969 	Loss: 0.2071[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 92.090 	Loss: 0.2223[00m
[92m  Client4 Test => 	Acc: 70.284 	Loss: 1.1753[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 85.026 	Loss: 0.4932[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 87.370 	Loss: 0.3670[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 90.104 	Loss: 0.2728[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 90.365 	Loss: 0.2768[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 90.625 	Loss: 0.2636[00m
[92m  Client5 Test => 	Acc: 71.001 	Loss: 1.5292[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 81.875 	Loss: 0.5587[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 88.562 	Loss: 0.3674[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 89.188 	Loss: 0.4476[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 70.500 	Loss: 1.0278[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 83.312 	Loss: 0.5333[00m
[92m  Client6 Test => 	Acc: 68.704 	Loss: 1.0734[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 77.500 	Loss: 0.6723[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 84.531 	Loss: 0.4955[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 86.250 	Loss: 0.3990[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 88.594 	Loss: 0.3599[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 82.734 	Loss: 0.5514[00m
[92m  Client7 Test => 	Acc: 72.506 	Loss: 1.0536[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 84.505 	Loss: 0.4842[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 90.625 	Loss: 0.3114[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 92.839 	Loss: 0.2315[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 94.792 	Loss: 0.1755[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 93.750 	Loss: 0.1788[00m
[92m  Client8 Test => 	Acc: 69.552 	Loss: 1.2602[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 85.036 	Loss: 0.4553[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 89.724 	Loss: 0.3331[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 91.526 	Loss: 0.2737[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 91.587 	Loss: 0.2773[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 92.007 	Loss: 0.2593[00m
[92m  Client9 Test => 	Acc: 72.036 	Loss: 0.9245[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 82.693 	Loss: 0.5063[00m
 Train: Round   7, Avg Accuracy 90.206 | Avg Loss 0.298
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 88.308 	Loss: 0.3620[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 93.265 	Loss: 0.2139[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 92.484 	Loss: 0.2301[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 94.316 	Loss: 0.1822[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 94.531 	Loss: 0.1702[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 23:41:30] [setup] RAM Tracking...
[codecarbon INFO @ 23:41:30] [setup] CPU Tracking...
[codecarbon WARNING @ 23:41:30] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:41:31] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:41:31] [setup] GPU Tracking...
[codecarbon INFO @ 23:41:31] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:41:31] >>> Tracker's metadata:
[codecarbon INFO @ 23:41:31]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:41:31]   Python version: 3.12.7
[codecarbon INFO @ 23:41:31]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:41:31]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:41:31]   CPU count: 56
[codecarbon INFO @ 23:41:31]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:41:31]   GPU count: 2
[codecarbon INFO @ 23:41:31]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:41:34] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:41:35] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:41:35] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:41:35] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.374743210832477 W
[codecarbon INFO @ 23:41:35] 0.000035 kWh of electricity used since the beginning.
[codecarbon INFO @ 23:42:31] [setup] RAM Tracking...
[codecarbon INFO @ 23:42:31] [setup] CPU Tracking...
[codecarbon WARNING @ 23:42:31] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 23:42:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:42:33] [setup] GPU Tracking...
[codecarbon INFO @ 23:42:33] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 23:42:33] >>> Tracker's metadata:
[codecarbon INFO @ 23:42:33]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 23:42:33]   Python version: 3.12.7
[codecarbon INFO @ 23:42:33]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 23:42:33]   Available RAM : 126.630 GB
[codecarbon INFO @ 23:42:33]   CPU count: 56
[codecarbon INFO @ 23:42:33]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 23:42:33]   GPU count: 2
[codecarbon INFO @ 23:42:33]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 23:42:36] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 23:42:36] Energy consumed for RAM : 0.000006 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 23:42:36] Energy consumed for all CPUs : 0.000014 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 23:42:36] Energy consumed for all GPUs : 0.000002 kWh. Total GPU Power : 15.742331781391346 W
[codecarbon INFO @ 23:42:36] 0.000022 kWh of electricity used since the beginning.

[92m  Client0 Test => 	Acc: 60.614 	Loss: 2.8038[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 86.545 	Loss: 0.4004[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 91.059 	Loss: 0.2612[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 86.458 	Loss: 0.4086[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 87.240 	Loss: 0.3859[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 89.670 	Loss: 0.2987[00m
[92m  Client1 Test => 	Acc: 72.355 	Loss: 1.2033[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 90.538 	Loss: 0.3034[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 89.844 	Loss: 0.2790[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 92.188 	Loss: 0.2308[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 94.010 	Loss: 0.1852[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 93.924 	Loss: 0.1764[00m
[92m  Client2 Test => 	Acc: 79.731 	Loss: 0.8797[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 92.318 	Loss: 0.2652[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 92.882 	Loss: 0.2440[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 94.097 	Loss: 0.1762[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 95.095 	Loss: 0.1522[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 94.401 	Loss: 0.1684[00m
[92m  Client3 Test => 	Acc: 82.845 	Loss: 0.6704[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 91.797 	Loss: 0.2772[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 94.336 	Loss: 0.1943[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 94.043 	Loss: 0.1679[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 93.652 	Loss: 0.1848[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 94.727 	Loss: 0.1740[00m
[92m  Client4 Test => 	Acc: 74.583 	Loss: 1.0053[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 88.021 	Loss: 0.4016[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 87.109 	Loss: 0.3673[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 89.974 	Loss: 0.2483[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 94.531 	Loss: 0.1666[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 94.271 	Loss: 0.1851[00m
[92m  Client5 Test => 	Acc: 76.159 	Loss: 1.3751[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 90.156 	Loss: 0.3257[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 90.812 	Loss: 0.2831[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 91.750 	Loss: 0.2588[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 93.250 	Loss: 0.2159[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 93.125 	Loss: 0.2136[00m
[92m  Client6 Test => 	Acc: 76.320 	Loss: 0.7787[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 79.531 	Loss: 0.6087[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 86.094 	Loss: 0.4730[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 89.141 	Loss: 0.3400[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 90.547 	Loss: 0.3004[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 91.328 	Loss: 0.2671[00m
[92m  Client7 Test => 	Acc: 77.203 	Loss: 0.7892[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 88.151 	Loss: 0.4183[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 92.188 	Loss: 0.2650[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 92.839 	Loss: 0.1796[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 94.401 	Loss: 0.1686[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 96.875 	Loss: 0.1206[00m
[92m  Client8 Test => 	Acc: 74.964 	Loss: 1.0361[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 90.925 	Loss: 0.3046[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 92.728 	Loss: 0.2378[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 93.990 	Loss: 0.2058[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 92.728 	Loss: 0.2417[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 93.510 	Loss: 0.2075[00m
[92m  Client9 Test => 	Acc: 76.630 	Loss: 0.7875[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 87.532 	Loss: 0.3886[00m
 Train: Round   8, Avg Accuracy 93.636 | Avg Loss 0.198
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 90.975 	Loss: 0.2903[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 93.427 	Loss: 0.1968[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 93.858 	Loss: 0.1821[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 94.585 	Loss: 0.1698[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 93.912 	Loss: 0.1924[00m
[92m  Client0 Test => 	Acc: 67.773 	Loss: 3.2933[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 87.674 	Loss: 0.3756[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 90.191 	Loss: 0.2964[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 93.056 	Loss: 0.2206[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 94.271 	Loss: 0.1736[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 95.226 	Loss: 0.1411[00m
[92m  Client1 Test => 	Acc: 78.454 	Loss: 0.9207[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 92.708 	Loss: 0.2300[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 94.358 	Loss: 0.1462[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 96.007 	Loss: 0.1186[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 96.701 	Loss: 0.0946[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 91.840 	Loss: 0.2608[00m
[92m  Client2 Test => 	Acc: 77.639 	Loss: 1.0440[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 94.010 	Loss: 0.2099[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 95.312 	Loss: 0.1642[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 94.878 	Loss: 0.1688[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 96.398 	Loss: 0.1201[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 96.832 	Loss: 0.0988[00m
[92m  Client3 Test => 	Acc: 82.106 	Loss: 0.7880[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 93.457 	Loss: 0.2099[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 94.922 	Loss: 0.1324[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 95.020 	Loss: 0.1323[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 95.801 	Loss: 0.1199[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 95.996 	Loss: 0.1028[00m
[92m  Client4 Test => 	Acc: 78.858 	Loss: 0.8069[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 90.885 	Loss: 0.2655[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 91.667 	Loss: 0.2170[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 94.922 	Loss: 0.1582[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 95.052 	Loss: 0.1512[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 96.354 	Loss: 0.1281[00m
[92m  Client5 Test => 	Acc: 77.505 	Loss: 0.9888[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 91.594 	Loss: 0.2752[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 93.812 	Loss: 0.2092[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 93.562 	Loss: 0.1845[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 94.125 	Loss: 0.1964[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 94.938 	Loss: 0.1571[00m
[92m  Client6 Test => 	Acc: 85.639 	Loss: 0.4663[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 89.375 	Loss: 0.3290[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 89.844 	Loss: 0.2695[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 92.188 	Loss: 0.2517[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 92.734 	Loss: 0.2291[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 93.906 	Loss: 0.1991[00m
[92m  Client7 Test => 	Acc: 80.591 	Loss: 0.7925[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 92.057 	Loss: 0.2588[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 93.880 	Loss: 0.1823[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 96.745 	Loss: 0.1170[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 97.917 	Loss: 0.0872[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 00:09:33] [setup] RAM Tracking...
[codecarbon INFO @ 00:09:33] [setup] CPU Tracking...
[codecarbon WARNING @ 00:09:33] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 00:09:34] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:09:34] [setup] GPU Tracking...
[codecarbon INFO @ 00:09:34] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 00:09:34] >>> Tracker's metadata:
[codecarbon INFO @ 00:09:34]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 00:09:34]   Python version: 3.12.7
[codecarbon INFO @ 00:09:34]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 00:09:34]   Available RAM : 126.630 GB
[codecarbon INFO @ 00:09:34]   CPU count: 56
[codecarbon INFO @ 00:09:34]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 00:09:34]   GPU count: 2
[codecarbon INFO @ 00:09:34]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 00:09:38] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 00:09:38] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 00:09:38] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 00:09:38] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 14.903070055691675 W
[codecarbon INFO @ 00:09:38] 0.000028 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 97.786 	Loss: 0.0887[00m
[92m  Client8 Test => 	Acc: 80.256 	Loss: 0.7625[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 92.728 	Loss: 0.2438[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 94.772 	Loss: 0.1575[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 94.531 	Loss: 0.1660[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 95.433 	Loss: 0.1498[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 92.909 	Loss: 0.2305[00m
[92m  Client9 Test => 	Acc: 78.532 	Loss: 0.8330[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 91.684 	Loss: 0.2666[00m
 Train: Round   9, Avg Accuracy 94.970 | Avg Loss 0.160
Training and Evaluation completed!
===== END Thu 01/08/2026  0:10:39.06 ===== 
