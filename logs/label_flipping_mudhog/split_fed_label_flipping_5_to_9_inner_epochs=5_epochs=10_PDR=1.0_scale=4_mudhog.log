===== START Sun 12/21/2025  1:14:53.83 ===== 
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon INFO @ 01:15:25] [setup] RAM Tracking...
[codecarbon INFO @ 01:15:25] [setup] CPU Tracking...
[codecarbon WARNING @ 01:15:25] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:15:27] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:15:27] [setup] GPU Tracking...
[codecarbon INFO @ 01:15:27] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:15:27] >>> Tracker's metadata:
[codecarbon INFO @ 01:15:27]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:15:27]   Python version: 3.12.7
[codecarbon INFO @ 01:15:27]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:15:27]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:15:27]   CPU count: 56
[codecarbon INFO @ 01:15:27]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:15:27]   GPU count: 2
[codecarbon INFO @ 01:15:27]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:15:30] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:15:32] Energy consumed for RAM : 0.000021 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:15:32] Energy consumed for all CPUs : 0.000046 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:15:32] Energy consumed for all GPUs : 0.000008 kWh. Total GPU Power : 17.10979913656716 W
[codecarbon INFO @ 01:15:32] 0.000074 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 01:42:03] [setup] RAM Tracking...
[codecarbon INFO @ 01:42:03] [setup] CPU Tracking...
[codecarbon WARNING @ 01:42:03] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:42:05] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:42:05] [setup] GPU Tracking...
[codecarbon INFO @ 01:42:05] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:42:05] >>> Tracker's metadata:
[codecarbon INFO @ 01:42:05]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:42:05]   Python version: 3.12.7
[codecarbon INFO @ 01:42:05]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:42:05]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:42:05]   CPU count: 56
[codecarbon INFO @ 01:42:05]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:42:05]   GPU count: 2
[codecarbon INFO @ 01:42:05]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:42:08] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:42:10] Energy consumed for RAM : 0.000018 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:42:10] Energy consumed for all CPUs : 0.000039 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:42:10] Energy consumed for all GPUs : 0.000008 kWh. Total GPU Power : 21.585698899109374 W
[codecarbon INFO @ 01:42:10] 0.000065 kWh of electricity used since the beginning.
[codecarbon INFO @ 01:43:04] [setup] RAM Tracking...
[codecarbon INFO @ 01:43:04] [setup] CPU Tracking...
[codecarbon WARNING @ 01:43:04] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 01:43:06] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:43:06] [setup] GPU Tracking...
[codecarbon INFO @ 01:43:06] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 01:43:06] >>> Tracker's metadata:
[codecarbon INFO @ 01:43:06]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 01:43:06]   Python version: 3.12.7
[codecarbon INFO @ 01:43:06]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 01:43:06]   Available RAM : 126.630 GB
[codecarbon INFO @ 01:43:06]   CPU count: 56
[codecarbon INFO @ 01:43:06]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 01:43:06]   GPU count: 2
[codecarbon INFO @ 01:43:06]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 01:43:09] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 01:43:10] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 01:43:10] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 01:43:10] Energy consumed for all GPUs : 0.000005 kWh. Total GPU Power : 21.4166030027356 W
[codecarbon INFO @ 01:43:10] 0.000040 kWh of electricity used since the beginning.
################################################################
#                              batch_size: 64                  #
#                         test_batch_size: 64                  #
#                                  epochs: 10                  #
#                               optimizer: SGD                 #
#                                      lr: 0.001               #
#                                momentum: 0.5                 #
#                                    seed: 1                   #
#                             num_clients: 10                  #
#                                   scale: 4                   #
#                                 dataset: plant               #
#                             loader_type: dirichlet           #
#                                      AR: mudhog              #
#                                    side: both                #
#                                     PDR: 1.0                 #
#                                  attack: label_flipping 5->9 #
#                          label_flipping: uni                 #
#                         experiment_name: split_fed_label_flipping_5_to_9_inner_epochs=5_epochs=10_PDR=1.0_scale=4_mudhog#
#                            inner_epochs: 5                   #
#                                   setup: split_fed           #
#                                   alpha: 0.5                 #
################################################################
NVIDIA RTX A5000
---------split_fed_label_flipping_5_to_9_inner_epochs=5_epochs=10_PDR=1.0_scale=4_mudhog----------
initialize a data loader
Using cuda
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 35.210 	Loss: 1.9941[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 56.008 	Loss: 1.3640[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 64.359 	Loss: 1.1250[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 68.858 	Loss: 0.9508[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 71.525 	Loss: 0.8649[00m
[92m  Client0 Test => 	Acc: 32.725 	Loss: 3.5260[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 22.222 	Loss: 3.7197[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 39.497 	Loss: 1.9876[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 39.497 	Loss: 1.8888[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 42.274 	Loss: 1.7732[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 45.052 	Loss: 1.6446[00m
[92m  Client1 Test => 	Acc: 16.242 	Loss: 4.6188[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 34.809 	Loss: 3.3673[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 42.101 	Loss: 2.1251[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 47.135 	Loss: 1.9944[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 47.483 	Loss: 1.8434[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 47.830 	Loss: 1.7156[00m
[92m  Client2 Test => 	Acc: 9.116 	Loss: 4.1664[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 27.387 	Loss: 3.2720[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 56.554 	Loss: 1.3466[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 71.788 	Loss: 0.9870[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 73.958 	Loss: 0.9147[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 74.696 	Loss: 0.8570[00m
[92m  Client3 Test => 	Acc: 21.715 	Loss: 5.1259[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 16.113 	Loss: 4.8122[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 24.414 	Loss: 2.5832[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 25.195 	Loss: 2.2228[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 38.281 	Loss: 1.8761[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 49.414 	Loss: 1.5353[00m
[92m  Client4 Test => 	Acc: 21.640 	Loss: 4.2093[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 19.401 	Loss: 3.7064[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 24.349 	Loss: 2.4651[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 31.250 	Loss: 2.0384[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 30.729 	Loss: 1.9762[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 41.667 	Loss: 1.8298[00m
[92m  Client5 Test => 	Acc: 23.697 	Loss: 3.8546[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 26.000 	Loss: 2.7306[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 43.688 	Loss: 1.8267[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 57.469 	Loss: 1.3764[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 67.062 	Loss: 1.0756[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 71.031 	Loss: 0.9083[00m
[92m  Client6 Test => 	Acc: 49.657 	Loss: 1.8905[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 18.281 	Loss: 3.2440[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 23.516 	Loss: 2.2915[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 25.391 	Loss: 2.1664[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 26.719 	Loss: 2.1511[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 34.297 	Loss: 1.9642[00m
[92m  Client7 Test => 	Acc: 18.398 	Loss: 3.3816[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 17.578 	Loss: 6.5378[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 19.792 	Loss: 2.4272[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 21.354 	Loss: 2.2228[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 24.609 	Loss: 2.1266[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 28.646 	Loss: 2.1454[00m
[92m  Client8 Test => 	Acc: 5.333 	Loss: 4.7420[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 18.089 	Loss: 3.8243[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 28.125 	Loss: 2.0843[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 29.928 	Loss: 2.0811[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 42.127 	Loss: 1.7385[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 48.257 	Loss: 1.5927[00m
[92m  Client9 Test => 	Acc: 39.644 	Loss: 2.4336[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 0. 0. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 11.081 	Loss: 2.7473[00m
 Train: Round   0, Avg Accuracy 51.241 | Avg Loss 1.506
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 37.823 	Loss: 1.8455[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 51.805 	Loss: 1.5947[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 68.939 	Loss: 0.9785[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 75.620 	Loss: 0.7502[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 80.765 	Loss: 0.5836[00m
[92m  Client0 Test => 	Acc: 45.299 	Loss: 3.5850[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 39.670 	Loss: 2.2373[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 39.931 	Loss: 1.9232[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 42.274 	Loss: 1.8062[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 41.927 	Loss: 1.7045[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 47.049 	Loss: 1.6998[00m
[92m  Client1 Test => 	Acc: 17.059 	Loss: 4.3464[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 47.222 	Loss: 2.1857[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 47.135 	Loss: 1.9848[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 47.222 	Loss: 1.9040[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 47.049 	Loss: 1.8283[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 46.788 	Loss: 1.6369[00m
[92m  Client2 Test => 	Acc: 14.872 	Loss: 5.7442[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 29.557 	Loss: 2.0482[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 49.826 	Loss: 1.5644[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 72.873 	Loss: 0.9373[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 78.082 	Loss: 0.7332[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 80.773 	Loss: 0.6347[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:09:53] [setup] RAM Tracking...
[codecarbon INFO @ 02:09:53] [setup] CPU Tracking...
[codecarbon WARNING @ 02:09:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:09:54] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:09:54] [setup] GPU Tracking...
[codecarbon INFO @ 02:09:54] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:09:54] >>> Tracker's metadata:
[codecarbon INFO @ 02:09:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:09:54]   Python version: 3.12.7
[codecarbon INFO @ 02:09:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:09:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:09:54]   CPU count: 56
[codecarbon INFO @ 02:09:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:09:54]   GPU count: 2
[codecarbon INFO @ 02:09:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:09:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:09:58] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:09:58] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:09:58] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 15.943502428722761 W
[codecarbon INFO @ 02:09:58] 0.000041 kWh of electricity used since the beginning.
[codecarbon INFO @ 02:10:53] [setup] RAM Tracking...
[codecarbon INFO @ 02:10:53] [setup] CPU Tracking...
[codecarbon WARNING @ 02:10:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:10:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:10:55] [setup] GPU Tracking...
[codecarbon INFO @ 02:10:55] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:10:55] >>> Tracker's metadata:
[codecarbon INFO @ 02:10:55]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:10:55]   Python version: 3.12.7
[codecarbon INFO @ 02:10:55]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:10:55]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:10:55]   CPU count: 56
[codecarbon INFO @ 02:10:55]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:10:55]   GPU count: 2
[codecarbon INFO @ 02:10:55]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:10:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:10:59] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:10:59] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:10:59] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.073410361648516 W
[codecarbon INFO @ 02:10:59] 0.000035 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 02:37:51] [setup] RAM Tracking...
[codecarbon INFO @ 02:37:51] [setup] CPU Tracking...
[codecarbon WARNING @ 02:37:51] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:37:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:37:53] [setup] GPU Tracking...
[codecarbon INFO @ 02:37:53] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:37:53] >>> Tracker's metadata:
[codecarbon INFO @ 02:37:53]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:37:53]   Python version: 3.12.7
[codecarbon INFO @ 02:37:53]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:37:53]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:37:53]   CPU count: 56
[codecarbon INFO @ 02:37:53]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:37:53]   GPU count: 2
[codecarbon INFO @ 02:37:53]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:37:56] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:37:56] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:37:56] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:37:56] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.173136448704362 W
[codecarbon INFO @ 02:37:56] 0.000035 kWh of electricity used since the beginning.
[codecarbon INFO @ 02:38:52] [setup] RAM Tracking...
[codecarbon INFO @ 02:38:52] [setup] CPU Tracking...
[codecarbon WARNING @ 02:38:52] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 02:38:53] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:38:53] [setup] GPU Tracking...
[codecarbon INFO @ 02:38:53] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 02:38:54] >>> Tracker's metadata:
[codecarbon INFO @ 02:38:54]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 02:38:54]   Python version: 3.12.7
[codecarbon INFO @ 02:38:54]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 02:38:54]   Available RAM : 126.630 GB
[codecarbon INFO @ 02:38:54]   CPU count: 56
[codecarbon INFO @ 02:38:54]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 02:38:54]   GPU count: 2
[codecarbon INFO @ 02:38:54]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 02:38:57] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 02:38:57] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 02:38:57] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 02:38:57] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.525425794340357 W
[codecarbon INFO @ 02:38:57] 0.000030 kWh of electricity used since the beginning.

[92m  Client3 Test => 	Acc: 41.992 	Loss: 5.8516[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 22.656 	Loss: 2.4608[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 41.211 	Loss: 1.7756[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 56.445 	Loss: 1.3289[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 64.648 	Loss: 1.0344[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 68.457 	Loss: 0.9418[00m
[92m  Client4 Test => 	Acc: 40.375 	Loss: 2.7427[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 18.750 	Loss: 2.5434[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 24.349 	Loss: 2.1010[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 32.292 	Loss: 1.9272[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 45.833 	Loss: 1.7426[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 52.083 	Loss: 1.5550[00m
[92m  Client5 Test => 	Acc: 27.519 	Loss: 3.1457[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 26.281 	Loss: 2.1766[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.156 	Loss: 2.0894[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 25.875 	Loss: 2.0836[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 25.781 	Loss: 2.0823[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.438 	Loss: 2.0800[00m
[92m  Client6 Test => 	Acc: 12.362 	Loss: 3.3185[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 21.406 	Loss: 2.3811[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 28.750 	Loss: 2.1690[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 36.406 	Loss: 1.9092[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 48.906 	Loss: 1.5431[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 47.109 	Loss: 1.5511[00m
[92m  Client7 Test => 	Acc: 30.953 	Loss: 2.9775[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 18.099 	Loss: 2.6024[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 38.021 	Loss: 2.1242[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 43.359 	Loss: 2.0167[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 49.479 	Loss: 1.7088[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 51.823 	Loss: 1.5065[00m
[92m  Client8 Test => 	Acc: 17.168 	Loss: 3.3817[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 21.575 	Loss: 2.2658[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 29.026 	Loss: 2.0396[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 34.135 	Loss: 1.9399[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 45.853 	Loss: 1.6994[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 53.425 	Loss: 1.4890[00m
[92m  Client9 Test => 	Acc: 27.148 	Loss: 2.2484[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[0. 0. 0. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 11.067 	Loss: 2.7486[00m
 Train: Round   1, Avg Accuracy 55.371 | Avg Loss 1.368
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 51.428 	Loss: 1.5174[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 71.821 	Loss: 0.9306[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 79.230 	Loss: 0.6583[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 81.223 	Loss: 0.5726[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 84.995 	Loss: 0.4717[00m
[92m  Client0 Test => 	Acc: 53.725 	Loss: 3.5794[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 42.101 	Loss: 1.9539[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 51.736 	Loss: 1.5270[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 58.160 	Loss: 1.2957[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 66.580 	Loss: 1.0668[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 74.392 	Loss: 0.8111[00m
[92m  Client1 Test => 	Acc: 34.459 	Loss: 5.9519[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 48.003 	Loss: 1.9469[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 53.733 	Loss: 1.4644[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 62.240 	Loss: 1.2006[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 69.618 	Loss: 0.9487[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 75.087 	Loss: 0.8105[00m
[92m  Client2 Test => 	Acc: 33.309 	Loss: 5.8790[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 54.297 	Loss: 1.4312[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 75.694 	Loss: 0.8156[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 78.993 	Loss: 0.7210[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 82.682 	Loss: 0.5613[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 84.679 	Loss: 0.4860[00m
[92m  Client3 Test => 	Acc: 42.456 	Loss: 4.8464[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 24.414 	Loss: 2.4159[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 51.270 	Loss: 1.5883[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 64.062 	Loss: 1.1180[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 68.164 	Loss: 1.0408[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 76.758 	Loss: 0.7630[00m
[92m  Client4 Test => 	Acc: 45.481 	Loss: 2.8808[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 21.354 	Loss: 2.4697[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 51.172 	Loss: 1.5878[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 64.453 	Loss: 1.1863[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 66.797 	Loss: 0.9870[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 70.573 	Loss: 0.8849[00m
[92m  Client5 Test => 	Acc: 44.351 	Loss: 3.1746[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 28.188 	Loss: 2.2501[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 25.312 	Loss: 2.1080[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 24.750 	Loss: 2.0824[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 26.688 	Loss: 2.0828[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 25.688 	Loss: 2.0843[00m
[92m  Client6 Test => 	Acc: 11.047 	Loss: 3.1335[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 21.406 	Loss: 2.4388[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 36.328 	Loss: 1.8770[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 48.438 	Loss: 1.5224[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 59.453 	Loss: 1.2727[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 68.047 	Loss: 1.0000[00m
[92m  Client7 Test => 	Acc: 45.584 	Loss: 2.3049[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 17.188 	Loss: 2.6984[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 52.865 	Loss: 1.6666[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 56.510 	Loss: 1.5090[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 67.839 	Loss: 1.1257[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 71.354 	Loss: 0.9080[00m
[92m  Client8 Test => 	Acc: 30.232 	Loss: 2.7900[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 31.250 	Loss: 2.0851[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 37.079 	Loss: 1.9842[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 45.132 	Loss: 1.6283[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 55.589 	Loss: 1.3622[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 64.363 	Loss: 1.1694[00m
[92m  Client9 Test => 	Acc: 46.161 	Loss: 2.0713[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 32.079 	Loss: 2.4113[00m
 Train: Round   2, Avg Accuracy 69.593 | Avg Loss 0.939
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 67.053 	Loss: 1.1464[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 76.105 	Loss: 0.7898[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 03:05:53] [setup] RAM Tracking...
[codecarbon INFO @ 03:05:53] [setup] CPU Tracking...
[codecarbon WARNING @ 03:05:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:05:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:05:55] [setup] GPU Tracking...
[codecarbon INFO @ 03:05:55] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:05:55] >>> Tracker's metadata:
[codecarbon INFO @ 03:05:55]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:05:55]   Python version: 3.12.7
[codecarbon INFO @ 03:05:55]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:05:55]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:05:55]   CPU count: 56
[codecarbon INFO @ 03:05:55]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:05:55]   GPU count: 2
[codecarbon INFO @ 03:05:55]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:05:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:05:59] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:05:59] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:05:59] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.987675613170257 W
[codecarbon INFO @ 03:05:59] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 03:06:54] [setup] RAM Tracking...
[codecarbon INFO @ 03:06:54] [setup] CPU Tracking...
[codecarbon WARNING @ 03:06:54] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:06:56] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:06:56] [setup] GPU Tracking...
[codecarbon INFO @ 03:06:56] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:06:56] >>> Tracker's metadata:
[codecarbon INFO @ 03:06:56]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:06:56]   Python version: 3.12.7
[codecarbon INFO @ 03:06:56]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:06:56]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:06:56]   CPU count: 56
[codecarbon INFO @ 03:06:56]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:06:56]   GPU count: 2
[codecarbon INFO @ 03:06:56]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:06:59] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:06:59] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:06:59] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:06:59] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 25.076379823237925 W
[codecarbon INFO @ 03:06:59] 0.000031 kWh of electricity used since the beginning.

[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 80.873 	Loss: 0.5935[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 84.456 	Loss: 0.4858[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 87.689 	Loss: 0.3937[00m
[92m  Client0 Test => 	Acc: 52.165 	Loss: 4.0685[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 45.573 	Loss: 1.8499[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 69.358 	Loss: 1.0218[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 75.347 	Loss: 0.7452[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 79.080 	Loss: 0.6459[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 81.597 	Loss: 0.5423[00m
[92m  Client1 Test => 	Acc: 39.554 	Loss: 6.1793[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 52.691 	Loss: 1.6072[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 69.965 	Loss: 0.9776[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 75.608 	Loss: 0.7796[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 78.906 	Loss: 0.6422[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 81.944 	Loss: 0.5747[00m
[92m  Client2 Test => 	Acc: 43.606 	Loss: 4.0095[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 71.007 	Loss: 1.1560[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 82.595 	Loss: 0.5604[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 82.509 	Loss: 0.5502[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 84.766 	Loss: 0.4887[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 87.413 	Loss: 0.3797[00m
[92m  Client3 Test => 	Acc: 53.073 	Loss: 5.8650[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 50.391 	Loss: 1.6484[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 73.828 	Loss: 0.7946[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 76.270 	Loss: 0.7761[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 78.223 	Loss: 0.7578[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 82.715 	Loss: 0.5639[00m
[92m  Client4 Test => 	Acc: 47.394 	Loss: 2.8162[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 43.359 	Loss: 2.0126[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 66.146 	Loss: 1.1207[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 74.089 	Loss: 0.8373[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 75.000 	Loss: 0.7194[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 77.604 	Loss: 0.7093[00m
[92m  Client5 Test => 	Acc: 54.120 	Loss: 2.2994[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 60.375 	Loss: 1.3741[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 71.531 	Loss: 0.8677[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 80.344 	Loss: 0.6762[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 75.281 	Loss: 0.7765[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 78.531 	Loss: 0.6713[00m
[92m  Client6 Test => 	Acc: 59.434 	Loss: 1.3433[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 37.031 	Loss: 2.0123[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 54.609 	Loss: 1.3895[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 70.859 	Loss: 0.9349[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 75.547 	Loss: 0.7868[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 75.547 	Loss: 0.7356[00m
[92m  Client7 Test => 	Acc: 55.038 	Loss: 1.8474[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 34.766 	Loss: 2.1568[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 66.667 	Loss: 1.0785[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 74.089 	Loss: 0.8639[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 80.729 	Loss: 0.6526[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 82.422 	Loss: 0.5440[00m
[92m  Client8 Test => 	Acc: 46.345 	Loss: 1.8685[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 52.644 	Loss: 1.5682[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 71.995 	Loss: 0.9438[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 76.803 	Loss: 0.8479[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 79.207 	Loss: 0.7245[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 83.714 	Loss: 0.5764[00m
[92m  Client9 Test => 	Acc: 64.126 	Loss: 1.3562[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 48.125 	Loss: 1.5542[00m
 Train: Round   3, Avg Accuracy 81.918 | Avg Loss 0.569
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 76.643 	Loss: 0.7003[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 86.665 	Loss: 0.4143[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 87.069 	Loss: 0.4135[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 89.709 	Loss: 0.3317[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 92.376 	Loss: 0.2277[00m
[92m  Client0 Test => 	Acc: 58.636 	Loss: 5.2824[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 65.885 	Loss: 1.0816[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 78.906 	Loss: 0.6576[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 83.247 	Loss: 0.5312[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 83.767 	Loss: 0.4763[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 88.194 	Loss: 0.3696[00m
[92m  Client1 Test => 	Acc: 53.551 	Loss: 4.2350[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 75.260 	Loss: 0.8070[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 76.736 	Loss: 0.7029[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 83.420 	Loss: 0.4854[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 86.545 	Loss: 0.4144[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 88.455 	Loss: 0.3596[00m
[92m  Client2 Test => 	Acc: 55.800 	Loss: 5.1715[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 81.250 	Loss: 0.6501[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 86.545 	Loss: 0.4167[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 87.109 	Loss: 0.4360[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 89.106 	Loss: 0.3443[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 91.884 	Loss: 0.2803[00m
[92m  Client3 Test => 	Acc: 57.737 	Loss: 4.9441[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 75.586 	Loss: 0.8499[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 86.621 	Loss: 0.4699[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 87.695 	Loss: 0.4069[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 88.867 	Loss: 0.3437[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 91.895 	Loss: 0.2908[00m
[92m  Client4 Test => 	Acc: 61.993 	Loss: 1.4129[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 63.802 	Loss: 1.1428[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 77.604 	Loss: 0.6943[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 81.120 	Loss: 0.5581[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 86.458 	Loss: 0.4185[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 87.891 	Loss: 0.3732[00m
[92m  Client5 Test => 	Acc: 61.043 	Loss: 2.7221[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 71.375 	Loss: 0.8828[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 79.250 	Loss: 0.6235[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 83.312 	Loss: 0.5702[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 88.375 	Loss: 0.3766[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 88.438 	Loss: 0.3893[00m
[92m  Client6 Test => 	Acc: 69.607 	Loss: 0.9308[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 58.438 	Loss: 1.2801[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 73.438 	Loss: 0.8669[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 79.453 	Loss: 0.6588[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 79.297 	Loss: 0.6492[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 80.391 	Loss: 0.6077[00m
[92m  Client7 Test => 	Acc: 62.622 	Loss: 1.7605[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 57.943 	Loss: 1.2501[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 03:33:42] [setup] RAM Tracking...
[codecarbon INFO @ 03:33:42] [setup] CPU Tracking...
[codecarbon WARNING @ 03:33:42] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:33:44] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:33:44] [setup] GPU Tracking...
[codecarbon INFO @ 03:33:44] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:33:44] >>> Tracker's metadata:
[codecarbon INFO @ 03:33:44]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:33:44]   Python version: 3.12.7
[codecarbon INFO @ 03:33:44]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:33:44]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:33:44]   CPU count: 56
[codecarbon INFO @ 03:33:44]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:33:44]   GPU count: 2
[codecarbon INFO @ 03:33:44]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:33:47] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:33:48] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:33:48] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:33:48] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 15.46832383624565 W
[codecarbon INFO @ 03:33:48] 0.000034 kWh of electricity used since the beginning.
[codecarbon INFO @ 03:34:43] [setup] RAM Tracking...
[codecarbon INFO @ 03:34:43] [setup] CPU Tracking...
[codecarbon WARNING @ 03:34:43] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 03:34:45] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:34:45] [setup] GPU Tracking...
[codecarbon INFO @ 03:34:45] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 03:34:45] >>> Tracker's metadata:
[codecarbon INFO @ 03:34:45]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 03:34:45]   Python version: 3.12.7
[codecarbon INFO @ 03:34:45]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 03:34:45]   Available RAM : 126.630 GB
[codecarbon INFO @ 03:34:45]   CPU count: 56
[codecarbon INFO @ 03:34:45]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 03:34:45]   GPU count: 2
[codecarbon INFO @ 03:34:45]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 03:34:48] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 03:34:49] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 03:34:49] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 03:34:49] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 18.635092290699248 W
[codecarbon INFO @ 03:34:49] 0.000034 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 04:01:46] [setup] RAM Tracking...
[codecarbon INFO @ 04:01:46] [setup] CPU Tracking...
[codecarbon WARNING @ 04:01:46] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:01:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:01:48] [setup] GPU Tracking...
[codecarbon INFO @ 04:01:48] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:01:48] >>> Tracker's metadata:
[codecarbon INFO @ 04:01:48]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:01:48]   Python version: 3.12.7
[codecarbon INFO @ 04:01:48]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:01:48]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:01:48]   CPU count: 56
[codecarbon INFO @ 04:01:48]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:01:48]   GPU count: 2
[codecarbon INFO @ 04:01:48]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:01:51] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:01:52] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:01:52] Energy consumed for all CPUs : 0.000023 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:01:52] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 15.841621902057224 W
[codecarbon INFO @ 04:01:52] 0.000037 kWh of electricity used since the beginning.
[codecarbon INFO @ 04:02:47] [setup] RAM Tracking...
[codecarbon INFO @ 04:02:47] [setup] CPU Tracking...
[codecarbon WARNING @ 04:02:47] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:02:48] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:02:48] [setup] GPU Tracking...
[codecarbon INFO @ 04:02:48] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:02:48] >>> Tracker's metadata:
[codecarbon INFO @ 04:02:48]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:02:48]   Python version: 3.12.7
[codecarbon INFO @ 04:02:48]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:02:48]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:02:48]   CPU count: 56
[codecarbon INFO @ 04:02:48]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:02:48]   GPU count: 2
[codecarbon INFO @ 04:02:48]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:02:51] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:02:52] Energy consumed for RAM : 0.000008 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:02:52] Energy consumed for all CPUs : 0.000017 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:02:52] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.907548614952443 W
[codecarbon INFO @ 04:02:52] 0.000027 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 82.292 	Loss: 0.6151[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 82.031 	Loss: 0.6480[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 83.464 	Loss: 0.5619[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 87.500 	Loss: 0.4060[00m
[92m  Client8 Test => 	Acc: 52.762 	Loss: 1.6680[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 71.334 	Loss: 0.9565[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 83.053 	Loss: 0.5370[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 89.123 	Loss: 0.3734[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 89.724 	Loss: 0.3292[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 86.058 	Loss: 0.4417[00m
[92m  Client9 Test => 	Acc: 67.005 	Loss: 1.1686[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 68.164 	Loss: 0.9413[00m
 Train: Round   4, Avg Accuracy 88.308 | Avg Loss 0.375
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 83.190 	Loss: 0.4979[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 88.874 	Loss: 0.3289[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 87.284 	Loss: 0.4105[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 85.426 	Loss: 0.4583[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 89.844 	Loss: 0.3099[00m
[92m  Client0 Test => 	Acc: 57.926 	Loss: 3.6014[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 72.135 	Loss: 0.8090[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 82.552 	Loss: 0.5106[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 87.066 	Loss: 0.3793[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 88.628 	Loss: 0.3351[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 88.802 	Loss: 0.2854[00m
[92m  Client1 Test => 	Acc: 59.608 	Loss: 5.0762[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 81.337 	Loss: 0.5657[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 88.976 	Loss: 0.3461[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 90.799 	Loss: 0.2763[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 90.191 	Loss: 0.3192[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 92.361 	Loss: 0.2393[00m
[92m  Client2 Test => 	Acc: 62.833 	Loss: 5.4674[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 86.936 	Loss: 0.4159[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 89.497 	Loss: 0.3326[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 91.146 	Loss: 0.2726[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 89.062 	Loss: 0.3722[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 92.535 	Loss: 0.2425[00m
[92m  Client3 Test => 	Acc: 61.816 	Loss: 4.8329[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 85.156 	Loss: 0.4702[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 91.895 	Loss: 0.2713[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 91.309 	Loss: 0.2651[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 92.578 	Loss: 0.2297[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 87.500 	Loss: 0.3871[00m
[92m  Client4 Test => 	Acc: 64.792 	Loss: 1.3748[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 79.036 	Loss: 0.7058[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 84.505 	Loss: 0.4591[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 86.589 	Loss: 0.4013[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 86.849 	Loss: 0.3950[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 89.583 	Loss: 0.2944[00m
[92m  Client5 Test => 	Acc: 68.880 	Loss: 1.8916[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 81.781 	Loss: 0.5662[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 86.000 	Loss: 0.4554[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 88.656 	Loss: 0.3656[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 90.031 	Loss: 0.3131[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 90.250 	Loss: 0.3146[00m
[92m  Client6 Test => 	Acc: 76.059 	Loss: 0.7975[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 73.203 	Loss: 0.7971[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 80.781 	Loss: 0.6527[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 78.281 	Loss: 0.7160[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 81.406 	Loss: 0.5835[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 86.406 	Loss: 0.4390[00m
[92m  Client7 Test => 	Acc: 68.210 	Loss: 1.2139[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 79.557 	Loss: 0.6657[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 89.062 	Loss: 0.3693[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 89.583 	Loss: 0.3410[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 88.932 	Loss: 0.3437[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 90.104 	Loss: 0.3133[00m
[92m  Client8 Test => 	Acc: 59.021 	Loss: 1.5140[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 82.993 	Loss: 0.5537[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 88.822 	Loss: 0.3878[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 90.865 	Loss: 0.2985[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 86.058 	Loss: 0.4591[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 90.264 	Loss: 0.3493[00m
[92m  Client9 Test => 	Acc: 70.665 	Loss: 1.2161[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 66.682 	Loss: 1.1223[00m
 Train: Round   5, Avg Accuracy 89.765 | Avg Loss 0.317
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 87.446 	Loss: 0.3789[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 91.595 	Loss: 0.2441[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 92.188 	Loss: 0.2540[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 92.807 	Loss: 0.2255[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 94.262 	Loss: 0.1878[00m
[92m  Client0 Test => 	Acc: 67.722 	Loss: 2.6152[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 81.944 	Loss: 0.5409[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 89.236 	Loss: 0.3235[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 90.365 	Loss: 0.2814[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 91.059 	Loss: 0.2658[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 94.965 	Loss: 0.1417[00m
[92m  Client1 Test => 	Acc: 61.002 	Loss: 3.3987[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 89.323 	Loss: 0.3848[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 91.319 	Loss: 0.2745[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 91.146 	Loss: 0.2575[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 93.229 	Loss: 0.2023[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 92.708 	Loss: 0.2014[00m
[92m  Client2 Test => 	Acc: 66.912 	Loss: 3.5004[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 89.670 	Loss: 0.3429[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 90.712 	Loss: 0.2884[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 93.229 	Loss: 0.2245[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 92.882 	Loss: 0.2323[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 94.488 	Loss: 0.1770[00m
[92m  Client3 Test => 	Acc: 68.759 	Loss: 3.3522[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 84.668 	Loss: 0.4966[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 92.969 	Loss: 0.2413[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 93.066 	Loss: 0.2131[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 04:29:32] [setup] RAM Tracking...
[codecarbon INFO @ 04:29:32] [setup] CPU Tracking...
[codecarbon WARNING @ 04:29:32] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:29:34] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:29:34] [setup] GPU Tracking...
[codecarbon INFO @ 04:29:34] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:29:34] >>> Tracker's metadata:
[codecarbon INFO @ 04:29:34]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:29:34]   Python version: 3.12.7
[codecarbon INFO @ 04:29:34]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:29:34]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:29:34]   CPU count: 56
[codecarbon INFO @ 04:29:34]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:29:34]   GPU count: 2
[codecarbon INFO @ 04:29:34]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:29:37] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:29:38] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:29:38] Energy consumed for all CPUs : 0.000022 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:29:38] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.668209920505024 W
[codecarbon INFO @ 04:29:38] 0.000036 kWh of electricity used since the beginning.
[codecarbon INFO @ 04:30:33] [setup] RAM Tracking...
[codecarbon INFO @ 04:30:33] [setup] CPU Tracking...
[codecarbon WARNING @ 04:30:33] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 04:30:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:30:35] [setup] GPU Tracking...
[codecarbon INFO @ 04:30:35] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 04:30:35] >>> Tracker's metadata:
[codecarbon INFO @ 04:30:35]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 04:30:35]   Python version: 3.12.7
[codecarbon INFO @ 04:30:35]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 04:30:35]   Available RAM : 126.630 GB
[codecarbon INFO @ 04:30:35]   CPU count: 56
[codecarbon INFO @ 04:30:35]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 04:30:35]   GPU count: 2
[codecarbon INFO @ 04:30:35]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 04:30:38] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 04:30:39] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 04:30:39] Energy consumed for all CPUs : 0.000019 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 04:30:39] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 18.242281998783056 W
[codecarbon INFO @ 04:30:39] 0.000031 kWh of electricity used since the beginning.
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 05:00:53] [setup] RAM Tracking...
[codecarbon INFO @ 05:00:53] [setup] CPU Tracking...
[codecarbon WARNING @ 05:00:53] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:00:55] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:00:55] [setup] GPU Tracking...
[codecarbon INFO @ 05:00:55] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:00:55] >>> Tracker's metadata:
[codecarbon INFO @ 05:00:55]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:00:55]   Python version: 3.12.7
[codecarbon INFO @ 05:00:55]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:00:55]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:00:55]   CPU count: 56
[codecarbon INFO @ 05:00:55]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:00:55]   GPU count: 2
[codecarbon INFO @ 05:00:55]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:00:58] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:00:59] Energy consumed for RAM : 0.000011 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:00:59] Energy consumed for all CPUs : 0.000024 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:00:59] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 15.253785821537562 W
[codecarbon INFO @ 05:00:59] 0.000039 kWh of electricity used since the beginning.
[codecarbon INFO @ 05:02:16] [setup] RAM Tracking...
[codecarbon INFO @ 05:02:16] [setup] CPU Tracking...
[codecarbon WARNING @ 05:02:16] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:02:17] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:02:17] [setup] GPU Tracking...
[codecarbon INFO @ 05:02:17] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:02:17] >>> Tracker's metadata:
[codecarbon INFO @ 05:02:17]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:02:17]   Python version: 3.12.7
[codecarbon INFO @ 05:02:17]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:02:17]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:02:17]   CPU count: 56
[codecarbon INFO @ 05:02:17]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:02:17]   GPU count: 2
[codecarbon INFO @ 05:02:17]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:02:21] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:02:21] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:02:21] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:02:21] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 17.353565830934034 W
[codecarbon INFO @ 05:02:21] 0.000035 kWh of electricity used since the beginning.

[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 92.188 	Loss: 0.2352[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 93.945 	Loss: 0.1771[00m
[92m  Client4 Test => 	Acc: 65.057 	Loss: 1.4060[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 78.646 	Loss: 0.7842[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 89.062 	Loss: 0.3546[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 89.453 	Loss: 0.3055[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 92.318 	Loss: 0.2404[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 93.229 	Loss: 0.2216[00m
[92m  Client5 Test => 	Acc: 73.258 	Loss: 1.3637[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 85.844 	Loss: 0.4719[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 89.469 	Loss: 0.3546[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 90.938 	Loss: 0.2978[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 93.094 	Loss: 0.2166[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 92.344 	Loss: 0.2300[00m
[92m  Client6 Test => 	Acc: 78.985 	Loss: 0.7219[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 78.203 	Loss: 0.6909[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 87.109 	Loss: 0.4106[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 88.906 	Loss: 0.3502[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 90.625 	Loss: 0.3039[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 89.219 	Loss: 0.3305[00m
[92m  Client7 Test => 	Acc: 75.479 	Loss: 0.9944[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 79.948 	Loss: 0.7029[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 89.193 	Loss: 0.3719[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 91.797 	Loss: 0.2853[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 91.667 	Loss: 0.2551[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 93.620 	Loss: 0.1877[00m
[92m  Client8 Test => 	Acc: 70.184 	Loss: 1.2502[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 85.697 	Loss: 0.4507[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 92.969 	Loss: 0.2443[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 91.106 	Loss: 0.2687[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 93.149 	Loss: 0.2311[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 94.772 	Loss: 0.1588[00m
[92m  Client9 Test => 	Acc: 75.153 	Loss: 0.9625[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 85.152 	Loss: 0.4557[00m
 Train: Round   6, Avg Accuracy 93.355 | Avg Loss 0.201
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 90.921 	Loss: 0.2952[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 93.238 	Loss: 0.2142[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 93.481 	Loss: 0.2053[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 94.639 	Loss: 0.1561[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 94.774 	Loss: 0.1681[00m
[92m  Client0 Test => 	Acc: 67.736 	Loss: 3.6105[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 83.681 	Loss: 0.5454[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 90.017 	Loss: 0.3002[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 93.490 	Loss: 0.2045[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 95.312 	Loss: 0.1299[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 95.486 	Loss: 0.1393[00m
[92m  Client1 Test => 	Acc: 62.843 	Loss: 4.2565[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 79.774 	Loss: 0.7238[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 89.497 	Loss: 0.3173[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 90.365 	Loss: 0.2870[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 93.490 	Loss: 0.1842[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 94.097 	Loss: 0.2125[00m
[92m  Client2 Test => 	Acc: 64.164 	Loss: 4.3329[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 88.238 	Loss: 0.4452[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 93.576 	Loss: 0.2015[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 93.403 	Loss: 0.2229[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 94.618 	Loss: 0.1698[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 95.269 	Loss: 0.1747[00m
[92m  Client3 Test => 	Acc: 68.148 	Loss: 3.9186[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 91.797 	Loss: 0.2333[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 93.457 	Loss: 0.2166[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 92.871 	Loss: 0.1944[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 95.410 	Loss: 0.1410[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 96.094 	Loss: 0.1097[00m
[92m  Client4 Test => 	Acc: 78.713 	Loss: 0.8404[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 92.057 	Loss: 0.2786[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 92.708 	Loss: 0.2196[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 93.880 	Loss: 0.1550[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 95.312 	Loss: 0.1454[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 90.755 	Loss: 0.3027[00m
[92m  Client5 Test => 	Acc: 72.076 	Loss: 1.1732[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 90.219 	Loss: 0.3141[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 92.125 	Loss: 0.2506[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 92.531 	Loss: 0.2359[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 93.406 	Loss: 0.2177[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 94.781 	Loss: 0.1778[00m
[92m  Client6 Test => 	Acc: 85.633 	Loss: 0.4658[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 86.953 	Loss: 0.4004[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 91.484 	Loss: 0.2632[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 92.266 	Loss: 0.2261[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 93.359 	Loss: 0.1948[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 92.500 	Loss: 0.2409[00m
[92m  Client7 Test => 	Acc: 83.844 	Loss: 0.6522[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 91.406 	Loss: 0.3037[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 94.141 	Loss: 0.1897[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 96.094 	Loss: 0.1205[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 97.005 	Loss: 0.0905[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 96.745 	Loss: 0.0881[00m
[92m  Client8 Test => 	Acc: 80.787 	Loss: 0.9350[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 90.986 	Loss: 0.2801[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 93.029 	Loss: 0.2092[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 94.772 	Loss: 0.1932[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 93.990 	Loss: 0.1921[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 93.930 	Loss: 0.1815[00m
[92m  Client9 Test => 	Acc: 75.308 	Loss: 0.7794[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 76.626 	Loss: 1.0254[00m
 Train: Round   7, Avg Accuracy 94.443 | Avg Loss 0.180
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 91.703 	Loss: 0.2580[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 94.989 	Loss: 0.1604[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 94.558 	Loss: 0.1801[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 94.639 	Loss: 0.1623[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 94.289 	Loss: 0.1729[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 05:33:17] [setup] RAM Tracking...
[codecarbon INFO @ 05:33:17] [setup] CPU Tracking...
[codecarbon WARNING @ 05:33:17] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:33:19] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:33:19] [setup] GPU Tracking...
[codecarbon INFO @ 05:33:19] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:33:19] >>> Tracker's metadata:
[codecarbon INFO @ 05:33:19]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:33:19]   Python version: 3.12.7
[codecarbon INFO @ 05:33:19]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:33:19]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:33:19]   CPU count: 56
[codecarbon INFO @ 05:33:19]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:33:19]   GPU count: 2
[codecarbon INFO @ 05:33:19]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:33:22] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:33:23] Energy consumed for RAM : 0.000012 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:33:23] Energy consumed for all CPUs : 0.000025 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:33:23] Energy consumed for all GPUs : 0.000004 kWh. Total GPU Power : 16.43996352309872 W
[codecarbon INFO @ 05:33:23] 0.000041 kWh of electricity used since the beginning.
[codecarbon INFO @ 05:34:21] [setup] RAM Tracking...
[codecarbon INFO @ 05:34:21] [setup] CPU Tracking...
[codecarbon WARNING @ 05:34:21] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 05:34:23] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:34:23] [setup] GPU Tracking...
[codecarbon INFO @ 05:34:23] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 05:34:23] >>> Tracker's metadata:
[codecarbon INFO @ 05:34:23]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 05:34:23]   Python version: 3.12.7
[codecarbon INFO @ 05:34:23]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 05:34:23]   Available RAM : 126.630 GB
[codecarbon INFO @ 05:34:23]   CPU count: 56
[codecarbon INFO @ 05:34:23]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 05:34:23]   GPU count: 2
[codecarbon INFO @ 05:34:23]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 05:34:26] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 05:34:27] Energy consumed for RAM : 0.000009 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 05:34:27] Energy consumed for all CPUs : 0.000020 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 05:34:27] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.82795018742799 W
[codecarbon INFO @ 05:34:27] 0.000033 kWh of electricity used since the beginning.

[92m  Client0 Test => 	Acc: 67.492 	Loss: 2.3329[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 92.274 	Loss: 0.2396[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 95.833 	Loss: 0.1216[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 95.486 	Loss: 0.1289[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 95.573 	Loss: 0.1199[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 94.444 	Loss: 0.1744[00m
[92m  Client1 Test => 	Acc: 67.272 	Loss: 2.4798[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 94.618 	Loss: 0.1941[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 95.573 	Loss: 0.1282[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 97.222 	Loss: 0.0824[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 95.399 	Loss: 0.1300[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 95.486 	Loss: 0.1223[00m
[92m  Client2 Test => 	Acc: 72.498 	Loss: 3.0031[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 94.444 	Loss: 0.1795[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 94.444 	Loss: 0.1758[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 96.398 	Loss: 0.1207[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 95.920 	Loss: 0.1301[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 96.398 	Loss: 0.1216[00m
[92m  Client3 Test => 	Acc: 71.290 	Loss: 3.1581[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 86.719 	Loss: 0.4135[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 93.848 	Loss: 0.1909[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 96.289 	Loss: 0.1126[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 95.996 	Loss: 0.1290[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 95.020 	Loss: 0.1637[00m
[92m  Client4 Test => 	Acc: 72.602 	Loss: 1.1825[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 74.349 	Loss: 0.8480[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 90.365 	Loss: 0.3982[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 93.880 	Loss: 0.1631[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 96.875 	Loss: 0.1086[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 95.833 	Loss: 0.1270[00m
[92m  Client5 Test => 	Acc: 77.986 	Loss: 1.5697[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 90.281 	Loss: 0.3209[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 93.531 	Loss: 0.2077[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 93.094 	Loss: 0.2184[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 94.500 	Loss: 0.1757[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 89.500 	Loss: 0.3656[00m
[92m  Client6 Test => 	Acc: 77.258 	Loss: 0.7295[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 83.125 	Loss: 0.6136[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 91.797 	Loss: 0.2623[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 91.172 	Loss: 0.2804[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 93.906 	Loss: 0.1834[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 95.000 	Loss: 0.1446[00m
[92m  Client7 Test => 	Acc: 82.309 	Loss: 0.7687[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 81.250 	Loss: 0.6582[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 91.927 	Loss: 0.3020[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 94.141 	Loss: 0.1743[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 96.224 	Loss: 0.1243[00m
[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 96.745 	Loss: 0.0970[00m
[92m  Client8 Test => 	Acc: 79.209 	Loss: 0.9234[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 89.002 	Loss: 0.3648[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 94.591 	Loss: 0.1815[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 95.613 	Loss: 0.1330[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 94.050 	Loss: 0.2064[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 94.892 	Loss: 0.1684[00m
[92m  Client9 Test => 	Acc: 76.929 	Loss: 0.8000[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 92.390 	Loss: 0.2696[00m
 Train: Round   8, Avg Accuracy 94.761 | Avg Loss 0.166
[91m Client0 Train => Local Epoch: 0 / 5 	Acc: 93.265 	Loss: 0.2021[00m
[91m Client0 Train => Local Epoch: 1 / 5 	Acc: 95.339 	Loss: 0.1423[00m
[91m Client0 Train => Local Epoch: 2 / 5 	Acc: 95.447 	Loss: 0.1361[00m
[91m Client0 Train => Local Epoch: 3 / 5 	Acc: 95.528 	Loss: 0.1475[00m
[91m Client0 Train => Local Epoch: 4 / 5 	Acc: 94.935 	Loss: 0.1636[00m
[92m  Client0 Test => 	Acc: 66.733 	Loss: 2.7750[00m
[91m Client1 Train => Local Epoch: 0 / 5 	Acc: 90.451 	Loss: 0.2802[00m
[91m Client1 Train => Local Epoch: 1 / 5 	Acc: 95.660 	Loss: 0.1448[00m
[91m Client1 Train => Local Epoch: 2 / 5 	Acc: 95.920 	Loss: 0.1035[00m
[91m Client1 Train => Local Epoch: 3 / 5 	Acc: 96.788 	Loss: 0.1121[00m
[91m Client1 Train => Local Epoch: 4 / 5 	Acc: 96.441 	Loss: 0.0889[00m
[92m  Client1 Test => 	Acc: 66.280 	Loss: 3.1143[00m
[91m Client2 Train => Local Epoch: 0 / 5 	Acc: 85.938 	Loss: 0.3846[00m
[91m Client2 Train => Local Epoch: 1 / 5 	Acc: 94.792 	Loss: 0.1752[00m
[91m Client2 Train => Local Epoch: 2 / 5 	Acc: 93.924 	Loss: 0.1715[00m
[91m Client2 Train => Local Epoch: 3 / 5 	Acc: 94.792 	Loss: 0.1537[00m
[91m Client2 Train => Local Epoch: 4 / 5 	Acc: 96.181 	Loss: 0.1104[00m
[92m  Client2 Test => 	Acc: 71.042 	Loss: 3.5749[00m
[91m Client3 Train => Local Epoch: 0 / 5 	Acc: 93.359 	Loss: 0.2232[00m
[91m Client3 Train => Local Epoch: 1 / 5 	Acc: 97.049 	Loss: 0.1033[00m
[91m Client3 Train => Local Epoch: 2 / 5 	Acc: 95.920 	Loss: 0.1383[00m
[91m Client3 Train => Local Epoch: 3 / 5 	Acc: 95.703 	Loss: 0.1394[00m
[91m Client3 Train => Local Epoch: 4 / 5 	Acc: 96.398 	Loss: 0.1175[00m
[92m  Client3 Test => 	Acc: 70.816 	Loss: 4.3199[00m
[91m Client4 Train => Local Epoch: 0 / 5 	Acc: 96.094 	Loss: 0.1474[00m
[91m Client4 Train => Local Epoch: 1 / 5 	Acc: 96.680 	Loss: 0.1046[00m
[91m Client4 Train => Local Epoch: 2 / 5 	Acc: 96.289 	Loss: 0.1088[00m
[91m Client4 Train => Local Epoch: 3 / 5 	Acc: 96.582 	Loss: 0.0879[00m
[91m Client4 Train => Local Epoch: 4 / 5 	Acc: 96.191 	Loss: 0.1109[00m
[92m  Client4 Test => 	Acc: 79.387 	Loss: 0.9376[00m
[91m Client5 Train => Local Epoch: 0 / 5 	Acc: 95.182 	Loss: 0.1711[00m
[91m Client5 Train => Local Epoch: 1 / 5 	Acc: 95.312 	Loss: 0.1302[00m
[91m Client5 Train => Local Epoch: 2 / 5 	Acc: 97.135 	Loss: 0.0886[00m
[91m Client5 Train => Local Epoch: 3 / 5 	Acc: 98.438 	Loss: 0.0602[00m
[91m Client5 Train => Local Epoch: 4 / 5 	Acc: 97.917 	Loss: 0.0807[00m
[92m  Client5 Test => 	Acc: 77.855 	Loss: 1.2883[00m
[91m Client6 Train => Local Epoch: 0 / 5 	Acc: 93.125 	Loss: 0.2199[00m
[91m Client6 Train => Local Epoch: 1 / 5 	Acc: 94.125 	Loss: 0.1834[00m
[91m Client6 Train => Local Epoch: 2 / 5 	Acc: 96.094 	Loss: 0.1264[00m
[91m Client6 Train => Local Epoch: 3 / 5 	Acc: 92.844 	Loss: 0.2486[00m
[91m Client6 Train => Local Epoch: 4 / 5 	Acc: 94.094 	Loss: 0.1852[00m
[92m  Client6 Test => 	Acc: 84.317 	Loss: 0.5410[00m
[91m Client7 Train => Local Epoch: 0 / 5 	Acc: 93.672 	Loss: 0.1960[00m
[91m Client7 Train => Local Epoch: 1 / 5 	Acc: 96.172 	Loss: 0.1162[00m
[91m Client7 Train => Local Epoch: 2 / 5 	Acc: 96.172 	Loss: 0.1304[00m
[91m Client7 Train => Local Epoch: 3 / 5 	Acc: 91.484 	Loss: 0.2549[00m
[91m Client7 Train => Local Epoch: 4 / 5 	Acc: 91.641 	Loss: 0.2622[00m
[92m  Client7 Test => 	Acc: 80.650 	Loss: 0.6777[00m
[91m Client8 Train => Local Epoch: 0 / 5 	Acc: 95.703 	Loss: 0.1685[00m
[91m Client8 Train => Local Epoch: 1 / 5 	Acc: 96.484 	Loss: 0.1238[00m
[91m Client8 Train => Local Epoch: 2 / 5 	Acc: 97.786 	Loss: 0.0740[00m
[91m Client8 Train => Local Epoch: 3 / 5 	Acc: 97.656 	Loss: 0.0914[00mC:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
C:\Users\pr8pf\AppData\Local\anaconda3\Lib\site-packages\sklearn\cluster\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
[codecarbon INFO @ 06:02:16] [setup] RAM Tracking...
[codecarbon INFO @ 06:02:16] [setup] CPU Tracking...
[codecarbon WARNING @ 06:02:16] No CPU tracking mode found. Falling back on CPU constant mode. 
 Windows OS detected: Please install Intel Power Gadget to measure CPU

[codecarbon INFO @ 06:02:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:02:18] [setup] GPU Tracking...
[codecarbon INFO @ 06:02:18] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 06:02:18] >>> Tracker's metadata:
[codecarbon INFO @ 06:02:18]   Platform system: Windows-11-10.0.22631-SP0
[codecarbon INFO @ 06:02:18]   Python version: 3.12.7
[codecarbon INFO @ 06:02:18]   CodeCarbon version: 2.8.3
[codecarbon INFO @ 06:02:18]   Available RAM : 126.630 GB
[codecarbon INFO @ 06:02:18]   CPU count: 56
[codecarbon INFO @ 06:02:18]   CPU model: Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz
[codecarbon INFO @ 06:02:18]   GPU count: 2
[codecarbon INFO @ 06:02:18]   GPU model: 2 x NVIDIA RTX A5000
[codecarbon INFO @ 06:02:21] Saving emissions data to file C:\Users\pr8pf\Documents\GitHub\SplitFed\emissions.csv
[codecarbon INFO @ 06:02:22] Energy consumed for RAM : 0.000010 kWh. RAM Power : 47.48608875274658 W
[codecarbon INFO @ 06:02:22] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 102.50000000000001 W
[codecarbon INFO @ 06:02:22] Energy consumed for all GPUs : 0.000003 kWh. Total GPU Power : 16.278701133912474 W
[codecarbon INFO @ 06:02:22] 0.000034 kWh of electricity used since the beginning.

[91m Client8 Train => Local Epoch: 4 / 5 	Acc: 97.917 	Loss: 0.0749[00m
[92m  Client8 Test => 	Acc: 79.338 	Loss: 0.8964[00m
[91m Client9 Train => Local Epoch: 0 / 5 	Acc: 95.493 	Loss: 0.1559[00m
[91m Client9 Train => Local Epoch: 1 / 5 	Acc: 95.673 	Loss: 0.1217[00m
[91m Client9 Train => Local Epoch: 2 / 5 	Acc: 94.591 	Loss: 0.1794[00m
[91m Client9 Train => Local Epoch: 3 / 5 	Acc: 96.514 	Loss: 0.0994[00m
[91m Client9 Train => Local Epoch: 4 / 5 	Acc: 96.755 	Loss: 0.0974[00m
[92m  Client9 Test => 	Acc: 83.171 	Loss: 0.5900[00m
------------------------------------------------
------ Federation process at Server-Side ------- 
------------------------------------------------
-----------------------------------------------------------
------ FedServer: Federation process at Client-Side ------- 
-----------------------------------------------------------
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Client-side aggregation done
[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]
Server-side aggregation done
[92m  Client0 Test => 	Acc: 81.908 	Loss: 0.9363[00m
 Train: Round   9, Avg Accuracy 95.847 | Avg Loss 0.129
Training and Evaluation completed!
===== END Sun 12/21/2025  6:03:25.33 ===== 
